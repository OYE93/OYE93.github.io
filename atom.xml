<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Trace&#39;s Blog</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://oyeblog.com/"/>
  <updated>2023-10-22T07:06:32.045Z</updated>
  <id>https://oyeblog.com/</id>
  
  <author>
    <name>Trace</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Blog 折腾记（二）</title>
    <link href="https://oyeblog.com/2019/hexo_blog_personalize_2/"/>
    <id>https://oyeblog.com/2019/hexo_blog_personalize_2/</id>
    <published>2019-02-20T12:06:00.000Z</published>
    <updated>2023-10-22T07:06:32.045Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本着不折腾不舒服的精神，对博客进行个性化，丰富功能。</p></blockquote><h2 id="增加顶部阅读进度条"><a href="#增加顶部阅读进度条" class="headerlink" title="增加顶部阅读进度条"></a>增加顶部阅读进度条</h2><p>Material主题本身不支持文章顶部阅读进度条，网上查阅资料也大多是<a href="http://theme-next.iissnan.com/" target="_blank" rel="noopener">Next主题</a>相关的介绍，<br>所以决定自己动手给Blog加上这个功能。其实这个功能加入并不复杂，<br>参考网上的方法也已经搞定，但是为了跟主题代码逻辑保持一致，决定重新把代码整理一下并记录。</p><ol><li>首先在<code>_config.yml</code>中增加<code>top_scroll_bar</code>设置来控制进度条的有无、宽度、颜色<pre><code class="yaml"># top scroll bar#   width: the width of scroll bar#   color: the color of scroll bartop_scroll_bar:enable: truewidth: 3pxcolor: &quot;#6d6d6d&quot;</code></pre></li><li>在<code>\layout\_widget\</code>里新建<code>top_scroll_bar.ejs</code>，内容如下：<pre><code class="html">&lt;!-- top scroll bar --&gt;&lt;style type=&quot;text/css&quot;&gt; .top-scroll-bar { position: fixed; top: 0; left: 0; z-index: 9999; display: none; width: 0; height: &lt;%= theme.top_scroll_bar.width %&gt;; background: &lt;%= theme.top_scroll_bar.color %&gt;; }&lt;/style&gt;&lt;div class=&quot;top-scroll-bar&quot;&gt;&lt;script type=&quot;text/javascript&quot;&gt;$(document).ready(function () {$(window).scroll(function(){ $(&quot;.top-scroll-bar&quot;).attr(&quot;style&quot;, &quot;width: &quot; + ($(this).scrollTop() / ($(document).height() - $(this).height()) * 100) + &quot;%; display: block;&quot;);});});&lt;/script&gt;</code></pre></li><li>然后在<code>\layout\_partial\head.ejs</code>里加入调用<code>top_scroll_bar.ejs</code>的代码<pre><code class="html"> &lt;!-- Top Scroll Bar --&gt; &lt;% if((theme.top_scroll_bar.enable) &amp;&amp; (is_post())){ %&gt;     &lt;%- partial(&#39;_widget/top_scroll_bar&#39;) %&gt; &lt;% } %&gt;</code></pre>效果如本博客所示。</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;本着不折腾不舒服的精神，对博客进行个性化，丰富功能。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;增加顶部阅读进度条&quot;&gt;&lt;a href=&quot;#增加顶部阅读进度条&quot; class=&quot;headerlink&quot; title=&quot;增加顶部阅读进度条&quot;&gt;&lt;/
      
    
    </summary>
    
      <category term="分享境" scheme="https://oyeblog.com/categories/%E5%88%86%E4%BA%AB%E5%A2%83/"/>
    
    
      <category term="Hexo" scheme="https://oyeblog.com/tags/Hexo/"/>
    
      <category term="Blog" scheme="https://oyeblog.com/tags/Blog/"/>
    
  </entry>
  
  <entry>
    <title>Tensorflow Serving 填坑记</title>
    <link href="https://oyeblog.com/2018/tensorflow_serving/"/>
    <id>https://oyeblog.com/2018/tensorflow_serving/</id>
    <published>2018-07-23T12:20:00.000Z</published>
    <updated>2023-10-22T07:06:32.046Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>　　之前用TensorFlow写了一个基于Bi-LSTM-CRF的临床命名实体识别模型，最近要求把模型部署API，供其他应用调用。本来打算直接用TensorFlow的Model saver和load配合flask框架实现。查询资料的时候发现TensorFlow官方出品了TensorFlow Serving工具可以实现相同的功能，于是尝试安装Serving，并跑通官方示例。在安装和调试过程中出现了诸多问题，记录一下。<a id="more"></a></p></blockquote><h2 id="安装环境"><a href="#安装环境" class="headerlink" title="安装环境"></a>安装环境</h2><p><strong>Ubuntu 16.04</strong><br><strong>Python 3.5</strong></p><h2 id="TensorFlow-Serving-简介"><a href="#TensorFlow-Serving-简介" class="headerlink" title="TensorFlow Serving 简介"></a>TensorFlow Serving 简介</h2><p>　　<strong>Tensorflow Serving</strong> 是面向产品环境开发的机器学习模型的服务系统，具有灵活、高效的特点。能够在保持相同的框架和API的基础上，比较容易地部署新的算法和实验。TensorFlow Serving为模型提供了开箱即用的集成环境，也十分容易扩展到其他类型的模型和数据上。它使用 gRPC 作为接口供外部调用。与此同时，它支持模型热更新与自动模型版本管理，意味着一旦部署 TensorFlow Serving 后，再也不需要为线上服务操心，只需要关心线下模型训练，实现模型版本的迭代更新。<br>参考：<a href="https://www.tensorflow.org/serving/" target="_blank" rel="noopener">https://www.tensorflow.org/serving/</a></p><h2 id="TensorFlow-Serving-安装及示例调试"><a href="#TensorFlow-Serving-安装及示例调试" class="headerlink" title="TensorFlow Serving 安装及示例调试"></a>TensorFlow Serving 安装及示例调试</h2><p>　　安装也是按照<a href="https://www.tensorflow.org/serving/setup" title="官方安装文档" target="_blank" rel="noopener">官方文档</a>的指导进行，在完全装好之后，才反应过来官方给出的是两种不同的安装方式，为了便于后面表述，这里简称为<strong>Bazel</strong>和<strong>PIP</strong>，下面详细介绍两种方式，以及相应的实例调试。</p><h3 id="Bazel安装方式及示例调试"><a href="#Bazel安装方式及示例调试" class="headerlink" title="Bazel安装方式及示例调试"></a>Bazel安装方式及示例调试</h3><ol><li>从github下载Bazel，链接：<a href="https://github.com/bazelbuild/bazel/releases" target="_blank" rel="noopener">https://github.com/bazelbuild/bazel/releases</a>，根据自己的系统选择相应的版本，我选择的版本是 <strong>bazel-0.15.1-installer-linux-x86_64.sh</strong>。</li><li>安装Bazel，应该是用来编译的  <pre><code class="bash">cd ~/Downloadschmod +x bazel-0.5.4-installer-linux-x86_64.sh./bazel-0.5.4-installer-linux-x86_64.sh --user</code></pre>建立环境  <pre><code class="bash">export PATH=&quot;$PATH:$HOME/bin&quot;</code></pre></li><li>安装gRPC（版本&gt;1.0.0），应该是用来开放端口供调用的  <pre><code class="bash">pip install grpcio</code></pre></li><li>安装TensorFlow Serving所需依赖软件包<pre><code class="bash">sudo apt-get update &amp;&amp; sudo apt-get install -y \     automake \     build-essential \     curl \     libcurl3-dev \     git \     libtool \     libfreetype6-dev \     libpng12-dev \     libzmq3-dev \     pkg-config \     python-dev \     python-numpy \     python-pip \     software-properties-common \     swig \     zip \     zlib1g-dev</code></pre><strong>注意</strong>：这一步涉及两条命令<code>sudo apt-get update</code>，这条命令用来更新源地址，以获取最新的软件包。<code>&amp;&amp;</code>的意思是在前一步命令执行成功后，再执行下一条命令，也是就是<code>sudo apt-get install -y XXX</code>，这条命令是用来安装软件包。所以，其实可以将这两条命令分开运行以保证后续build成功，这个ERROR后面再提及。</li><li>用Bazel从源编译安装TensorFlow Serving<pre><code class="bash">git clone https://github.com/tensorflow/servingcd servingbazel build -c opt tensorflow_serving/...</code></pre><strong>注意</strong>：这里我出现了好几次错误，也查阅了好多好多博客文章，也没有解决。然后，决定查阅github issue，查关键词“<strong>libevent</strong>”，最后参考<a href="https://github.com/tensorflow/serving/issues/906" target="_blank" rel="noopener">https://github.com/tensorflow/serving/issues/906</a>里的“<em>The Dockerfile does not have ‘automake’ and ‘libtool’ deb packages listed</em>”，才幡然醒悟，有可能是第4步中的依赖没有安装好，因为之前有个错误以安装“<em>automake</em>”解决了，重新安装好依赖之后，最终解决。这也是我在第4步的注意力提及把两条命令分开运行的原因。</li><li>测试Serving是否安装成功<pre><code class="bash">bazel-bin/tensorflow_serving/model_servers/tensorflow_model_serverbazel test -c opt tensorflow_serving/...</code></pre></li></ol><p>到此，以Bazel安装的方式就结束了，接下来是Serving自带示例的调试，示例代码都在<code>serving/tensorflow_serving/example</code>路径下面，是一个简单的mnist的实现。测试方式也是参考<a href="https://www.tensorflow.org/serving/serving_basic" target="_blank" rel="noopener">官方文档</a>，具体的代码解释就暂时不做了，只负责跑通。  </p><ol><li>把模型导出的路径清空  <pre><code class="bash">rm -rf /tmp/mnist_model</code></pre></li><li>训练并导出模型<pre><code class="bash">&gt;bazel build -c opt //tensorflow_serving/example:mnist_saved_model&gt;bazel-bin/tensorflow_serving/example/mnist_saved_model /tmp/mnist_modelTraining model......Done training!Exporting trained model to /tmp/mnist_modelDone exporting!</code></pre></li><li>部署模型，端口：9000<pre><code class="bash">bazel build -c opt //tensorflow_serving/model_servers:tensorflow_model_serverbazel-bin/tensorflow_serving/model_servers/tensorflow_model_server --port=9000 --model_name=mnist --model_base_path=/tmp/mnist_model/</code></pre></li><li>本地测试模型<pre><code class="bash">bazel build -c opt //tensorflow_serving/example:mnist_clientbazel-bin/tensorflow_serving/example/mnist_client --num_tests=1000 --server=localhost:9000</code></pre>如果出现<code>Inference error rate: 10.5%</code>，则测试成功。</li></ol><h3 id="PIP安装方式及示例调试"><a href="#PIP安装方式及示例调试" class="headerlink" title="PIP安装方式及示例调试"></a>PIP安装方式及示例调试</h3><ol><li>安装tensorflow-serving-api<pre><code class="bash">pip install tensorflow-serving-api</code></pre></li><li>安装ModelSaver<pre><code class="bash">echo &quot;deb [arch=amd64] http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal&quot; | sudo tee /etc/apt/sources.list.d/tensorflow-serving.listcurl https://storage.googleapis.com/tensorflow-serving-apt/tensorflow-serving.release.pub.gpg | sudo apt-key add -sudo apt-get update &amp;&amp; sudo apt-get install tensorflow-model-server</code></pre></li></ol><p>到此，PIP方式的安装就结束了，当然跟Bazel方式一样，gRPC和Serving所需的依赖软件包都需要安装。下面是PIP方式的示例调试。</p><ol><li>训练并导出模型<pre><code class="bash">python3 tensorflow_serving/example/mnist_saved_model.py /tmp/mnist_model</code></pre><strong>注意</strong>：这里使用的是python3，但是<code>mnist_saved_model.py</code>是用python2写的，里面有个<code>xrange</code>，在python3里是不存在，需要改成<code>range</code>，即可以运行成功。</li><li>部署模型，端口：9000<pre><code class="bash">tensorflow_model_server --port=9000 --model_name=mnist --model_base_path=/tmp/mnist_model/</code></pre></li><li>测试模型<pre><code class="bash">python3 tensorflow_serving/example/mnist_client.py --num_tests=1000 --server=localhost:9000</code></pre><strong>注意</strong>:在训练和导出模型、启动server时都没出现错误，在使用client调用server的时候出现与 <a href="https://github.com/tensorflow/serving/issues/387" target="_blank" rel="noopener">https://github.com/tensorflow/serving/issues/387</a> 相同的情况，本来以为是proxy的问题，将proxy取消（命令：unset http_proxy）之后，问题还是存在。<br>于是，再重新阅读了这个issue的讨论，发现一句“<em>Just check on the client side if sudo fixes your problem. Then configure your user permissions accordingly.</em>”，尝试sudo之后，PIP和Bazel的方式都终于调试成功！！！</li></ol><blockquote><p>从这次安装的过程，总结的经验如下：安装的时候需要弄清楚每条命令的含义、目的，才能保证成功；还有就是网上很多教程可能并不准确，而且版本更新较快，很多教程也很容易过时，官方文档和GitHub中的issue是很好的找解决方法的地方。</p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;　　之前用TensorFlow写了一个基于Bi-LSTM-CRF的临床命名实体识别模型，最近要求把模型部署API，供其他应用调用。本来打算直接用TensorFlow的Model saver和load配合flask框架实现。查询资料的时候发现TensorFlow官方出品了TensorFlow Serving工具可以实现相同的功能，于是尝试安装Serving，并跑通官方示例。在安装和调试过程中出现了诸多问题，记录一下。
    
    </summary>
    
      <category term="技术向" scheme="https://oyeblog.com/categories/%E6%8A%80%E6%9C%AF%E5%90%91/"/>
    
    
      <category term="TensorFlow" scheme="https://oyeblog.com/tags/TensorFlow/"/>
    
      <category term="Serving" scheme="https://oyeblog.com/tags/Serving/"/>
    
  </entry>
  
  <entry>
    <title>win10 + python3.6 + tensorflow-gpu1.4.0 + CUDA8.0 + cuDNN v6环境安装</title>
    <link href="https://oyeblog.com/2018/install_tensorflow_gpu/"/>
    <id>https://oyeblog.com/2018/install_tensorflow_gpu/</id>
    <published>2018-01-16T14:44:00.000Z</published>
    <updated>2023-10-22T07:06:32.045Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>之前换了新电脑，一直没来得及把TensorFlow装上，电脑是惠普 战66，有独显MX150，所以这次安装的是gpu版，网上找了好些个教程，最后在自己摸索中，把环境装好了，记录一下。<br><a id="more"></a></p></blockquote><h3 id="安装python3-6"><a href="#安装python3-6" class="headerlink" title="安装python3.6"></a>安装python3.6</h3><p>这一步实在没什么好说的。</p><h3 id="安装TensorFlow-gpu-1-4-0"><a href="#安装TensorFlow-gpu-1-4-0" class="headerlink" title="安装TensorFlow-gpu 1.4.0"></a>安装TensorFlow-gpu 1.4.0</h3><p>这里我之前本来想安装最新的1.5.0rc1版本，但是这个版本需要CUDA 9.0，我不想重新下载CUDA了，所以选择了<strong>1.4.0</strong>版本。具体的报错信息如下：</p><pre><code>ImportError: Could not find &#39;cudart64_90.dll&#39;. TensorFlow requires that this DLL be installed in a directory that is named in your %PATH% environment variable. Download and install CUDA 9.0 from this URL: https://developer.nvidia.com/cuda-toolkit</code></pre><p>这一步记得选择正确的版本，因为我的是python3.6、Windows 64位、gpu版本，所有选择下载<a href="https://pypi.python.org/pypi/tensorflow-gpu/1.4.0" target="_blank" rel="noopener">tensorflow_gpu-1.4.0-cp36-cp36m-win_amd64.whl</a>。<br>使用命令<code>pip install tensorflow_gpu-1.4.0-cp36-cp36m-win_amd64.whl</code> 安装</p><h3 id="安装CUDA-8-0"><a href="#安装CUDA-8-0" class="headerlink" title="安装CUDA 8.0"></a>安装CUDA 8.0</h3><p>这一步也要选对版本，我之前看了好多教程，都是说要去<a href="https://developer.nvidia.com/cuda-downloads" target="_blank" rel="noopener">https://developer.nvidia.com/cuda-downloads</a>下载，然而我下载的时候网站正在维护，然后是在<a href="https://developer.nvidia.com/cuda-toolkit-archive" target="_blank" rel="noopener">https://developer.nvidia.com/cuda-toolkit-archive</a>这个网站下载的，这个网站提供所有版本的CUDA下载链接，我本来想下载CUDA Toolkit 8.0 GA2这个版本，但是local版的链接失效，所以最后下载了<strong>CUDA Toolkit 8.0 GA1</strong>。双击<code>.exe</code>文件安装成功后，可以在cmd里用命令<code>nvcc -V</code>测试，如果出现版本号就说明安装成功。</p><h3 id="安装cuDNN-v6"><a href="#安装cuDNN-v6" class="headerlink" title="安装cuDNN v6"></a>安装cuDNN v6</h3><p>本来是想安装v7版本的，但是TensorFlow 1.4好像需要用v6版本的，所以这里安装的版本是<strong>cuDNN v6.0 (April 27, 2017), for CUDA 8.0</strong>。<br>cuDNN的下载地址是<a href="https://developer.nvidia.com/rdp/cudnn-download" target="_blank" rel="noopener">https://developer.nvidia.com/rdp/cudnn-download</a>，这个网址提供所有版本的cuDNN下载，但是需要先注册，我选择的版本是<strong>cuDNN v6.0 (April 27, 2017), for CUDA 8.0</strong>，下载完成后是一个压缩包。解压缩之后是三个文件夹<code>/bin, /include, /lib</code>，将这三个文件夹复制到之前CUDA的安装目录下，我的是默认安装目录<code>C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v8.0</code>。</p><p>至此，整个安装过程就结束了，可以<code>import tensorflow as tf</code>测试一下，我这边已经成功了。</p><p>总结下来，就像一些教程里说的，版本真的非常重要，需要保证版本兼容才能安装成功，比如我这个环境就是<strong>win10+python3.6+tensorflow-gpu1.4.0+CUDA8.0+cuDNN v6</strong>。其他的版本我这里就没有探索了，之后版本升级，我应该还要继续更新，到时候做个版本适配总结。</p><p>参考：<br><a href="http://blog.csdn.net/vera__zhang/article/details/78531550" target="_blank" rel="noopener">http://blog.csdn.net/vera__zhang/article/details/78531550</a><br><a href="http://blog.csdn.net/u010099080/article/details/53418159" target="_blank" rel="noopener">http://blog.csdn.net/u010099080/article/details/53418159</a></p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;之前换了新电脑，一直没来得及把TensorFlow装上，电脑是惠普 战66，有独显MX150，所以这次安装的是gpu版，网上找了好些个教程，最后在自己摸索中，把环境装好了，记录一下。&lt;br&gt;
    
    </summary>
    
      <category term="分享境" scheme="https://oyeblog.com/categories/%E5%88%86%E4%BA%AB%E5%A2%83/"/>
    
    
      <category term="Tensorflow" scheme="https://oyeblog.com/tags/Tensorflow/"/>
    
      <category term="Install" scheme="https://oyeblog.com/tags/Install/"/>
    
  </entry>
  
  <entry>
    <title>2017年终总结</title>
    <link href="https://oyeblog.com/2018/2017_summary/"/>
    <id>https://oyeblog.com/2018/2017_summary/</id>
    <published>2018-01-07T12:50:00.000Z</published>
    <updated>2023-10-22T07:17:02.011Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>2017悄然过去，在犹豫徘徊中迎来了2018，回顾过去一年，收获与遗憾同在，有坚持、有放弃、有惊喜、有感动。总结2017，展望更好的2018。<br><a id="more"></a></p></blockquote><p>2017年初，我应该还在继续完成和肿瘤医院合作的超声报告和病理报告的一致性分析的项目，处于项目中期，而且这个项目和我的毕业设计十分相关，绝大部分的精力都放在上面了。中间项目初步完成，回家过年了。年后基于医生的反馈又把一些细节优化，完成最后的结果整理，将可分析的数据交给医生，一起合作完成了一篇中文文章，目前在审稿中。</p><p>上面事情还在进行之中的时候，收到一个私活邀请，是要完成一个中医科室病人数据库的建立，当时的设想是基于<a href="https://www.ohdsi.org/" target="_blank" rel="noopener">OHDSI</a>的数据标准和已有的可视化框架来完成，所以当时对OHDSI也初步了解了一下。后面因为需要注册公司才能和医院签合同，而后面在和中间人谈利益职责分配时没谈拢，也考虑到这种公司注册存在一定的风险因素，所以最终放弃了。</p><p>再接下来，4、5月份左右，收到CCKS2017竞赛的消息，关于这个竞赛可以参见我之前的文章：<a href="http://oyeblog.com/2017/ccks2017/">参加CCKS2017 Task_2有感</a>。我从样例数据放出，开始前期数据预处理的工作，到后面学习深度学习、实现基础算法，看文章优化算法，调参数，最终的提交结果是我们得到第4。而在后续的阶段还需要写作成文，修改、提交论文。后面文章被大会接收，并被邀请去参加在成都的会议，收获还是挺大的。但是也因为这些事情，我大学以来第一次暑假没有回家，我还是觉得这些都是值得的。对了，这中间我还把blog搞起来了，也才有了今天写总结的地方，也算一点小成就吧。</p><p>这学期一开学，9月份，到了该找工作的时节了，学校里宣讲会多了起来，西装革履也多了起来，且不说是不是像房产中介，给人感觉倒是耳目一新吧，以至于后面我在找工作之前也去买了一套，后面发现咱面试的公司，并不需要这。我第一家面试的公司是业内一家初创企业，名字就不说了，由于他们的创始人在我们同事之间有点名气，我自己也看过几篇他的文章，印象还不错。然而他们人力发邮件时就把我的名字写错，面试当天先给了我一份大概是面试医学生的试题来做，当天他们也正好在进行办公室小装修，面试期间换了好几次房间，当然应该是自己表现不好，后面杳无音信。这次之后我开始正式进入找工作状态，下了好几个APP，修改了好几次简历，疯狂投，收到的反馈却不是很多，面试过给大型企业做外包的、外企、初创企业，收到好几个实习offer，也拿到了还比较满意的正式offer。后面因为有文章要写，找工作的事情暂告一段落，之后应该还会再努力找找。</p><p>在找工作期间，其实也一直在纠结着自己到底想要的是什么，到底要走什么样的路，在反复思索中，还有另一项任务，写文章。学院规定，要拿学位证必须得有文章，而我考虑的落户上海必须得有学位证，而且必须在我毕业的时候拿到，留给自己的时间其实并不多了，修修改改，终于在今天把文章投了，希望好的运气延续下来，让我顺利发表吧。</p><p>这一年还有的其他收获：足迹踏进了北京、成都、宁波、江苏；大学以来第一次拿奖学金；光荣转正，成为正式的共产党员，虽然我党在敌对分子的造谣诽谤中风雨飘摇，我还是充满信心哈；在磕磕碰碰中，和我的逗比又走过了一年的岁月，相互嫌弃又相互依靠。这一年唯一的遗憾：没能实现我进入研究生时的梦想，以第一作者发表一篇SCI。</p><p>其实我并不善于总结，总是会遗忘一些事情，脚步也不够坚定，我曾经一度轻视、看不起的某些人，现在渐渐发现他们的观念、阅历也许在我之上，至少在选择豁达这一项上，他们要强于我。我一直都不知道自己想要的是什么，所以什么都想要，而什么都停留在要到了的水平。新的一年了，我对自己的期待就是，摆脱他人的期待，找到真正的自己，完成从学生到社会人的过渡。</p><p><img src="https://cdn.jsdelivr.net/gh/oye93/oyeImg/blog/post/hug_1.jpg" alt></p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;2017悄然过去，在犹豫徘徊中迎来了2018，回顾过去一年，收获与遗憾同在，有坚持、有放弃、有惊喜、有感动。总结2017，展望更好的2018。&lt;br&gt;
    
    </summary>
    
      <category term="自言语" scheme="https://oyeblog.com/categories/%E8%87%AA%E8%A8%80%E8%AF%AD/"/>
    
    
      <category term="Personal Summary" scheme="https://oyeblog.com/tags/Personal-Summary/"/>
    
  </entry>
  
  <entry>
    <title>Reinforcement Learning for Relation Classification from Noisy Data</title>
    <link href="https://oyeblog.com/2017/paper_1_RL/"/>
    <id>https://oyeblog.com/2017/paper_1_RL/</id>
    <published>2017-12-12T11:11:00.000Z</published>
    <updated>2023-10-22T07:17:02.026Z</updated>
    
    <content type="html"><![CDATA[<p>这篇文章是Reinforcement Learning在NLP方面的应用，具体是用在有噪音训练集的实体关系分类问题上，已经被AAAI 2018录用，作者之前也在<a href="https://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247486440&amp;idx=2&amp;sn=d43b6799f62337ec19f405bed1cd0138&amp;chksm=96e9d468a19e5d7ea1cd673045eaa57dd8f5bee49074b6ef0f4fc64558e4626a0461867b216b&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">PaperWeekly</a>分享过了，最近一个前同事提到Reinforcement Learning应该会是NLP的下一个热点，想想应该也是这么回事，就像之前的Attention机制一样。因此在了解了Reinforcement Learning的基本概念之后，又把这篇文章细读一遍。<br><a id="more"></a><br>链接：<a href="http://aihuang.org/static/papers/AAAI2018Denoising.pdf" target="_blank" rel="noopener">Reinforcement Learning for Relation Classification from Noisy Data</a></p><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>现有的关系分类方法主要依赖于<strong>距离监督（distant supervision）</strong>，主要的假设是假如有一组句子都提到了一个实体对，那么这些句子就都描述了这个实体对的一个关系（<em>我觉得可能就是和共现差不多吧</em>）。这些方法一般都是在句子集的层面进行分类，而不能把关系和句子一一对应起来，造成这个问题的主要原因是标注数据集里有噪声数据。作者在这篇文章里提出了一种新的方法，这种方法可以在有噪声的数据上做到句子层面的关系分类。这个模型有两个组成部分：<strong>实例选取器（instance selector）</strong>和<strong>关系分类器（relation classifier）</strong>。实例选取器用强化学习的方法选取高质量的句子，并传递给关系分类器，关系分类器在句子层面作出预测，并反馈给实例选取器。这两个模块共同训练、优化。实验结果表明这样的方法可以有效处理训练数据中的噪声，从而在句子层面的关系分类上取得更好的performance。</p><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>为解决标注数据含噪声的问题，现有的Bag Level的关系分类方法有两个缺陷：1. 不能处理句子级别的关系分类； 2. 假如‘Bag’中的所有句子都是噪声句子，对模型的影响很大。下图是对第一个缺陷的解释说明，<em>‘Bag-Level’</em>也就是relation的label是给Bag的，这一组句子包含同一个实体对，描述了哪些关系，而<em>‘Sentence-Level’</em>的relation label是给Sentence的，也就是对每一个句子指定一个关系类型。造成第二个缺陷的原因是，即使‘Bag’中所有句子都是噪声（也就是这些句子都没有描述某个关系），模型也会选取至少一个句子，认为选取的句子描述了某个关系，进而基于这些句子进行模型训练，而且假如标注集只是简单基于距离监督得到，这样的情况是很常见的，因此这样训练得到的分类模型的performance肯定会下降。</p><p><img src="https://cdn.jsdelivr.net/gh/oye93/oyeImg/blog/post/paper_1_example.JPG" alt></p><p>为了解决上述的两个缺陷，作者提出加入实例选取器，并将其转换成一个强化学习问题来解决。因为这个选取器有以下两个特征：首先，这个句子选取是一个反复试错（<em>trial-and-error-search</em>）的过程，需要从分类器得到对选取的句子质量的反馈（<em>reward</em>）；其次，上述的反馈只能在整个挑选过程结束之后才能得到，因此反馈是滞后（<em>delayed</em>）的。这两点都非常符合强化学习的特点。</p><h2 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h2><p><img src="https://cdn.jsdelivr.net/gh/oye93/oyeImg/blog/post/paper_1_model.JPG" alt></p><p>上图是整个模型的框架，由Instance Selector和Relation Classifier两部分组成，下面具体介绍两部分。</p><h3 id="Instance-Selector"><a href="#Instance-Selector" class="headerlink" title="Instance Selector"></a>Instance Selector</h3><p>因为Instance Selector是当作强化学习问题处理，因此policy function的更新会滞后，为了加快更新速度，作者采用了把所有句子分成$N$个Bag的做法，即$B={B^1, B^2,\cdots, B^N}$。对于每个$B^k$，都包含同一个实体对，而且标注的关系都是$r^k$，虽然这个标注可能是有噪声的（不准确的）。之后的训练都是以一个Bag为单位进行操作。<br>下面就要介绍作为强化学习，<strong>State</strong>、<strong>Action</strong>、<strong>Reward</strong>的定义。  </p><ul><li><strong>State</strong> State $s_i$ 包含了以下三部分信息：1.当前句子的向量表示，这个向量表示由关系分类器里CNN的非线性输出层得到；2.被选的句子集合的矩阵表示，这个由被选句子的向量表示取平均得到；3.句子中实体对的矩阵表示，这个从预训练的知识图谱embeddings得到，<em>这个embeddings是在Freebase上采用TransE模型训练得到</em>。</li><li><strong>Action</strong> action $a_i \in {0, 1}$表示是否应该选取第$i$个句子，$a_i$的取值由<em>policy function</em>得到，具体定义如下：<br>$\pi_\Theta(s_i, a_i) = a_i\sigma(W*F(s_i)+b)+(1-a_i)(1-\sigma(W*F(s_i)+b))$<br>这里的$\sigma(.)$是sigmoid函数。</li><li><strong>Reward</strong> reward由基于CNN的分类器反馈得到，计算所选的句子集合$\hat B$的likelihood，<font color="red">假设所选的句子集合是空集，则用所有句子的平均likelihood来计算，这应该是文章能够有效选出噪声数据的关键之一。</font></li></ul><h3 id="Relation-Classifier"><a href="#Relation-Classifier" class="headerlink" title="Relation Classifier"></a>Relation Classifier</h3><p>文章用的分类模型比较简单，也是目前效果比较好的CNN，包括输入层，卷积层，max-pooling层。</p><ul><li><strong>输入层</strong> 对于每个词的表示分为两部分，一部分是word2vec训练得到的embedding，另一部分是position embedding，这个position embedding其实是两个固定长度的向量，分别用来表示某个词到关系里的两个实体的距离，具体可以参考<a href="http://www.nlpr.ia.ac.cn/cip/liukang.files/camera_coling2014_final.pdf" target="_blank" rel="noopener">中科院这篇文章</a>。</li><li><strong>参数设置</strong>  </li></ul><table><thead><tr><th style="text-align:center">para</th><th style="text-align:center">value</th></tr></thead><tbody><tr><td style="text-align:center">word embedding</td><td style="text-align:center">50</td></tr><tr><td style="text-align:center">position embedding</td><td style="text-align:center">5</td></tr><tr><td style="text-align:center">learning rate</td><td style="text-align:center">0.02</td></tr><tr><td style="text-align:center">dropout</td><td style="text-align:center">0.5</td></tr><tr><td style="text-align:center">convolution window</td><td style="text-align:center">3</td></tr></tbody></table><h2 id="试验"><a href="#试验" class="headerlink" title="试验"></a>试验</h2><ul><li><strong>数据集</strong> 数据集来自<a href="https://link.springer.com/chapter/10.1007%2F978-3-642-15939-8_10" target="_blank" rel="noopener">New York Times (NYT)</a>，里面包含了39528个不重复的实体和53个不重复的关系类别，具体数据如下：</li></ul><table><thead><tr><th style="text-align:center"></th><th style="text-align:center">sentence</th><th style="text-align:center">entity pairs</th><th style="text-align:center">relation facts</th></tr></thead><tbody><tr><td style="text-align:center">training set</td><td style="text-align:center">522611</td><td style="text-align:center">281270</td><td style="text-align:center">18252</td></tr><tr><td style="text-align:center">test set</td><td style="text-align:center">172448</td><td style="text-align:center">96678</td><td style="text-align:center">1950</td></tr></tbody></table><ul><li><strong>评价方式</strong> 因为本身数据集是有噪音的，所以作者随机选取了<strong>300</strong>个句子，人工标注，然后在这些句子上做评测，评测包括Accuracy和Macro F-value。设定的baseline包括：CNN、CNN+Max（每个bag里选一个认为正确的句子）、CNN+ATT（加入attention机制，降低噪声数据的权重）。</li></ul><h3 id="训练过程"><a href="#训练过程" class="headerlink" title="训练过程"></a>训练过程</h3><p><img src="https://cdn.jsdelivr.net/gh/oye93/oyeImg/blog/post/paper_1_training_process.PNG" alt title="训练过程"><br>ALGORITHM 1描述的是整体训练过程，也就是先预训练CNN分类模型，使得$log p(r_i|x_i)$最大，然后固定CNN分类器，预训练policy network，最后联合训练两个模型直至收敛。<br>ALGORITHM 2描述的是具体怎么实现联合训练，对于每一次的epoch，分为N个word bag，对于每个$B_i$，在计算完reward之后实例选取器的参数要更新一次，而CNN分类器的参数只有在整个epoch结束才会更新。</p><h3 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h3><p><font color="red">因为后两个模型是bag level的，所以在评价的时候是把一个句子当成一个bag来处理的</font>，最终结果如下：<br><img src="https://cdn.jsdelivr.net/gh/oye93/oyeImg/blog/post/paper_1_result.PNG" alt><br>可以看出文章的模型取得最好的performance，而且句子层次的模型相比较于bag层次的模型，在这个评测中表现更好，这也是理所当然。</p><h3 id="附加分析"><a href="#附加分析" class="headerlink" title="附加分析"></a>附加分析</h3><p>分别对实例选取器和关系分类器作了分析：</p><ol><li>分析加入实例选取器是否对performance提高有帮助（方法：在原始数据和选取出来的数据上分别训练模型）。</li><li>评价了选取器的accuracy（方法：随机选取300个句子，人工判断，最终的accuracy达到(54+177)/300=74%）。</li><li>比较了强化学习机制和贪婪机制（greedy selection）之间的差异（方法：所谓贪婪机制就是<strong>把强化学习机制改成选取CNN中likelihood最大的N个句子，当然这个N与强化学习机制选出的句子数目一致</strong>）。</li><li>验证选取器是否能区分出那些全是噪声数据的bag（方法：随机选取100个模型认为是全噪声的bag，其中有<strong>86%</strong>真的是全噪声的bag，可以证明模型把绝大多数的全噪声bag过滤了）。</li></ol><h2 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h2><ol><li>第一次阅读强化学习用在NLP上的文献，大致了解强化学习的基本思想，看到强化学习在NLP领域是有所作为的。</li><li>模型的State表示是由3部分组成，分别包含句子、句子集合、实体对的信息，这个State表示是否可以改变，是不是越复杂越好，包含的信息越多越好，这些应该会在下面的工作中有探索。</li><li>本篇文章设定的Action比较简单，但是这个Action确实是结合实际需要提出的，我不太明白是否Action设定更加复杂之后会不会对模型的performance有影响。</li><li>这篇工作是基于噪声数据做的，现在NLP在实际应用中，标注数据的不足、质量不高是比较大的问题，假设我们能用比较简单但是准确率不太高的方式预标注，再加入强化学习机制做模型训练，也许可以解决标注不足的问题。</li><li>可以探索更多能够加入强化学习机制的NLP任务，而不是仅限于噪声数据筛选这一项，比如本文同实验室的另一篇AAAI 2018的文章<a href="http://aihuang.org/static/papers/AAAI2018_ClassifyAndStructure.pdf" target="_blank" rel="noopener">Learning Structured Representation for Text Classification via Reinforcement Learning</a>，这篇文章也是要解决文本分类问题，但是角度又不一样了，是用Reinforcement Learning学习<strong>结构化表示</strong>来提高分类效果，而在强化学习上又分为两种：删去非关键词和切分词组，具体可以查看文章。</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这篇文章是Reinforcement Learning在NLP方面的应用，具体是用在有噪音训练集的实体关系分类问题上，已经被AAAI 2018录用，作者之前也在&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;amp;mid=2247486440&amp;amp;idx=2&amp;amp;sn=d43b6799f62337ec19f405bed1cd0138&amp;amp;chksm=96e9d468a19e5d7ea1cd673045eaa57dd8f5bee49074b6ef0f4fc64558e4626a0461867b216b&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;PaperWeekly&lt;/a&gt;分享过了，最近一个前同事提到Reinforcement Learning应该会是NLP的下一个热点，想想应该也是这么回事，就像之前的Attention机制一样。因此在了解了Reinforcement Learning的基本概念之后，又把这篇文章细读一遍。&lt;br&gt;
    
    </summary>
    
      <category term="文献库" scheme="https://oyeblog.com/categories/%E6%96%87%E7%8C%AE%E5%BA%93/"/>
    
    
      <category term="NLP" scheme="https://oyeblog.com/tags/NLP/"/>
    
      <category term="Deep Learning" scheme="https://oyeblog.com/tags/Deep-Learning/"/>
    
      <category term="Paper" scheme="https://oyeblog.com/tags/Paper/"/>
    
      <category term="Relation Classification" scheme="https://oyeblog.com/tags/Relation-Classification/"/>
    
      <category term="Reinforcement Learning" scheme="https://oyeblog.com/tags/Reinforcement-Learning/"/>
    
  </entry>
  
  <entry>
    <title>Semi-supervised sequence tagging with bidirectional language models</title>
    <link href="https://oyeblog.com/2017/paper_0_LM/"/>
    <id>https://oyeblog.com/2017/paper_0_LM/</id>
    <published>2017-12-04T14:11:00.000Z</published>
    <updated>2023-10-22T07:17:02.026Z</updated>
    
    <content type="html"><![CDATA[<p>最近在看微信推送的时候，有看到一篇推荐文献，发表在ACL2017，跟我之前想做的 <em>通过改进embedding的表示提高NLP任务的表现</em> 方面有点联系的，大致看下来觉得挺不错的，这里在仔细阅读一遍，记录下来。这篇文章不管是在对技术上、研究思想上，还是文章写作方面都有借鉴意义。<br><a id="more"></a><br>链接：<a href="https://arxiv.org/abs/1705.00108" title="arvix" target="_blank" rel="noopener">Semi-supervised sequence tagging with bidirectional language models</a></p><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>预训练的word embedding已经在基于深度学习的NLP模型里广泛应用了，但是word embedding往往只从数量比较少的数据中训练得来。文章提出了将一个双向的语言模型的context embedding引入序列标注任务中，在NER和chunking两个任务上进行了实验，发现context embedding的引入可以提高performance，并且与其他的某些transfer或者joint learning，以及某些引入附加信息的方法相比，能得到更好的performance。</p><h2 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h2><p><img src="https://cdn.jsdelivr.net/gh/oye93/oyeImg/blog/post/TagLM_1.JPG" alt title="Overview"><br>上图是整个模型的概览，左边是一个比较基本的Bi-RNN-CRF的序列标注模型，也可以参考<a href="https://arxiv.org/abs/1603.01354" target="_blank" rel="noopener">End-to-end sequence labeling via bi-directional LSTM-CNNs-CRF</a>，这个模型最开始输入的character representation也是由两部分组成，一部分是形态学特征信息，$c_k$，另一部分是预训练的word embedding，$w_k$。接着是一个正向一个反向RNN，最后接一个CRF层对标签进行优化。<br>语言模型（Language Model）本来是用来计算一个序列 $(t_1, t_2, \cdots, t_N)$ 的可能性，即：  </p><p>$p(t_1, t_2, \cdots, t_N) = \prod_{k=1}^N{p(t_k|t_1, t_2, \cdots, t_{k-1})}$  </p><p>基于以上的基本假设，构建深度神经网络，最后得到一个固定长度的向量，$h_f^{LM}$。上面公式其实是得到一个正向的表示，考虑到既然可以获得正向上下文信息，作者又训练了一个反向的语言模型，也得到一个固定长度的向量，$h_b^{LM}$。主要的计算公式如下：  </p><p>$p(t_1, t_2, \cdots, t_N) = \prod_{k=1}^N{p(t_k|t_{k+1}, t_{k+2}, \cdots, t_N)}$  </p><p>最后两个语言模型的embedding，$h_f^{LM}$，$h_b^{LM}$，串联组成一个向量$h^{LM}$。<strong>这里的两个向量完全是独立训练得到，没有共享参数。</strong>在得到$h^{LM}$后，作者将这个向量和Bi-RNN第一层的输出串联起来当成第二层RNN的输入。 <strong><em>其实，作者也提出了几个方案来做$h^{LM}$和第一层输出的整合，包括1. 串联之后加一个非线性变换；2. 加入类似attention机制，来给$h^{LM}$加上权重。因为直接串联的效果已经比较好了，所以作者并没有实现。</em></strong></p><h2 id="试验"><a href="#试验" class="headerlink" title="试验"></a>试验</h2><p>作者主要在两个任务上做了评测，<strong>CoNLL 2003 NER task</strong>和<strong>CoNLL 2000 Chunking task</strong>。采用的标注方式是<strong>BIOES</strong>。</p><h3 id="训练中的tricks"><a href="#训练中的tricks" class="headerlink" title="训练中的tricks"></a>训练中的tricks</h3><ul><li>Adam optimizer</li><li>用early stopping来防止overfitting，具体策略是：先固定learning rate，在每个epoch训练结束之后，都测试一下开发集上的的performance。假如得到了一个最好的performance，就把learning rate作退火处理（annealing），即降低一个数量级（比如除以10），继续训练5个epoch，再降低一个数量级，继续训练5个epoch就结束训练。<font color="red"><em>我的理解是假如说连续训练5个epoch，再降低learning rate训练5个epoch还没有出现更好的模型，就停止训练。</em></font></li><li>随机种子，训练10次，取F值的平均和标准差</li></ul><h3 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h3><p><img src="https://cdn.jsdelivr.net/gh/oye93/oyeImg/blog/post/TagLM_2.JPG" alt title="Results"><br>从上图可以看出，文章的模型与baseline相比，表现最好，而且加入语言模型embedding，可以显著提高系统performance。</p><h3 id="附加分析"><a href="#附加分析" class="headerlink" title="附加分析"></a>附加分析</h3><ol><li>在模型的哪个模块加入语言模型embedding，输入层，第一层RNN的输出，第二层RNN的输出？   <font color="red">第一层RNN的输出，解释是可能第二层的RNN可以把第一层RNN的任务特殊性的上下文信息和语言模型中通用的上下文信息结合起来考虑。</font></li><li>使用不同的语言模型是否会有影响？  <font color="red">加入反向语言模型更好，比较大的语言模型的size更好，比较大的语料用来训练语言模型更好。</font></li><li>评测数据集大小？  <font color="red">在小的数据集上，加入语言模型后，performance提高更显著。</font></li><li>是不是因为语言模型embedding的加入增加了参数，所以performance更好？<br>通过两个实验：1. 不加LM，只是单纯增加第二层RNN的维度（<strong>没有提及怎么增加这个维度的？</strong>）与加入LM时的维度一致；2. 加LM，但是对维度进行压缩（<strong>同样没有提及怎么压缩这个维度的？</strong>），使得与不加LM的基础模型维度一致。<font color="red">结论是：单纯增加维度是没用的，压缩维度会稍微降低performance。</font></li><li>语言模型可以跨领域吗？  <font color="red">将新闻领域训练出来的语言模型，用到科学出版物的任务上，也有performance的提升。</font></li></ol><h2 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h2><ol><li>即使是dropout这么一个参数就有好多选择要不要用，在哪些层要用，用多大，比如在CoNLL 2003 NER的基本模型中，作者就只在GRU的输入上用了25%的dropout；在CoNLL 2000 chunking的基础模型中就在embedding上，LSTM的输入，以及最后一层LSTM的输出上用了50%的dropout。</li><li>对人们比较关心的几个问题都做了附加的分析，让人心服口服，值得学习。</li><li>即使只是对基础模型的一个细小改动，增加一个类型信息（本文是语言模型的上下文信息），如果把实验做的充分，结果显著，也是可以发出来文章的。</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近在看微信推送的时候，有看到一篇推荐文献，发表在ACL2017，跟我之前想做的 &lt;em&gt;通过改进embedding的表示提高NLP任务的表现&lt;/em&gt; 方面有点联系的，大致看下来觉得挺不错的，这里在仔细阅读一遍，记录下来。这篇文章不管是在对技术上、研究思想上，还是文章写作方面都有借鉴意义。&lt;br&gt;
    
    </summary>
    
      <category term="文献库" scheme="https://oyeblog.com/categories/%E6%96%87%E7%8C%AE%E5%BA%93/"/>
    
    
      <category term="NLP" scheme="https://oyeblog.com/tags/NLP/"/>
    
      <category term="Deep Learning" scheme="https://oyeblog.com/tags/Deep-Learning/"/>
    
      <category term="Embedding" scheme="https://oyeblog.com/tags/Embedding/"/>
    
      <category term="Paper" scheme="https://oyeblog.com/tags/Paper/"/>
    
  </entry>
  
  <entry>
    <title>Markdown 小技巧</title>
    <link href="https://oyeblog.com/2017/tricks_in_markdown/"/>
    <id>https://oyeblog.com/2017/tricks_in_markdown/</id>
    <published>2017-11-28T12:11:00.000Z</published>
    <updated>2023-10-22T07:13:16.027Z</updated>
    
    <content type="html"><![CDATA[<h2 id="MathJax-公式"><a href="#MathJax-公式" class="headerlink" title="MathJax 公式"></a>MathJax 公式</h2><p>在更新后的Material 1.5.0版本的post中加入了MathJax选项，即可以选择是否启用MathJax公式渲染，具体语法可以参见 <a href="https://www.mathjax.org/" title="MathJax" target="_blank" rel="noopener">MathJax官网</a> 。但是我在渲染公式的时候还是有点问题，记录一下配置过程。<br><a id="more"></a><br>其实只要在post的head里设置<code>mathjax: true</code>就可以了。<strong>而且mathjax这个词是区分大小写的，千万要注意。</strong>如果需要使用需要在两边加上<code>$</code>。下面是常用的一些公式：</p><table><thead><tr><th style="text-align:center">意义</th><th style="text-align:center">格式</th><th style="text-align:center">显示</th></tr></thead><tbody><tr><td style="text-align:center">上标</td><td style="text-align:center"><code>x^y</code></td><td style="text-align:center">$x^y$</td></tr><tr><td style="text-align:center">多上标</td><td style="text-align:center"><code>x^{y^z}</code></td><td style="text-align:center">$x^{y^z}$</td></tr><tr><td style="text-align:center">下标</td><td style="text-align:center"><code>x\_i</code></td><td style="text-align:center">$x_i$</td></tr><tr><td style="text-align:center">希腊字母</td><td style="text-align:center"><code>\alpha</code></td><td style="text-align:center">$\alpha$</td></tr><tr><td style="text-align:center">希腊字母</td><td style="text-align:center"><code>\beta</code></td><td style="text-align:center">$\beta$</td></tr><tr><td style="text-align:center">希腊字母</td><td style="text-align:center"><code>\Delta</code></td><td style="text-align:center">$\Delta$</td></tr><tr><td style="text-align:center">无穷</td><td style="text-align:center"><code>\infty</code></td><td style="text-align:center">$\infty$</td></tr><tr><td style="text-align:center">点</td><td style="text-align:center"><code>\cdot</code>, <code>\cdots</code></td><td style="text-align:center">$\cdot$, $\cdots$</td></tr><tr><td style="text-align:center">运算符</td><td style="text-align:center"><code>\times</code>, <code>\div</code>, <code>\lt</code>, <code>\gt</code>, <code>\le</code>, <code>\ge</code>, <code>\neq</code></td><td style="text-align:center">$\times$, $\div$, $\lt$, $\gt$, $\le$, $\ge$, $\neq$</td></tr><tr><td style="text-align:center">求和</td><td style="text-align:center"><code>\sum\_{i=0}^n</code></td><td style="text-align:center">$\sum_{i=0}^n$</td></tr><tr><td style="text-align:center">分数</td><td style="text-align:center"><code>\frac{x}{y}</code></td><td style="text-align:center">$\frac{x}{y}$</td></tr><tr><td style="text-align:center">开根号</td><td style="text-align:center"><code>\sqrt 3</code></td><td style="text-align:center">$\sqrt 3$</td></tr><tr><td style="text-align:center">开根号</td><td style="text-align:center"><code>\sqrt[3] 3</code></td><td style="text-align:center">$\sqrt[3] 3$</td></tr><tr><td style="text-align:center">极限</td><td style="text-align:center"><code>\lim\_{x \to 0}</code></td><td style="text-align:center">$\lim_{x \to 0}$</td></tr><tr><td style="text-align:center">分情况</td><td style="text-align:center"><code>f: \begin {cases} x, x&gt;0 \\\ \\\ -x, x&lt;0 \end {cases}</code></td><td style="text-align:center">$f: \begin {cases} x, x&gt;0 \\ \\ -x, x&lt;0 \end {cases}$</td></tr><tr><td style="text-align:center">连等式</td><td style="text-align:center"><code>\begin{eqnarray} \sum_{ k = 1 }^{ n } k^2 = \overbrace{ 1^2 + 2^2 + \cdots + n^2 }^{ n } = \frac{ 1 }{ 6 } n ( n + 1 ) ( 2n + 1 ) \end{eqnarray}</code></td><td style="text-align:center">$\begin{eqnarray} \sum_{ k = 1 }^{ n } k^2 = \overbrace{ 1^2 + 2^2 + \cdots + n^2 }^{ n } = \frac{ 1 }{ 6 } n ( n + 1 ) ( 2n + 1 ) \end{eqnarray}$</td></tr></tbody></table><p>参考：<a href="http://daniellaah.github.io/2016/Mathmatical-Formula-within-Markdown.html" target="_blank" rel="noopener">http://daniellaah.github.io/2016/Mathmatical-Formula-within-Markdown.html</a></p><h2 id="链接中含有"><a href="#链接中含有" class="headerlink" title="链接中含有()"></a>链接中含有()</h2><p>正常的链接格式为： <code>[link text](URL &#39;title text&#39;)</code>，但是假如<code>URL</code>中含有<code>()</code>，比如<code>https://en.wikipedia.org/wiki/Rectifier_(neural_networks)</code>。如果还是用正常的链接格式，就会多出来一个括号，而且链接也是错误的，像下面这样：</p><p><a href="https://en.wikipedia.org/wiki/Rectifier_(neural_networks" target="_blank" rel="noopener">例子</a>)</p><p>然后可以采用<strong>参考式</strong>的形式：<br>1.定义链接文字：  </p><pre><code class="shell">[link text][id]</code></pre><p>其中<code>id</code>可以是数字、字母、标点等的唯一标识符。</p><p>2.定义链接网址：  </p><pre><code class="shell">[id]: URL &quot;title&quot;</code></pre><p>其中<code>URL</code>必须加上<code>http</code>或者<code>https</code>，这个内容可以放在文件的任意位置。  </p><p>3.省略<code>id</code>，直接用<code>link text</code>来指针链接：  </p><pre><code class="shell">[link text][][link text]: URL &quot;title&quot;</code></pre><p>这个方式还有一个好处就是可以在不同的地方调用同一个链接。</p><p>当然，还学到一种超链接的表示形式 <strong>自动链接</strong> ，即用<code>&lt;&gt;</code>将URL或者邮箱地址括起来，就能将URL直接转换成超链接文字，非常方便啊。</p><p>参考：<a href="http://xianbai.me/learn-md/article/syntax/links.html" target="_blank" rel="noopener">http://xianbai.me/learn-md/article/syntax/links.html</a></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;MathJax-公式&quot;&gt;&lt;a href=&quot;#MathJax-公式&quot; class=&quot;headerlink&quot; title=&quot;MathJax 公式&quot;&gt;&lt;/a&gt;MathJax 公式&lt;/h2&gt;&lt;p&gt;在更新后的Material 1.5.0版本的post中加入了MathJax选项，即可以选择是否启用MathJax公式渲染，具体语法可以参见 &lt;a href=&quot;https://www.mathjax.org/&quot; title=&quot;MathJax&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;MathJax官网&lt;/a&gt; 。但是我在渲染公式的时候还是有点问题，记录一下配置过程。&lt;br&gt;
    
    </summary>
    
      <category term="技术向" scheme="https://oyeblog.com/categories/%E6%8A%80%E6%9C%AF%E5%90%91/"/>
    
    
      <category term="Markdown" scheme="https://oyeblog.com/tags/Markdown/"/>
    
  </entry>
  
  <entry>
    <title>Excel小技巧</title>
    <link href="https://oyeblog.com/2017/excel_tricks/"/>
    <id>https://oyeblog.com/2017/excel_tricks/</id>
    <published>2017-11-27T16:00:00.000Z</published>
    <updated>2023-10-22T07:17:02.026Z</updated>
    
    <content type="html"><![CDATA[<p>我自己之前在做某些Excel操作时，有些技巧是百度之后才学来的，特地分享一波。</p><h2 id="数字转文本出现“小数E-12”"><a href="#数字转文本出现“小数E-12”" class="headerlink" title="数字转文本出现“小数E+12”"></a>数字转文本出现“小数E+12”</h2><p><em>figure 1</em>里D列是长数值格式，转成<em>figure 2</em>中的文本格式后出现“小数E+12”的格式，可以像<em>figure 3</em>中一样通过“数据-分列-下一步-下一步”，把“列数据格式”设置成“文本”，然后“完成”，即可转为<em>figure 4</em>中的样式。</p><p><img src="https://cdn.jsdelivr.net/gh/oye93/oyeImg/blog/post/excel_int2string_1.JPG" alt title="figure 1"><br><img src="https://cdn.jsdelivr.net/gh/oye93/oyeImg/blog/post/excel_int2string_2.JPG" alt title="figure 2"><br><img src="https://cdn.jsdelivr.net/gh/oye93/oyeImg/blog/post/excel_int2string_3.JPG" alt title="figure 3"><br><img src="https://cdn.jsdelivr.net/gh/oye93/oyeImg/blog/post/excel_int2string_4.JPG" alt title="figure 4"></p><p>参考：<a href="https://wenku.baidu.com/view/7ebc09fdf78a6529657d5338.html" target="_blank" rel="noopener">https://wenku.baidu.com/view/7ebc09fdf78a6529657d5338.html</a></p><h2 id="日期格式转特定文本格式"><a href="#日期格式转特定文本格式" class="headerlink" title="日期格式转特定文本格式"></a>日期格式转特定文本格式</h2><p>如下图，需要将左侧的日期格式转换成右边连写的文本格式，可以利用公式：</p><pre><code class="python">=text(A2,&quot;yyyymmdd&quot;)</code></pre><p>其中<code>yyyymmdd</code>是需要定义的日期文本格式，也可以加入时、分、秒等信息，比如<code>yyyymmddhhmmss</code>就会生成“20171020141212”这样的文本，<code>yyyymmdd hh:mm:ss</code>就会生成“20171020 14:12:12”这样。<br>在转成文本格式之后，可能还会在文本末尾加上后缀等等，用<code>&amp;</code>将后缀加在文本后就可以了，比如<code>=text(A2,&quot;yyyymmdd&quot;)&amp;&quot;001&quot;</code>就是在日期后加上<code>001</code>。</p><p><img src="https://cdn.jsdelivr.net/gh/oye93/oyeImg/blog/post/excel_5.jpg" alt></p><p>参考：<a href="http://blog.sina.com.cn/s/blog_598ae3e30100a4jw.html" target="_blank" rel="noopener">http://blog.sina.com.cn/s/blog_598ae3e30100a4jw.html</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;我自己之前在做某些Excel操作时，有些技巧是百度之后才学来的，特地分享一波。&lt;/p&gt;
&lt;h2 id=&quot;数字转文本出现“小数E-12”&quot;&gt;&lt;a href=&quot;#数字转文本出现“小数E-12”&quot; class=&quot;headerlink&quot; title=&quot;数字转文本出现“小数E+12”
      
    
    </summary>
    
      <category term="技术向" scheme="https://oyeblog.com/categories/%E6%8A%80%E6%9C%AF%E5%90%91/"/>
    
    
      <category term="Excel" scheme="https://oyeblog.com/tags/Excel/"/>
    
  </entry>
  
  <entry>
    <title>不被注意的Python代码规范(2)---语言规范</title>
    <link href="https://oyeblog.com/2017/python_code_rules_2/"/>
    <id>https://oyeblog.com/2017/python_code_rules_2/</id>
    <published>2017-11-16T11:30:00.000Z</published>
    <updated>2023-10-22T07:06:32.046Z</updated>
    
    <content type="html"><![CDATA[<p>本篇接上一篇：<a href="http://oyeblog.com/2017/python_code_rules_1/">不被注意的Python代码规范(1)—风格规范</a>，主要介绍Pythn代码的语言规范。<br><a id="more"></a><br>主要的参考是<a href="https://google.github.io/styleguide/pyguide.html" target="_blank" rel="noopener">Google Python Style Guide</a>。</p><h3 id="Pylint"><a href="#Pylint" class="headerlink" title="Pylint"></a>Pylint</h3><p>Pylint是一个代码检查工具，用来发现代码bug和不符合规范的地方，默认代码风格是PEP 8。但是目前流行的IDE，如eclipse，pycharm都包含了代码检查功能。</p><h3 id="包"><a href="#包" class="headerlink" title="包"></a>包</h3><p>在代码中通过包的全名来import每个模块，比如：</p><pre><code class="python"># 用全名引用.import sound.effects.echo# 只用模块名引用 (推荐).from sound.effects import echo</code></pre><h3 id="异常处理"><a href="#异常处理" class="headerlink" title="异常处理"></a>异常处理</h3><p>异常处理是被允许的，但是使用的时候要注意。<br>其实之前都没注意过这方面的细节，就会用一个try…except…，上具体代码学习学习：</p><pre><code class="python">try:    # 正常操作    passexcept Exception, expression:     # 可以有多种异常，满足一个就执行异常代码，代码：except(Exception1[, Exception2[, ...]])    print expression    # 获得expression作为错误的具体表述else:    # 如果没有异常发生finally:    # 不管有没有异常发生，都会执行</code></pre><p>还有几个点需要注意的：</p><ul><li>异常的识别比较敏感，会把各种基本异常都识别到，所以尽量指定异常名。</li><li>尽量减少try后面的代码操作，代码越多，异常可能也越多，而让我们catch不到我们关心的异常。</li></ul><h3 id="Lambda函数"><a href="#Lambda函数" class="headerlink" title="Lambda函数"></a>Lambda函数</h3><p>Lambda函数定义的是匿名函数，经常和map()、filter()函数连用。主要好处是可以减少定义那些只用到一次的函数。但是不需要用来代替某些内置函数，比如乘法之类的，又来一波实践代码：</p><pre><code class="python">&gt;&gt;&gt; l = [&#39;foo&#39;, &#39;bar&#39;, &#39;far&#39;]&gt;&gt;&gt; map(lambda x: x.upper(), l)  # 取list中所有词的大写[&#39;FOO&#39;, &#39;BAR&#39;, &#39;FAR&#39;]&gt;&gt;&gt; filter(lambda x: &#39;f&#39; in x, l)  # 筛选list中含有&#39;f&#39;的词[&#39;foo&#39;, &#39;far&#39;]&gt;&gt;&gt; reduce(lambda x, y: x*y, xrange(1,5)) # xrange与range的区别是xrange得到的是一个生成器，reduce函数与map函数差不多，是一个反复调用的功能。24</code></pre><h3 id="装饰器"><a href="#装饰器" class="headerlink" title="装饰器"></a>装饰器</h3><p>本来对装饰器一无所知，之前还和同事讨论过装饰器的一些用法之类的，大致了解了。感觉它的主要目的是提取函数中与本身功能无关的一些代码，进而达到代码重用的目的。我主要是参考<a href="http://python.jobbole.com/82344/" target="_blank" rel="noopener">http://python.jobbole.com/82344/</a>这篇博客，循序渐进地描述了把一个计时功能逐渐转成装饰器的过程，从实现最基本功能，到函数加入参数，再到装饰器加入参数，比较容易理解，很推荐。我把代码重写一遍，加深一下理解。</p><pre><code class="python"># coding:utf8import timedef time_count(func):    s_time = time.time()    func()    e_time = time.time()    time_c = e_time - s_time    print &#39;elapsed time: {} s.&#39;.format(time_c)def func():    print &#39;strat&#39;    time.sleep(0.5)    print &#39;end&#39;time_count(func)  # 以上代码是实现func函数的运行时间计算，但是所有的func函数都要以time_count(func)来运行了。# 以下是用装饰器重写import timedef time_count(func):    def wrapper():        s_time = time.time()        func()        e_time = time.time()        time_c = e_time - s_time        print &#39;elapsed time: {} s.&#39;.format(time_c)    return wrapper@time_countdef func():    print &#39;strat&#39;    time.sleep(0.5)    print &#39;end&#39;func()</code></pre><p>至此，对于Python的代码规范大致总结了一些我个人之前忽略了的方面，也希望之后在coding的过程中进一步应用，写出漂亮的代码。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本篇接上一篇：&lt;a href=&quot;http://oyeblog.com/2017/python_code_rules_1/&quot;&gt;不被注意的Python代码规范(1)—风格规范&lt;/a&gt;，主要介绍Pythn代码的语言规范。&lt;br&gt;
    
    </summary>
    
      <category term="技术向" scheme="https://oyeblog.com/categories/%E6%8A%80%E6%9C%AF%E5%90%91/"/>
    
    
      <category term="Python" scheme="https://oyeblog.com/tags/Python/"/>
    
      <category term="Code" scheme="https://oyeblog.com/tags/Code/"/>
    
      <category term="Standard" scheme="https://oyeblog.com/tags/Standard/"/>
    
  </entry>
  
  <entry>
    <title>不被注意的Python代码规范(1)---风格规范</title>
    <link href="https://oyeblog.com/2017/python_code_rules_1/"/>
    <id>https://oyeblog.com/2017/python_code_rules_1/</id>
    <published>2017-11-14T11:11:00.000Z</published>
    <updated>2023-10-22T07:06:32.045Z</updated>
    
    <content type="html"><![CDATA[<p>最近已经在找工作了，发现各个公司对代码能力要求还是比较高的，谁叫咱还是要干码农的活呢，所以决心改一改自己的代码习惯，写出漂亮的代码。虽说重要的是实现功能，但是代码看起来漂亮，也会让人更舒服吧。下面会记录一些自己以前不太注意到的地方，主要准则还是“有则改之，无则加勉”。主要分成风格规范和语言规范两类。这篇是讲风格规范。<br><a id="more"></a><br>主要的参考是<a href="https://google.github.io/styleguide/pyguide.html" target="_blank" rel="noopener">Google Python Style Guide</a>。</p><h3 id="最长行"><a href="#最长行" class="headerlink" title="最长行"></a>最长行</h3><p>最大行长度不超过80个字符，很长的导入语句或者注释里的URL除外。<br>如果一个文本串的长度超过了80，可以以括号的形式来隐性连接两段短文本，如下：  </p><pre><code class="python">x = (&#39;This will build a very long long long long long &#39;    &#39;long long long long long long string&#39;)</code></pre><h3 id="缩进"><a href="#缩进" class="headerlink" title="缩进"></a>缩进</h3><p>用 <em>4个空格</em> 作为缩进符<br>当字符数大于80了，可以有两种缩进方式选择，一种是超过80的部分，以固定缩进长度表示；第二种是以4个空格作为缩进，但是这种情况下，第一行就不能有任何内容，具体例子如下：  </p><pre><code class="python"># 固定缩进长度foo = long_function_name(var_one, var_two,                var_three, var_four)# 在字典中固定缩进长度foo = {    long_dictionary_key: value1 +                 value2,    ...}# 4个空格缩进，第一行没有任何东西foo = long_function_name(    var_one, var_two, var_three,    var_four)# 在字典中以4个空格缩进foo = {    long_dictionary_key:        value1 + value2,    ...}</code></pre><h3 id="空行"><a href="#空行" class="headerlink" title="空行"></a>空行</h3><p>高级定义（函数或者类）之间空两行，方法定义之间，以及<code>class</code>定义行和第一个方法定义行之间空一行。</p><h3 id="空格"><a href="#空格" class="headerlink" title="空格"></a>空格</h3><p>根据印刷标准的要求，来使用标点周围的空格。<br>当’=’出现在表示关键值或者默认参数值时，周围不需要加空格，如下：</p><pre><code class="python">def complex(real, imag=0.0):     return magic(r=real, i=imag)</code></pre><h3 id="注释"><a href="#注释" class="headerlink" title="注释"></a>注释</h3><p>对于函数、方法的注释，应该使用文档字符串，当然假如函数非常短小，简单明了，就不必要注释了。下面会有具体的例子。</p><blockquote><p>文档字符串是包、模块、类或函数里的第一个语句。这些字符串可以通过对象的__doc__成员被自动提取，并且被pydoc所用。(你可以在你的模块上运行pydoc试一把, 看看它长什么样)。我们对文档字符串的惯例是使用三重双引号”””( PEP-257 )。一个文档字符串应该这样组织：首先是一行以句号，问号或惊叹号结尾的概述(或者该文档字符串单纯只有一行)。接着是一个空行。接着是文档字符串剩下的部分，它应该与文档字符串的第一行的第一个引号对齐。</p></blockquote><p>具体的文档字符串应该包括：</p><ul><li>Args: 列出所有参数名字，并对参数进行描述</li><li>Returns: 描述返回值的类型和语义</li><li>Raises: 列出与接口有关的所有异常</li></ul><pre><code class="python">def fetch_bigtable_rows(big_table, keys, other_silly_variable=None):    &quot;&quot;&quot;Fetches rows from a Bigtable.    Retrieves rows pertaining to the given keys from the Table instance    represented by big_table.  Silly things may happen if    other_silly_variable is not None.    Args:        big_table: An open Bigtable Table instance.        keys: A sequence of strings representing the key of each table row            to fetch.        other_silly_variable: Another optional variable, that has a much            longer name than the other args, and which does nothing.    Returns:        A dict mapping keys to the corresponding table row data        fetched. Each row is represented as a tuple of strings. For        example:        {&#39;Serak&#39;: (&#39;Rigel VII&#39;, &#39;Preparer&#39;),         &#39;Zim&#39;: (&#39;Irk&#39;, &#39;Invader&#39;),         &#39;Lrrr&#39;: (&#39;Omicron Persei 8&#39;, &#39;Emperor&#39;)}        If a key from the keys argument is missing from the dictionary,        then that row was not found in the table.    Raises:        IOError: An error occurred accessing the bigtable.Table object.    &quot;&quot;&quot;    pass</code></pre><p>对于类的注释，也应该有一个用于描述该类的文档字符串。而且如果你的类有公共属性(Attributes)，那么文档中应该有一个属性(Attributes)段。并且应该遵守和函数参数相同的格式。具体例子如下：</p><pre><code class="python">class SampleClass(object):    &quot;&quot;&quot;Summary of class here.    Longer class information....    Longer class information....    Attributes:        likes_spam: A boolean indicating if we like SPAM or not.        eggs: An integer count of the eggs we have laid.    &quot;&quot;&quot;    def __init__(self, likes_spam=False):        &quot;&quot;&quot;Inits SampleClass with blah.&quot;&quot;&quot;        self.likes_spam = likes_spam        self.eggs = 0    def public_method(self):        &quot;&quot;&quot;Performs operation blah.&quot;&quot;&quot;</code></pre><h3 id="字符串"><a href="#字符串" class="headerlink" title="字符串"></a>字符串</h3><p>即使在参数都是字符串的情况下，也应该使用<code>format</code>或者<code>%</code>方法来格式化字符串。但是还是要在<code>+</code>和<code>format</code>（或者<code>%</code>）判断性的选择。<strong>从下面的例子中，是不是说，假如只是两个字符串组合，就直接使用<code>+</code>，而假如是字符串潜入到别的内容中，就最好使用<code>format</code>或者<code>%</code></strong></p><pre><code class="python">x = a + bx = &#39;%s, %s!&#39; % (imperative, expletive)x = &#39;{}, {}!&#39;.format(imperative, expletive)x = &#39;name: %s; score: %d&#39; % (name, n)x = &#39;name: {}; score: {}&#39;.format(name, n)</code></pre><p>在循环里不要使用<code>+</code>或者<code>+=</code>的形式来累加字符串。尽管字符串是不变的，但是这样会生成很多不必要的临时对象和结果，进而会造成运行时间平方次的增长，而不是线性增长。因此把自字符串先加到一个<code>list</code>里，然后在循环结束后<code>join</code>起来是更好的选择。</p><pre><code class="python">items = [&#39;&lt;table&gt;&#39;]for last_name, first_name in employee_list:    items.append(&#39;&lt;tr&gt;&lt;td&gt;%s, %s&lt;/td&gt;&lt;/tr&gt;&#39; % (last_name, first_name))items.append(&#39;&lt;/table&gt;&#39;)employee_table = &#39;&#39;.join(items)</code></pre><p>其他小规范：在同一个文件中使用统一的字符串引号；使用<code>&quot;&quot;&quot;</code>来表示多行字符串。</p><h3 id="文件"><a href="#文件" class="headerlink" title="文件"></a>文件</h3><p>在使用完文件之后，要关闭文件，推荐使用<code>with</code>的方式打开文件，因为这样会自动关闭文件。</p><pre><code class="python">with open(&quot;hello.txt&quot;) as hello_file:    for line in hello_file:        print line</code></pre><h3 id="导入格式"><a href="#导入格式" class="headerlink" title="导入格式"></a>导入格式</h3><p>每一行只导入一个模块，模块导入顺序如下：</p><ol><li>标准库导入</li><li>第三方库导入</li><li>程序指定导入</li></ol><p>在同一个组中，又要按字母顺序导入，且忽略大小写</p><pre><code class="python">import foofrom foo import barfrom foo.bar import bazfrom foo.bar import Quuxfrom Foob import ar</code></pre><h3 id="命名"><a href="#命名" class="headerlink" title="命名"></a>命名</h3><p>命名约定：</p><blockquote><ul><li>所谓”内部(Internal)”表示仅模块内可用，或者在类内是保护或私有的。  </li><li>用单下划线(_)开头表示模块变量或函数是protected的(使用import * from时不会包含。  </li><li>用双下划线(__)开头的实例变量或方法表示类内私有。  </li><li>将相关的类和顶级函数放在同一个模块里。不像Java，没必要限制一个类一个模块。  </li><li>对类名使用大写字母开头的单词(如CapWords，即Pascal风格)，但是模块名应该用小写加下划线的方式(如lower_with_under.py).。尽管已经有很多现存的模块使用类似于CapWords.py这样的命名，但现在已经不鼓励这样做，因为如果模块名碰巧和类名一致，这会让人困扰。</li></ul></blockquote><p>下面是具体例子</p><table><thead><tr><th style="text-align:center"><strong>Type</strong></th><th style="text-align:center"><strong>Public</strong></th><th style="text-align:center"><strong>Internal</strong></th></tr></thead><tbody><tr><td style="text-align:center">Modules</td><td style="text-align:center">lower_with_under</td><td style="text-align:center">_lower_with_under</td></tr><tr><td style="text-align:center">Packages</td><td style="text-align:center">lower_with_under</td><td style="text-align:center"></td></tr><tr><td style="text-align:center">Classes</td><td style="text-align:center">CapWords</td><td style="text-align:center">_CapWords</td></tr><tr><td style="text-align:center">Exceptions</td><td style="text-align:center">CapWords</td><td style="text-align:center"></td></tr><tr><td style="text-align:center">Functions</td><td style="text-align:center">lower_with_under()</td><td style="text-align:center">_lower_with_under()</td></tr><tr><td style="text-align:center">Global/Class Constants</td><td style="text-align:center">CAPS_WITH_UNDER</td><td style="text-align:center">_CAPS_WITH_UNDER</td></tr><tr><td style="text-align:center">Global/Class Variables</td><td style="text-align:center">lower_with_under</td><td style="text-align:center">_lower_with_under</td></tr><tr><td style="text-align:center">Instance Variables</td><td style="text-align:center">lower_with_under</td><td style="text-align:center">_lower_with_under (protected) or __lower_with_under (private)</td></tr><tr><td style="text-align:center">Method Names</td><td style="text-align:center">lower_with_under()</td><td style="text-align:center">_lower_with_under() (protected) or __lower_with_under() (private)</td></tr><tr><td style="text-align:center">Function/Method Parameters</td><td style="text-align:center">lower_with_under</td><td style="text-align:center"></td></tr><tr><td style="text-align:center">Local Variables</td><td style="text-align:center">lower_with_under</td></tr></tbody></table><p>正文到此结束，确实学到了很多代码规范，虽然写了2年多Python了，但是某些细节上的东西并没有注意太多。当然，正如参考文章最后提到的<strong>保持一致</strong>才是最终的目的，也就是与已有的代码风格保持一致，也许有些地方并不完全遵照上文里的规范，但是为了风格一致性，可以少许放弃规范，可以实现更好的代码沟通。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近已经在找工作了，发现各个公司对代码能力要求还是比较高的，谁叫咱还是要干码农的活呢，所以决心改一改自己的代码习惯，写出漂亮的代码。虽说重要的是实现功能，但是代码看起来漂亮，也会让人更舒服吧。下面会记录一些自己以前不太注意到的地方，主要准则还是“有则改之，无则加勉”。主要分成风格规范和语言规范两类。这篇是讲风格规范。&lt;br&gt;
    
    </summary>
    
      <category term="技术向" scheme="https://oyeblog.com/categories/%E6%8A%80%E6%9C%AF%E5%90%91/"/>
    
    
      <category term="Python" scheme="https://oyeblog.com/tags/Python/"/>
    
      <category term="Code" scheme="https://oyeblog.com/tags/Code/"/>
    
      <category term="Standard" scheme="https://oyeblog.com/tags/Standard/"/>
    
  </entry>
  
  <entry>
    <title>Blog 折腾记</title>
    <link href="https://oyeblog.com/2017/hexo_blog_personalize/"/>
    <id>https://oyeblog.com/2017/hexo_blog_personalize/</id>
    <published>2017-10-11T15:06:00.000Z</published>
    <updated>2024-08-17T13:59:46.691Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本着不折腾不舒服的精神，对博客进行个性化，丰富功能。</p></blockquote><h2 id="修改不蒜子统计"><a href="#修改不蒜子统计" class="headerlink" title="修改不蒜子统计"></a>修改不蒜子统计</h2><p>Material 主题的PV和UV统计用的也是不蒜子，但是显示的位置在分享里，太隐蔽了。于是乎，我就想把统计信息显示在footer里，然后参照网上教程，修改了<code>layout/_partial/footer.ejs</code>，如下：</p><pre><code class="javascript">&lt;script async src=&quot;//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js&quot;&gt;&lt;/script&gt;&lt;span id=&quot;busuanzi_container_site_pv&quot;&gt;本站总访问量&lt;span id=&quot;busuanzi_value_site_pv&quot;&gt;&lt;/span&gt;次&lt;/span&gt;</code></pre><h2 id="增加每日一图"><a href="#增加每日一图" class="headerlink" title="增加每日一图"></a>增加每日一图</h2><p>Update in 2024-08:<br>之前使用的API最近速度又比较慢了， 我又换成使用<a href="https://picsum.photos/1920/1080" target="_blank" rel="noopener">https://picsum.photos/1920/1080</a>，加载速度非常快，感谢作者。</p><p>Update in 2023-10:<br>之前使用的API最近速度比较慢， 我已经换成使用<a href="http://api.muvip.cn//api/bing/index.php?rand=false&amp;day=0&amp;size=1920x1080&amp;info=false" target="_blank" rel="noopener">http://api.muvip.cn//api/bing/index.php?rand=false&amp;day=0&amp;size=1920x1080&amp;info=false</a>，参考了这个<a href="https://allanhao.com/2022/07/19/2022-07-19-bing-daily-picture/" target="_blank" rel="noopener">博客</a>，里面还提供了其他API可供选择。</p><p>每日一图的功能是我在搜索Material主题的博客时，偶然发现的一个隐藏属性，具体可以参见<a href="http://w4lle.com/2016/11/17/hexo-theme-material/" title="每日一图" target="_blank" rel="noopener">这里</a>，因为我发现这个作者给的API比较慢，于是就搜了一下有没有比较快的API，结果还真有，就是<a href="https://github.com/xCss/bing/tree/v1.0.0" title="Bing每日一图API" target="_blank" rel="noopener">这个</a>，这个API返回的是Bing的图片，图片质量很有保证，而且作者有很多参数可以设置，我选择了分辨率为800*480，这样加载速度更快，十分满意，具体修改<code>layout/_partial/daily_pic.ejs</code>，如下：</p><pre><code class="http">&lt;div class=&quot;mdl-card__media mdl-color-text--grey-50&quot; style=&quot;background-image:url(https://bing.ioliu.cn/v1/rand/?w=800&amp;h=480)&quot;&gt;</code></pre><p>其中<strong>w</strong>是设置宽度，<strong>h</strong>是设置高度，具体的参数设置可以参考<a href="https://github.com/xCss/bing/tree/v1.0.0" target="_blank" rel="noopener">github页面</a>。总之，给这个API的作者点个赞，哈哈。</p><h2 id="增加版权信息"><a href="#增加版权信息" class="headerlink" title="增加版权信息"></a>增加版权信息</h2><p>为每篇文章增加版权信息，其实也没人会来转载我的文章，但是就是想尽可能完善一下自己的博客嘛。我参考的是<a href="https://jerry011235.github.io/2015/11/15/Hexo%E6%96%87%E7%AB%A0%E6%9C%AB%E5%B0%BE%E6%B7%BB%E5%8A%A0%E7%89%88%E6%9D%83%E6%88%96%E8%87%AA%E5%AE%9A%E4%B9%89%E6%96%87%E6%9C%AC/" target="_blank" rel="noopener">这位仁兄</a>的方法，结合了一些别的博客看到的版权声明。具体我是修改<code>layout/_partial/post-content.ejs</code>，如下：</p><pre><code class="javascript">&lt;% if(!page.nostatement){ %&gt;  &lt;div class=&quot;article-statement&quot;&gt;    &lt;hr&gt;      &lt;strong&gt;本文标题: &lt;/strong&gt;&lt;a href=&quot;&lt;%- url_for(page.path) %&gt;&quot;&gt;&lt;%= page.title %&gt;&lt;/a&gt;&lt;br&gt;    &lt;strong&gt;原始链接: &lt;/strong&gt;&lt;a href=&quot;&lt;%- url_for(page.path) %&gt;&quot; title=&quot;&lt;%= page.title %&gt;&quot;&gt;&lt;%= page.permalink %&gt;&lt;/a&gt;&lt;br&gt;    &lt;strong&gt;发布时间: &lt;/strong&gt;&lt;%= page.date.format(&quot;YYYY年MM月DD日-HH:mm&quot;) %&gt;&lt;br&gt;    &lt;% if(page.updated){ %&gt;    &lt;strong&gt;最后更新: &lt;/strong&gt;&lt;%= page.updated.format(&quot;YYYY年MM月DD日-HH:mm&quot;) %&gt;&lt;/p&gt;    &lt;% } %&gt;    &lt;strong&gt;版权声明: &lt;/strong&gt;本站文章均采用&lt;a rel=&quot;license&quot; href=&quot;https://creativecommons.org/licenses/by-nc-sa/4.0/&quot;&gt;CC BY-NC-SA 4.0协议&lt;/a&gt;进行许可。转载请注明出处！&lt;br&gt;  &lt;/div&gt;&lt;% } %&gt;</code></pre><p>这里增加了nostatement参数，主要是考虑到<strong>About</strong>页面并不需要版权信息，加了这个参数可以自由控制版权信息的添加。</p><h2 id="增加代码高亮"><a href="#增加代码高亮" class="headerlink" title="增加代码高亮"></a>增加代码高亮</h2><p>在增加了上面这些代码以后，发现Material主题的代码渲染不是很好看，于是去查了作者的说明文档，发现可以安装插件<a href="https://github.com/ele828/hexo-prism-plugin" target="_blank" rel="noopener">Hexo-Prism-Plugin</a>，我按照github页面安装配置。  </p><pre><code class="bash">npm i -S hexo-prism-plugin</code></pre><pre><code class="yaml">prism_plugin:  mode: preprocess    # realtime/preprocess  theme: solarizedlight  line_number: true    # default false</code></pre><p>还是不能渲染，最后参照<a href="https://mayusheng.cn/2016/12/20/HEXO%E9%AB%98%E4%BA%AE%E4%BA%AE%E4%B8%8D%E8%B5%B7%E6%9D%A5%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95/" target="_blank" rel="noopener">这篇博客</a>，发现是我的theme写错了，所以不能高亮，然后我把所有的theme都试了一遍，最后选择了<strong>solarizedlight</strong>，显示效果在上面。<br>主要theme有如下几种：</p><ul><li>default</li><li>coy</li><li>dark</li><li>funky</li><li>okaidia</li><li>solarizedlight</li><li>tomorrow</li><li>twilight</li></ul><p>在<code>.md</code>文件中插入代码块的语法如下，其中<code>language</code>可以包括绝大部分编程语言，具体参考<a href="http://prismjs.com/#languages-list" title="languages-list" target="_blank" rel="noopener">官方文档</a></p><pre><code>```language代码块```</code></pre><hr><p><strong>2019年2月20日更新</strong><br>由于Material主题更新，已经支持新的渲染工具，并且效果还不错，因此放弃prism插件，改用主题自带的<code>prettify</code></p><ol><li>首先卸载<code>hexo-prism-plugin</code><pre><code class="bash">npm uninstall -S hexo-prism-plugin</code></pre></li><li>修改<code>_config.yml</code>，设置<code>prettify</code>的<code>enable</code>为<code>true</code><pre><code class="yaml">prettify: enable: true theme: &quot;tranquil-heart&quot; </code></pre></li><li>重新generate，deploy即可</li></ol><h2 id="About页面增加背景音乐"><a href="#About页面增加背景音乐" class="headerlink" title="About页面增加背景音乐"></a>About页面增加背景音乐</h2><blockquote><p>毋庸置疑，好的事情总会到来。而当它来晚时，也不失为一种惊喜。<br>                          ——— 《托斯卡纳艳阳下》</p></blockquote><p>这个是心血来潮的想法，之前听过《Almost Lover》，主要是配合女神汤唯和廖凡演的<a href="http://v.yinyuetai.com/video/2370266" title="Almost Lover" target="_blank" rel="noopener">《命中注定》</a>电影原声MV，简直不能更唯美心碎，真的推荐这个MV，刚刚我又循环了10遍。是的，刚刚也把电影刷了一遍。于是想把 它加过来做背景音乐，然后加在了<strong>About me</strong>页面，方法其实很简单。在<a href="https://music.163.com/" target="_blank" rel="noopener">网易云音乐</a>上搜索歌名，选择<em>生成外链播放器</em>。<br><img src="https://cdn.jsdelivr.net/gh/oye93/oyeImg/blog/post/almost%20lover.PNG" alt><br>得到的外链代码大致如下：</p><pre><code class="javascript">&lt;iframe frameborder=&quot;no&quot; border=&quot;0&quot; marginwidth=&quot;0&quot; marginheight=&quot;0&quot; width=330 height=86 src=&quot;//music.163.com/outchain/player?type=2&amp;id=22423722&amp;auto=1&amp;height=66&quot;&gt;&lt;/iframe&gt;</code></pre><p>然后在<code>.md</code>文件中插入这段代码就可以生成播放器，具体效果可以参考<a href="http://oyeblog.com/about/">About me页面</a>。</p><h2 id="更换评论系统为gitment"><a href="#更换评论系统为gitment" class="headerlink" title="更换评论系统为gitment"></a>更换评论系统为gitment</h2><p>Update in 2023-10:<br>改回<a href="https://disqus.com/" target="_blank" rel="noopener">DISQUS</a>，放弃墙内用户(doge</p><p>在升级了Material 1.5之后，发现评论系统disqus_click选项会根据网络环境自动加载，这就失去了<strong>click</strong>的意义了，然后发现1.5版本的主题开始支持其他的评论系统，比如<a href="https://github.com/imsun/gitment" target="_blank" rel="noopener">gitment</a>，也就是我后面要换成的评论系统。选择这个有以下几个考虑：  </p><ol><li>玩博客的人肯定用github，保证了适用性。</li><li>配置比较方便，下面我会说具体过程。</li><li>可以不用科学上网就可以访问。</li></ol><p>下面是具体配置过程，因为我是在Material主题的基础上配置，所以有些步骤直接省掉了，其他主题的可以参看作者的<a href="https://github.com/imsun/gitment" target="_blank" rel="noopener">说明文档</a>，挺详细的，点个赞！</p><ol><li>点击<a href="https://github.com/settings/applications/new" target="_blank" rel="noopener">链接</a>，注册OAuth application<br><img src="https://cdn.jsdelivr.net/gh/oye93/oyeImg/blog/post/zheteng_oauth.JPG" alt></li><li>得到一个 client ID 和一个 client secret，这个将被用于之后的配置。</li><li>修改theme里的config文件，如下：<br><img src="https://cdn.jsdelivr.net/gh/oye93/oyeImg/blog/post/zheteng_gitment_config.JPG" alt></li><li>配置完成之后，点击登录按钮，然后会出现初始化按钮，点击之后会在上面新建的repo的issue里建立一个新的issue，然后就可以评论了。</li></ol><p>这个作者的这个评论系统做的挺好的，支持代码高亮什么的，可以再研究研究。</p><hr><p><strong>2019年2月20日更新</strong><br>之前一直没注意，也因为没人评论，才发现<strong>gitment</strong>出问题，报<code>[object ProgressEvent]</code>的错误，<br>参考<a href="https://github.com/jjeejj/jjeejj.github.io/issues/8" target="_blank" rel="noopener">这个老哥的解答</a>，貌似是因为原作者的跨域服务接口出问题了，<br>然后出现上述错误，根据他的解决方案，我也调整了我的代码，记录如下：<br>在<code>\layout\_widget\comment\gitment\enter.ejs</code>修改如下代码：</p><pre><code class="html">&lt;link rel=&quot;stylesheet&quot; href=&quot;https://imsun.github.io/gitment/style/default.css&quot;&gt;&lt;script src=&quot;https://imsun.github.io/gitment/dist/gitment.browser.js&quot;&gt;&lt;/script&gt;</code></pre><p>为</p><pre><code class="html">&lt;link rel=&quot;stylesheet&quot; href=&quot;https://www.wenjunjiang.win/css/gitment.css&quot;&gt;&lt;script src=&quot;https://www.wenjunjiang.win/js/gitment.js&quot;&gt;&lt;/script&gt;</code></pre><p>重新部署，应该就可以恢复正常了。</p><blockquote><p>我会继续折腾，本页面也将持续更新。</p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;本着不折腾不舒服的精神，对博客进行个性化，丰富功能。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;修改不蒜子统计&quot;&gt;&lt;a href=&quot;#修改不蒜子统计&quot; class=&quot;headerlink&quot; title=&quot;修改不蒜子统计&quot;&gt;&lt;/a&gt;修改不蒜
      
    
    </summary>
    
      <category term="分享境" scheme="https://oyeblog.com/categories/%E5%88%86%E4%BA%AB%E5%A2%83/"/>
    
    
      <category term="Hexo" scheme="https://oyeblog.com/tags/Hexo/"/>
    
      <category term="Blog" scheme="https://oyeblog.com/tags/Blog/"/>
    
  </entry>
  
  <entry>
    <title>Introduction to RNNs</title>
    <link href="https://oyeblog.com/2017/introduction_to_rnn/"/>
    <id>https://oyeblog.com/2017/introduction_to_rnn/</id>
    <published>2017-10-11T11:11:00.000Z</published>
    <updated>2023-10-22T07:06:32.046Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>最近在找关于deep learning的基础知识看，找到一个比较推荐的<a href="http://www.wildml.com" title="WILDML" target="_blank" rel="noopener">英文博客</a>介绍，为了加深一下映象，决定翻译一遍。采取中英文对照的形式。</p></blockquote><h2 id="What-are-RNNs"><a href="#What-are-RNNs" class="headerlink" title="What are RNNs?"></a>What are RNNs?</h2><p><em>The idea behind RNNs is to make use of sequential information. In a traditional neural network we assume that all inputs (and outputs) are independent of each other. But for many tasks that’s a very bad idea. If you want to predict the next word in a sentence you better know which words came before it. RNNs are called recurrent because they perform the same task for every element of a sequence, with the output being depended on the previous computations. Another way to think about RNNs is that they have a “memory” which captures information about what has been calculated so far. In theory RNNs can make use of information in arbitrarily long sequences, but in practice they are limited to looking back only a few steps (more on this later). Here is what a typical RNN looks like:</em></p><p>Recurrent Neural Networks (RNNs)背后的思想是充分利用序列信息。在传统的神经网络中，我们是假设所有的输入（或者输出）之间是相互独立的。但是在一些任务中，这个假设是非常不合理的。比如，如果你想预测某个句子中的下一个词，那么最好能知道这个词的前一个词是什么。RNN之所以叫循环的（recurrent），是因为它对于序列中的每一个元素执行相同的操作，而且输出是依赖于前一步的计算。也可以从另一种角度来理解RNN，就是它拥有记忆前面所有计算得到的信息的能力。理论上，RNN可以利用任意长度序列中的信息，但是在实践中只能回溯到有限的几步。下面是一个典型的RNN图示：<br><img src="http://d3kbpzbmcynnmx.cloudfront.net/wp-content/uploads/2015/09/rnn.jpg" alt title="RNN"><br>Source: Nature</p><p><em>The above diagram shows a RNN being unrolled (or unfolded) into a full network. By unrolling we simply mean that we write out the network for the complete sequence. For example, if the sequence we care about is a sentence of 5 words, the network would be unrolled into a 5-layer neural network, one layer for each word. The formulas that govern the computation happening in a RNN are as follows:</em></p><p>上面的图展示了一个RNN展开成全网络的情况。通过展开，我们简单的把整个序列表示成网络形式。举个例子，如果序列的长度是5，那么整个网络会被展开成5层，每一层对应一个词。图中的参数以及一些计算公式如下：</p><p><em>$x_t$ is the input at time step $t$. For example, $x_1$ could be a one-hot vector corresponding to the second word of a sentence.<br>$s_t$ is the hidden state at time step $t$. It’s the “memory” of the network. $s_t$ is calculated based on the previous hidden state and the input at the current step: $s_t=f(Ux_t + Ws_{t-1})$. The function $f$ usually is a nonlinearity such as <a href="https://reference.wolfram.com/language/ref/Tanh.html" target="_blank" rel="noopener">tanh</a> or <a href="https://en.wikipedia.org/wiki/Rectifier_(neural_networks)" target="_blank" rel="noopener">ReLU</a>.  $s_{-1}$, which is required to calculate the first hidden state, is typically initialized to all zeroes.<br>$o_t$ is the output at step $t$. For example, if we wanted to predict the next word in a sentence it would be a vector of probabilities across our vocabulary. $o_t = \mathrm{softmax}(Vs_t)$.<br>There are a few things to note here:</em></p><p>$x_t$ 是在时间步骤 $t$ 的输入。比如： $x_1$ 可能就是一个句子中的第二个词的one-hot向量。<br>$s_t$ 是时间步骤 $t$ 的隐含状态，也就是这个网络的“记忆”。$s_t$ 是基于前一个隐含状态和当前步骤的输入计算得到，计算公式：$s_t=f(Ux_t + Ws_{t-1})$。公式 $f$ 一般是非线性函数，比如：<a href="https://reference.wolfram.com/language/ref/Tanh.html" target="_blank" rel="noopener">tanh</a> 或者 <a href="https://en.wikipedia.org/wiki/Rectifier_(neural_networks)" target="_blank" rel="noopener">ReLU</a>。$s_{-1}$ 是在计算第一个隐含状态是需要的值，会被初始化为0。<br>$o_t$ 是步骤$t$的输出。比如，如果我们想预测一个句子中的下一个词，那么 $o_t$ 可能就是一个基于整个词汇集的概率向量。公式：$o_t = \mathrm{softmax}(Vs_t)$<br>下面是需要注意的几点：</p><p><em>You can think of the hidden state $s_t$ as the memory of the network. $s_t$ captures information about what happened in all the previous time steps. The output at step $o_t$ is calculated solely based on the memory at time $t$. As briefly mentioned above, it’s a bit more complicated in practice because $s_t$ typically can’t capture information from too many time steps ago.</em></p><p>我们可以把隐含状态 $s_t$ 看成是网络的记忆。$s_t$ 能获取前面所有时间步骤中的所有信息。时间步骤 $t$ 的输出 $o_t$ 只基于时间 $t$ 的记忆计算得到。就像上面提到的，实际操作中会更加复杂，因为 $s_t$ 并不能获得太多时间步骤前的信息。</p><p><em>Unlike a traditional deep neural network, which uses different parameters at each layer, a RNN shares the same parameters ($U$, $V$, $W$ above) across all steps. This reflects the fact that we are performing the same task at each step, just with different inputs. This greatly reduces the total number of parameters we need to learn.</em></p><p>不像传统的深度神经网络那样在每层都采用不同的参数，RNN在所有步骤中都是用的相同的参数集（上图中的$U$, $V$, $W$）。这反映的事实就是我们在每步都进行了相同的操作，只是每步的输入不一样。这使得要学习的参数数量大大降低。</p><p><em>The above diagram has outputs at each time step, but depending on the task this may not be necessary. For example, when predicting the sentiment of a sentence we may only care about the final output, not the sentiment after each word. Similarly, we may not need inputs at each time step. The main feature of an RNN is its hidden state, which captures some information about a sequence.</em></p><p>上图中每个步骤都有输出，但是基于不同的任务并不是每个步骤都需要输出的。比如在做句子情感分析的时候，我们只关心最终的输出，而不是每个词的情感分析结果。类似的，我们也不需要每个步骤都有输入。RNN的一个主要特征就是隐含状态，这样能够获得整个序列的某些信息。</p><h2 id="What-can-RNNs-do"><a href="#What-can-RNNs-do" class="headerlink" title="What can RNNs do?"></a>What can RNNs do?</h2><p><em>RNNs have shown great success in many NLP tasks. At this point I should mention that the most commonly used type of RNNs are LSTMs, which are much better at capturing long-term dependencies than vanilla RNNs are. But don’t worry, LSTMs are essentially the same thing as the RNN we will develop in this tutorial, they just have a different way of computing the hidden state. We’ll cover LSTMs in more detail in a later post. Here are some example applications of RNNs in NLP (by non means an exhaustive list).</em></p><p>RNN已经在很多的NLP任务中取得了成功。最常用的RNN是LSTM，它比获取长依赖信息上比vanilla RNNs表现更好。但是，LSTM和我们想建立的RNN模型实际上是一样的，只是用了不同的方法来计算隐含状态。我们会在后面讨论LSTM的更多细节。下面是RNN在NLP领域上应用的例子。</p><h3 id="Language-Modeling-and-Generating-Text"><a href="#Language-Modeling-and-Generating-Text" class="headerlink" title="Language Modeling and Generating Text"></a>Language Modeling and Generating Text</h3><p><em>Given a sequence of words we want to predict the probability of each word given the previous words. Language Models allow us to measure how likely a sentence is, which is an important input for Machine Translation (since high-probability sentences are typically correct). A side-effect of being able to predict the next word is that we get a generative model, which allows us to generate new text by sampling from the output probabilities. And depending on what our training data is we can generate all kinds of stuff. In Language Modeling our input is typically a sequence of words (encoded as one-hot vectors for example), and our output is the sequence of predicted words. When training the network we set $o_t = x_{t+1}$ since we want the output at step $t$ to be the actual next word.</em></p><p><strong>语言建模和文本生成</strong> 给定一个词序列，我们想预测每个词出现在它前一个词后面的概率。语言模型可以让我们能够估算一个句子有多像一个正常的句子（<em>或者说符合语法、符合自然语言的句子</em>），这在机器翻译中是十分重要的（因为更高的可能性指正着更高的准确率）。预测下一个词的功能带来的另一个功能就是我们也可以得到一个生成模型，使得我们可以根据输出概率来生成新的文本。而且，根据我们的训练数据的不同，可以生成各种各样的文本素材。在语言模型中，我们的输入通常是词序列（比如：编码成one-hot的向量），输出就是预测词的序列。在训练整个网络的时候，我们设置 $o_t = x_{t+1}$ ，因为我们想得到步骤 $t$ 的输出就是下一个词。</p><p><em>Research papers about Language Modeling and Generating Text:</em></p><p>关于语言建模和文本生成的文章：</p><ul><li><a href="http://www.fit.vutbr.cz/research/groups/speech/publi/2010/mikolov_interspeech2010_IS100722.pdf" target="_blank" rel="noopener">Recurrent neural network based language model</a>  </li><li><a href="http://www.fit.vutbr.cz/research/groups/speech/publi/2011/mikolov_icassp2011_5528.pdf" target="_blank" rel="noopener">Extensions of Recurrent neural network based language model</a>  </li><li><a href="http://machinelearning.wustl.edu/mlpapers/paper_files/ICML2011Sutskever_524.pdf" target="_blank" rel="noopener">Generating Text with Recurrent Neural Networks</a></li></ul><h2 id="Machine-Translation"><a href="#Machine-Translation" class="headerlink" title="Machine Translation"></a>Machine Translation</h2><p><em>Machine Translation is similar to language modeling in that our input is a sequence of words in our source language (e.g. German). We want to output a sequence of words in our target language (e.g. English). A key difference is that our output only starts after we have seen the complete input, because the first word of our translated sentences may require information captured from the complete input sequence.</em></p><p><strong>机器翻译</strong> 和语言建模比较类似。只是在机器翻译中，我们的输入是源语言（比如：德语）的词序列，而我们想得到的输出是目标语言（比如：英语）的词序列。关键的不同在于我们的输出是在看了所有的输入之后进行，因为翻译的句子的第一个词有可能需要整个输入序列的信息。</p><p><img src="http://d3kbpzbmcynnmx.cloudfront.net/wp-content/uploads/2015/09/Screen-Shot-2015-09-17-at-10.39.06-AM.png" alt title="RNN for Machine Translation"><br>Source: <a href="http://cs224d.stanford.edu/lectures/CS224d-Lecture8.pdf" target="_blank" rel="noopener">http://cs224d.stanford.edu/lectures/CS224d-Lecture8.pdf</a></p><p><em>Research papers about Machine Translation:</em></p><p>关于机器翻译的文章：</p><ul><li><a href="http://www.aclweb.org/anthology/P14-1140.pdf" target="_blank" rel="noopener">A Recursive Recurrent Neural Network for Statistical Machine Translation</a></li><li><a href="http://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf" target="_blank" rel="noopener">Sequence to Sequence Learning with Neural Networks</a></li><li><a href="http://research.microsoft.com/en-us/um/people/gzweig/Pubs/EMNLP2013RNNMT.pdf" target="_blank" rel="noopener">Joint Language and Translation Modeling with Recurrent Neural Networks</a></li></ul><h3 id="Speech-Recognition"><a href="#Speech-Recognition" class="headerlink" title="Speech Recognition"></a>Speech Recognition</h3><p><em>Given an input sequence of acoustic signals from a sound wave, we can predict a sequence of phonetic segments together with their probabilities.</em></p><p><strong>语音识别</strong> 给定从声波中得到的声形信号序列，预测语音片段序列，以及概率。</p><p><em>Research papers about Speech Recognition:</em></p><p>关于语音识别的文章：</p><ul><li><a href="http://www.jmlr.org/proceedings/papers/v32/graves14.pdf" target="_blank" rel="noopener">Towards End-to-End Speech Recognition with Recurrent Neural Networks</a></li></ul><h3 id="Generating-Image-Descriptions"><a href="#Generating-Image-Descriptions" class="headerlink" title="Generating Image Descriptions"></a>Generating Image Descriptions</h3><p><em>Together with convolutional Neural Networks, RNNs have been used as part of a model to generate descriptions for unlabeled images. It’s quite amazing how well this seems to work. The combined model even aligns the generated words with features found in the images.</em></p><p><strong>生成图片描述</strong> 结合卷积神经网络，RNN开始被作为未标注图片的描述生成模型的一部分，而且取得令人惊喜的结果。这个联合模型甚至可以把生成的文字和找到的图片特征整合起来。</p><p><img src="http://d3kbpzbmcynnmx.cloudfront.net/wp-content/uploads/2015/09/Screen-Shot-2015-09-17-at-11.44.24-AM.png" alt title="Deep Visual-Semantic Alignments for Generating Image Descriptions"><br>Source: <a href="http://cs.stanford.edu/people/karpathy/deepimagesent/" target="_blank" rel="noopener">http://cs.stanford.edu/people/karpathy/deepimagesent/</a></p><h2 id="Training-RNNs"><a href="#Training-RNNs" class="headerlink" title="Training RNNs"></a>Training RNNs</h2><p><em>Training a RNN is similar to training a traditional Neural Network. We also use the backpropagation algorithm, but with a little twist. Because the parameters are shared by all time steps in the network, the gradient at each output depends not only on the calculations of the current time step, but also the previous time steps. For example, in order to calculate the gradient at <code>t=4</code> we would need to backpropagate 3 steps and sum up the gradients. This is called Backpropagation Through Time (BPTT). If this doesn’t make a whole lot of sense yet, don’t worry, we’ll have a whole post on the gory details. For now, just be aware of the fact that vanilla RNNs trained with BPTT have difficulties learning long-term dependencies (e.g. dependencies between steps that are far apart) due to what is called the vanishing/exploding gradient problem. There exists some machinery to deal with these problems, and certain types of RNNs (like LSTMs) were specifically designed to get around them.</em></p><p>训练RNN模型与训练传统神经网络模型差不多，都是使用反向传播算法，但是会有点曲折。因为参数是共享的，所以每个输出的梯度不仅取决于当前步骤的计算，也取决于前面步骤的。比如，为了计算<code>t=4</code>这个时刻的梯度，需要反向传播3步，求梯度之和，这也叫做“Backpropagation Through Time (BPTT)”。如果上面的描述还令你有点困惑也不用担心，之后会有一篇详细的说明。现在只需要清楚，因为存在梯度消失和梯度爆炸的问题，用BPTT训练的vanilla RNNs模型在学习长距离依赖（比如：相距很远的步骤间的依赖）时是有困难的。当然，现在也有一些机制来解决这些问题，也有像LSTM这样类型的RNN模型专门来避开这个问题的。</p><h2 id="RNN-Extensions"><a href="#RNN-Extensions" class="headerlink" title="RNN Extensions"></a>RNN Extensions</h2><p><em>Over the years researchers have developed more sophisticated types of RNNs to deal with some of the shortcomings of the vanilla RNN model. We will cover them in more detail in a later post, but I want this section to serve as a brief overview so that you are familiar with the taxonomy of models.</em></p><p>这么多年来，研究人员已经开发了更多复杂的RNN来解决vanilla RNN中存在的不足。我们会在后续的文章中详细介绍，下面只是简单的介绍一下，让大家有个印象。</p><h3 id="Bidirectional-RNN"><a href="#Bidirectional-RNN" class="headerlink" title="Bidirectional RNN"></a>Bidirectional RNN</h3><p><em>Bidirectional RNNs are based on the idea that the output at time <code>t</code> may not only depend on the previous elements in the sequence, but also future elements. For example, to predict a missing word in a sequence you want to look at both the left and the right context. Bidirectional RNNs are quite simple. They are just two RNNs stacked on top of each other. The output is then computed based on the hidden state of both RNNs.</em></p><p><strong>双向RNNs</strong>基于的主要思想是<code>t</code>时刻的输出不仅取决于序列中前面的要素，也要考虑后面的要素。举个例子，在预测句子中的缺失词时，就要同时考虑上下文。双向RNN也比较简单，只是两层RNN相互堆叠，然后输出基于两个RNN的隐含层计算得到。</p><h3 id="Deep-Bidirectional-RNN"><a href="#Deep-Bidirectional-RNN" class="headerlink" title="Deep Bidirectional RNN"></a>Deep Bidirectional RNN</h3><p><em>Deep (Bidirectional) RNNs are similar to Bidirectional RNNs, only that we now have multiple layers per time step. In practice this gives us a higher learning capacity (but we also need a lot of training data).</em></p><p><strong>深度（双向）RNNs</strong>和双向RNNs类似，只是每个时间步骤有多层。实践中会有更高的学习能力，同时也需要更多的训练数据。</p><h3 id="LSTM-networks"><a href="#LSTM-networks" class="headerlink" title="LSTM networks"></a>LSTM networks</h3><p><em>LSTM networks are quite popular these days and we briefly talked about them above. LSTMs don’t have a fundamentally different architecture from RNNs, but they use a different function to compute the hidden state. The memory in LSTMs are called cells and you can think of them as black boxes that take as input the previous state $h_{t-1}$ and current input $x_t$. Internally these cells  decide what to keep in (and what to erase from) memory. They then combine the previous state, the current memory, and the input. It turns out that these types of units are very efficient at capturing long-term dependencies. LSTMs can be quite confusing in the beginning but if you’re interested in learning more this post has an excellent explanation.</em></p><p><strong>LSTM网络</strong>现在应用十分广泛，上面也简单提到过。LSTM从根本上来说和RNN并没有不同，只是用了不同的函数来获得隐含状态。LSTM中的记忆单元叫做cell，可以把它想象成一个黑盒，这个黑盒的输入是前面的状态$h_{t-1}$和当前的输入$x_t$。在cell的内部决定哪些信息要被保留，哪些信息要被丢弃。然后把前面的状态、当前的记忆以及输入结合起来。实践证明，这种单元在获取长距离的依赖时十分有效。刚开始，你可能会觉得LSTM十分令人困惑，但是如果你有兴趣了解更多，后续的文章会有很好的解释说明。</p><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p><em>So far so good. I hope you’ve gotten a basic understanding of what RNNs are and what they can do. In the next post we’ll implement a first version of our language model RNN using Python and Theano. Please leave questions in the comments!</em></p><p>到此为止，我相信你们对RNN是什么，以及RNN能做什么有个大致的了解了。下一篇文章我们将利用Python和Theano完成第一个版本的RNN语言模型。欢迎提问！</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;最近在找关于deep learning的基础知识看，找到一个比较推荐的&lt;a href=&quot;http://www.wildml.com&quot; title=&quot;WILDML&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;英文博客&lt;/a&gt;介绍，
      
    
    </summary>
    
      <category term="技术向" scheme="https://oyeblog.com/categories/%E6%8A%80%E6%9C%AF%E5%90%91/"/>
    
    
      <category term="Deep Learning" scheme="https://oyeblog.com/tags/Deep-Learning/"/>
    
      <category term="RNN" scheme="https://oyeblog.com/tags/RNN/"/>
    
      <category term="Introduction" scheme="https://oyeblog.com/tags/Introduction/"/>
    
      <category term="Translation" scheme="https://oyeblog.com/tags/Translation/"/>
    
  </entry>
  
  <entry>
    <title>在线PPT演示工具---nodePPT 简介</title>
    <link href="https://oyeblog.com/2017/use_nodeppt/"/>
    <id>https://oyeblog.com/2017/use_nodeppt/</id>
    <published>2017-09-14T11:11:00.000Z</published>
    <updated>2023-10-22T07:06:32.046Z</updated>
    
    <content type="html"><![CDATA[<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><blockquote><p>这可能是迄今为止最好的网页版演示库</p></blockquote><p>正如作者所说，nodePPT是基于node.js开发的，用Markdown语法来编写的在线PPT工具，参见<a href="https://github.com/ksky521/nodeppt" target="_blank" rel="noopener">Github nodePPT</a>。下面是官方demo，当然也是用nodePPT实现。<br><a id="more"></a></p><iframe src="http://js8.in/nodeppt/" height="600px" align="center"></iframe><h1 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h1><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p><code>npm install -g nodeppt</code><br>如果出现被qiang的情况可以用下面这个命令：<br><code>npm install -g nodeppt --registry=http://r.cnpmjs.org</code>  </p><h2 id="创建"><a href="#创建" class="headerlink" title="创建"></a>创建</h2><p>支持markdown语法快速创建网页幻灯片。<br><code>nodeppt create ppt-name</code>  </p><h2 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h2><pre><code class="python"># 获取帮助nodeppt start -h# 绑定端口nodeppt start -p &lt;port&gt;nodeppt start -p 8090 -d path/for/ppts# 绑定host，默认绑定0.0.0.0nodeppt start -p 8080 -d path/for/ppts -H 127.0.0.1</code></pre><h2 id="启用socket控制"><a href="#启用socket控制" class="headerlink" title="启用socket控制"></a>启用socket控制</h2><p>使用socket通信（按Q键显示/关闭二维码，手机扫描，即可控制）<br>socket须知：1、注意手机和pc要可以相互访问，2、防火墙，3、ip</p><h3 id="方法1-使用url参数"><a href="#方法1-使用url参数" class="headerlink" title="方法1 使用url参数"></a>方法1 使用url参数</h3><p><code>http://127.0.0.1:8080/md/demo.md?controller=socket</code><br>在页面按键【Q】显示控制url的二维码和控制链接（需要隐身窗口打开），手机上可以使用左右touch滑动和摇一摇切换下一页</p><h3 id="方法2-使用start命令行"><a href="#方法2-使用start命令行" class="headerlink" title="方法2 使用start命令行"></a>方法2 使用start命令行</h3><p><code>nodeppt start -c socket</code><br>在页面按键【Q】显示控制url的二维码和控制链接（需要隐身窗口打开），手机上可以使用左右touch滑动和摇一摇切换下一页</p><h2 id="打印-amp-导出PPT"><a href="#打印-amp-导出PPT" class="headerlink" title="打印&amp;导出PPT"></a>打印&amp;导出PPT</h2><p>使用<code>url?print=1</code>访问页面，然后选择chrome的系统打印即可。  </p><pre><code class="shell"># 获取generate帮助nodeppt generate -h# 使用generate命令nodeppt generate filepath# 导出全部，包括nodeppt的js、img和css文件夹# 默认导出在publish文件夹nodeppt generate ./ppts/demo.md -a# 指定导出文件夹nodeppt generate ./ppts/demo.md output/path -a</code></pre><p>这里可以生成<code>.html</code>文件，但是必须是<code>-a</code>模式，不然单独打开时没有PPT的效果。</p><h1 id="语法"><a href="#语法" class="headerlink" title="语法"></a>语法</h1><p>总体来说，nodePPT用的是Markdown，在此基础上做了一些扩展。</p><h2 id="基本配置"><a href="#基本配置" class="headerlink" title="基本配置"></a>基本配置</h2><pre><code class="yaml">title: 演讲题目speaker: 演讲者url: 可以设置链接transition: 转场效果，例如：zoomin/cards/slide，其他的可以参见github页面files: 引入的js和css文件，多个以半角逗号隔开theme: 皮肤样式highlightStyle: 代码高亮样式，默认monokai_sublimeusemathjax: yes 启用MathJax渲染公式</code></pre><h2 id="单页配置语法"><a href="#单页配置语法" class="headerlink" title="单页配置语法"></a>单页配置语法</h2><p>通过<code>[slide]</code>作为PPT分隔</p><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><pre><code>[slide style=&quot;background-image:url(&#39;/img/bg1.png&#39;)&quot;]</code></pre><h3 id="单页动画"><a href="#单页动画" class="headerlink" title="单页动画"></a>单页动画</h3><p>主要有以下模式：kontext，vkontext，circle，earthquake，cards，glue，stick，move，newspaper，slide，slide2，slide3，horizontal3d，horizontal，vertical3d，zoomin，zoomout，pulse等</p><pre><code>[slide data-transition=&quot;vertical3d&quot;]</code></pre><h3 id="转场回调"><a href="#转场回调" class="headerlink" title="转场回调"></a>转场回调</h3><pre><code class="html">[slide data-on-leave=&quot;outcallback&quot; data-on-enter=&quot;incallback&quot;]## 当进入此页，就执行incallback函数## 当离开此页面，就执行outcallback函数</code></pre><h2 id="页面内配置语法"><a href="#页面内配置语法" class="headerlink" title="页面内配置语法"></a>页面内配置语法</h2><h3 id="单条动画"><a href="#单条动画" class="headerlink" title="单条动画"></a>单条动画</h3><p>使用方法：列表第一条加上<code>{:&amp;.动画类型}</code>（注意空格），下面是示例代码，其他动画类型包括moveIn，fadeIn，bounceIn，rollIn，zoomIn：  </p><pre><code class="html">* 上下左右方向键翻页    * 列表支持渐显动画 {:&amp;.moveIn}    * 支持多级列表    * 这个动画是moveIn</code></pre><h3 id="页面内上下布局"><a href="#页面内上下布局" class="headerlink" title="页面内上下布局"></a>页面内上下布局</h3><pre><code class="html">[slide]## 主页面样式### ----是上下分界线----nodeppt是基于nodejs写的支持 **Markdown!** 语法的网页PPTnodeppt：https://github.com/ksky521/nodeppt</code></pre><h3 id="页面内表格"><a href="#页面内表格" class="headerlink" title="页面内表格"></a>页面内表格</h3><pre><code class="html">### 市面上主要的css预处理器：less\sass\stylus--- |less| sass | stylus:-------|:------:|-------:|--------环境 |js/nodejs | Ruby | nodejs扩展名 | .less | .sass/.scss | .styl特点 | 老牌，用户多，支持js解析 | 功能全，有成型框架，发展快 | 语法多样，小众案例/框架 | [Bootstrap](http://getbootstrap.com/) | [compass](http://compass-style.org) [bourbon](http://bourbon.io) |</code></pre><h3 id="转场效果"><a href="#转场效果" class="headerlink" title="转场效果"></a>转场效果</h3><p><code>magic</code>标签，转场效果有zoomin/zoomout,move,circle,earthquake,newspaper,cover-diamond,horizontal3d/horizontal,vertical3d,cover-circle等  </p><pre><code>[slide][magic data-transition=&quot;效果&quot;]form code===== #4个以上的=作为转换前后页面的分隔符new code[/magic]</code></pre><h3 id="其他属性"><a href="#其他属性" class="headerlink" title="其他属性"></a>其他属性</h3><ul><li>字体分类 <code>&lt;span class=&quot;text-分类&quot;&gt;text&lt;/span&gt;</code></li><li>字体颜色 <code>&lt;span class=&quot;颜色&quot;&gt;text&lt;/span&gt;</code></li><li>label分类 <code>&lt;span class=&quot;label label-分类&quot;&gt;text&lt;/span&gt;</code></li><li>href <code>&lt;a href=&quot;&quot;&gt;text&lt;/a&gt;</code></li><li>mark <code>&lt;mark&gt;text&lt;/mark&gt;</code></li><li>左、右对齐 <code>{:&amp;.pull-right}</code> 和 <code>{:&amp;.pull-right}</code></li><li>引用块 <code>&gt; nodeppt可能是迄今为止最好用的web presentation &lt;small&gt;三水清&lt;/small&gt; {:&amp;.pull-right}</code></li><li>代码高亮 <code>&lt;code class=&quot;javascript&quot;&gt;code&lt;/code&gt;</code> <strong>这里必须在配置中设置<code>highlightStyle</code>为特定风格，比如<code>monokai_sublime</code> </strong></li></ul><h1 id="特色功能"><a href="#特色功能" class="headerlink" title="特色功能"></a>特色功能</h1><h2 id="iframe-效果"><a href="#iframe-效果" class="headerlink" title="iframe 效果"></a>iframe 效果</h2><ul><li>可以嵌入网页等，在做demo的时候会相当有用 <code>&lt;iframe data-src=&quot;http://www.baidu.com&quot; src=&quot;about:blank;&quot;&gt;&lt;/iframe&gt;</code></li></ul><h2 id="快速翻页"><a href="#快速翻页" class="headerlink" title="快速翻页"></a>快速翻页</h2><ul><li>输入页码，然后enter</li><li>使用O键，开启纵览模式，然后翻页</li></ul><h2 id="动效样式强调"><a href="#动效样式强调" class="headerlink" title="动效样式强调"></a>动效样式强调</h2><ul><li>官方文档说<strong>粗体</strong>和<em>斜体</em>，都可以有动效，但是我的实践中只有斜体有效，之后可能还要再研究一下</li><li>按下【H】键查看效果</li></ul><h2 id="支持zoom-js"><a href="#支持zoom-js" class="headerlink" title="支持zoom.js"></a>支持zoom.js</h2><ul><li>增加了zoom.js的支持，在演示过程中使用<code>alt+click</code>，则点击的地方就开始放大，再次<code>alt+click</code>则回复原状</li></ul><h2 id="使用note笔记"><a href="#使用note笔记" class="headerlink" title="使用note笔记"></a>使用note笔记</h2><ul><li>代码 <code>[note]这是note[/note]</code></li><li>按下键盘【N】键显示note</li><li>如果使用多窗口控制，note会在控制窗口中出现，这个功能点个赞！</li></ul><h2 id="使用画笔"><a href="#使用画笔" class="headerlink" title="使用画笔"></a>使用画笔</h2><ul><li>按下键盘【P】键：按下鼠标左键，在此处乱花下看看效果。</li><li>按下键盘【B/Y/R/G/M】：更换颜色</li><li>按下【1~4】：更换粗细</li><li>按下键盘【C】键：清空画板</li></ul><h2 id="PPT宽度变化"><a href="#PPT宽度变化" class="headerlink" title="PPT宽度变化"></a>PPT宽度变化</h2><ul><li>按下键盘【W】键，切换到更宽的页面看效果，第二次按键返回</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;这可能是迄今为止最好的网页版演示库&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;正如作者所说，nodePPT是基于node.js开发的，用Markdown语法来编写的在线PPT工具，参见&lt;a href=&quot;https://github.com/ksky521/nodeppt&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Github nodePPT&lt;/a&gt;。下面是官方demo，当然也是用nodePPT实现。&lt;br&gt;
    
    </summary>
    
      <category term="分享境" scheme="https://oyeblog.com/categories/%E5%88%86%E4%BA%AB%E5%A2%83/"/>
    
    
      <category term="nodePPT" scheme="https://oyeblog.com/tags/nodePPT/"/>
    
      <category term="node" scheme="https://oyeblog.com/tags/node/"/>
    
  </entry>
  
  <entry>
    <title>参加CCKS2017 Task_2有感</title>
    <link href="https://oyeblog.com/2017/ccks2017/"/>
    <id>https://oyeblog.com/2017/ccks2017/</id>
    <published>2017-09-12T11:07:43.000Z</published>
    <updated>2023-10-22T07:25:24.537Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>总结一下参加CCKS2017 Task_2的感想和经验</p></blockquote><h2 id="前言-amp-简介"><a href="#前言-amp-简介" class="headerlink" title="前言&amp;简介"></a>前言&amp;简介</h2><p><strong>全国知识图谱与语义计算大会</strong>（CCKS, China Conference on Knowledge Graph and Semantic Computing），具体介绍可以参见<a href="http://www.ccks2017.com/" title="ccks2017官网" target="_blank" rel="noopener">官网</a>。本次会议共有两个Task：  </p><ul><li>Task_1: 问题命名实体识别和链接（QEDL, Question Entity Discovery and Linking）</li><li>Task_2: 电子病历命名实体识别（CNER, Clinical Named Entity Recognition）</li></ul><p>我们参加的是Task_2，与我们现在在做的医学NLP比较相关，我之前也做过一些实体抽取的工作，不过大多是基于规则的方法。</p><h2 id="过程"><a href="#过程" class="headerlink" title="过程"></a>过程</h2><p>竞赛任务应该是5月份放出来的，最开始给我们的示例数据是包含嵌套实体的例子，由于竞赛组织者的标注比较随意，标注存在很多不一致的地方，但我们还是做了数据转换的工作，首先转换成<a href="https://github.com/keighrim/mae-annotation," title="github页面" target="_blank" rel="noopener">MAE</a>（一个标注工具）能处理的格式，企图对数据进行标注修正。然后把数据转换成CONLL格式，用于后面的训练和测试。但是，经过多次反馈协商，最后组织者放出来的数据都是非嵌套实体的，一致性也比之前的示例数据要好，同时组织者还给出了较多的未标注数据。</p><h2 id="Model"><a href="#Model" class="headerlink" title="Model"></a>Model</h2><p>这次用的model是比较传统的深度学习模型，Bidirctional RNN-CRF，如下图所示。这个模型在很多的NLP任务上都取得了很好的表现，当然我也做了一些改进。因为之前从来没有接触过深度学习，更没有实现过深度学习模型，我参考了<a href="https://github.com/zjy-ucas/ChineseNER" target="_blank" rel="noopener">github上的一个中文NER的项目</a>，这个项目也是用的前面所说的基础模型，在人民日报的数据集上取得了比较好的performance，作者用的是Tensorflow实现。因为作者的代码写得比较清楚，我把所有代码通读了几遍，理解了基本逻辑，数据输入格式，特征加入等，然后基于我们的数据实现了一下，发现效果还可以。在实现了基本模型之后，我就开始了调参，还好公司的电脑比较给力，模型跑得相对较快，选出了最优参数。在此期间，我也读了一些基于深度学习的中文NLP的工作，想借鉴一些方法，当然有些模型比较复杂，实现这些模型也超出了我的能力。最终实现了一下<a href="https://arxiv.org/pdf/1704.01314.pdf" title="Character-based Joint Segmentation and POS Tagging for Chinese using Bidirectional RNN-CRF" target="_blank" rel="noopener">此论文</a>中的character representation的方法，然后加入了分词，词性，字典等特征，最后对分模型和总模型的结果做了一个整合得到最终结果。在本次竞赛中拿到<strong>第4名</strong>的成绩，参见<a href="http://www.ccks2017.com/?page_id=51" target="_blank" rel="noopener">官网</a>。<br><img src="https://cdn.jsdelivr.net/gh/oye93/oyeImg/blog/post/ccks_1.png" alt="基本模型"></p><h2 id="Future-Work"><a href="#Future-Work" class="headerlink" title="Future Work"></a>Future Work</h2><ul><li>探索新的模型，比如不同的character representation方法。</li><li>充分利用未标注数据，现在未标注数据只用在了word embedding的训练中，可以探索一些semi-supervised和active learning的方法来充分利用未标注数据。</li><li>把这个模型用在已有的或者新的任务上，改变大量依赖规则的现状。</li></ul><h2 id="感想-amp-后记"><a href="#感想-amp-后记" class="headerlink" title="感想&amp;后记"></a>感想&amp;后记</h2><p>这次是我自己第二次参加NLP方面的竞赛，去年的<a href="https://www.i2b2.org/NLP/RDoCforPsychiatry/" target="_blank" rel="noopener">CEGS N-GRID Shared-Tasks</a>作为参与者，今年作为主要完成者，差别还是挺大的。有几点感想：  </p><ul><li>首先，在参加这种竞赛的时候，还是要做好分工合作，这方面我觉得自己还是做的不好，绝大部分的工作都是自己完成，从最开始的数据转换，方法调研，代码实现，参数调校，论文撰写。当然其中也得到了他人的帮助，在与公司同事的交流讨论中，也产生了许多灵感，在此也十分感谢他们。希望以后自己在这方面可以做的更好吧。</li><li>其次，就是上面也说过的一定要多读相关文献，有个积累，然后多交流，多讨论，会有意想不到的收获。</li><li>最后就是代码功力，要有用代码实现方法的能力。</li></ul><blockquote><p>已经把竞赛评测论文提交了，<del>希望这次可以被接收吧</del>，文章经过小修，已经被接收，还被邀请现场做Presentation，班门弄斧啊，有点紧张。</p></blockquote><p>最后附上我的<a href="https://cdn.jsdelivr.net/gh/oye93/oyeImg/blog/docs/ccks_summary.pdf" target="_blank" rel="noopener">总结</a>，里面有对方法和数据更详细的介绍。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;总结一下参加CCKS2017 Task_2的感想和经验&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;前言-amp-简介&quot;&gt;&lt;a href=&quot;#前言-amp-简介&quot; class=&quot;headerlink&quot; title=&quot;前言&amp;amp;简介&quot;&gt;&lt;
      
    
    </summary>
    
      <category term="分享境" scheme="https://oyeblog.com/categories/%E5%88%86%E4%BA%AB%E5%A2%83/"/>
    
    
      <category term="Knowledge Graph" scheme="https://oyeblog.com/tags/Knowledge-Graph/"/>
    
      <category term="NLP" scheme="https://oyeblog.com/tags/NLP/"/>
    
      <category term="Deep Learning" scheme="https://oyeblog.com/tags/Deep-Learning/"/>
    
      <category term="CCKS" scheme="https://oyeblog.com/tags/CCKS/"/>
    
      <category term="NER" scheme="https://oyeblog.com/tags/NER/"/>
    
  </entry>
  
  <entry>
    <title>参加CCKS 2017</title>
    <link href="https://oyeblog.com/2017/ccks2017_chengdu/"/>
    <id>https://oyeblog.com/2017/ccks2017_chengdu/</id>
    <published>2017-09-12T11:07:43.000Z</published>
    <updated>2023-10-22T07:25:24.537Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>总结一下这次去成都参加CCKS2017的感想和经验</p></blockquote><p>接上一篇<a href="http://oyeblog.com/2017/ccks2017/">参加CCKS2017 Task_2有感</a>，评测论文被接收后，去成都参加了CCKS大会，了解了一下知识图谱相关知识，见识了各位知识图谱领域的大牛，也看到了知识图谱现阶段的应用。当然，最重要的还是去看看同为评测任务的其他组选手的方法，为进一步工作找到方向。这也是第一次做大会报告，比较紧张。下面是我的总结PPT。</p><div class="row">    <embed src="https://cdn.jsdelivr.net/gh/oye93/oyeImg/blog/docs/CCKS2017_ouyang.pdf" width="100%" height="550" type="application/pdf"></div>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;总结一下这次去成都参加CCKS2017的感想和经验&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;接上一篇&lt;a href=&quot;http://oyeblog.com/2017/ccks2017/&quot;&gt;参加CCKS2017 Task_2有感&lt;/a&gt;，评测论文被
      
    
    </summary>
    
      <category term="分享境" scheme="https://oyeblog.com/categories/%E5%88%86%E4%BA%AB%E5%A2%83/"/>
    
    
      <category term="CCKS" scheme="https://oyeblog.com/tags/CCKS/"/>
    
  </entry>
  
  <entry>
    <title>Google Doodles下载</title>
    <link href="https://oyeblog.com/2017/google-doodles/"/>
    <id>https://oyeblog.com/2017/google-doodles/</id>
    <published>2017-09-07T13:39:00.000Z</published>
    <updated>2023-10-22T07:17:02.026Z</updated>
    
    <content type="html"><![CDATA[<p>最近又看到Google的搜索界面的Logo变了，有些Logo还是挺漂亮的，作为一个收集癖，想把所有的Google Logo下载过来，分享一下过程，以及最终收集到的Logo合集。</p><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><blockquote><p>涂鸦是在Google徽标的基础上，为庆祝节日、纪念日和缅怀著名艺术家、先驱者和科学家而设计创作的作品，涂鸦作品大都幽默风趣，能给用户带来一份惊喜，有些时候纯粹是即兴之作。</p></blockquote><p>Google Doodles，也就是各个节日或者纪念日，Google搜索界面的涂鸦。比如下面这种：<br><img src="https://cdn.jsdelivr.net/gh/oye93/oyeImg/blog/post/google-doodle_example.jpg" alt title="Google Doodles"><br>我找到了一下所有涂鸦的合集 – <a href="https://www.google.com/doodles" title="Google Doodles" target="_blank" rel="noopener">链接</a>，但是不能批量下载，然后想找一下是不是有人收集了所有的涂鸦或者有脚本可以实现爬取，很遗憾，没有！然后想着自己写个爬虫爬一下吧，发现太久不写爬虫已经忘得差不多了。最后找到一个chrome插件—<a href="https://chrome.google.com/webstore/detail/chrome-image-downloaderzi/bedbigoemkinkepgmcmgnapjcahnedmn" title="小乐图客chrome插件" target="_blank" rel="noopener">小乐图客</a>，这个插件可以实现爬取网站页面上的所有图片，这样刚好可以实现我的需求。其实我还找了一些别的这类插件，缺点主要有：收费（<a href="https://chrome.google.com/webstore/detail/bulk-image-downloader/facoldpeadablbngjnohbmgaehknhcaj" target="_blank" rel="noopener">Bulk Image Downloader</a>），gif有时候下载为静态（<a href="https://chrome.google.com/webstore/detail/fatkun-batch-download-ima/nnjjahlikiabnchcpehcpkdeckfgnohf" target="_blank" rel="noopener">Fatkun图片批量下载</a>），下载中断且不能修改图片名称（<a href="https://chrome.google.com/webstore/detail/imagespark-ultimate-image/hooaoionkjogngfhjjniefmenehnopag" target="_blank" rel="noopener">ImageSpark - Ultimate 图片 Downloader</a>）。所以，最终选定<strong>小乐图客</strong>，下载速度比较快，而且可以自定义图片名字为网页上对应图片的”Title”，点个赞。</p><h2 id="下载过程"><a href="#下载过程" class="headerlink" title="下载过程"></a>下载过程</h2><p>首先打开前面提到的Google涂鸦合集的网站，如下所示：<br><img src="https://cdn.jsdelivr.net/gh/oye93/oyeImg/blog/post/doodles_1.PNG" alt>  </p><p>在上面的页面，点击右上角的小乐图客插件按钮，会出现如下界面：<br><img src="https://cdn.jsdelivr.net/gh/oye93/oyeImg/blog/post/doodles_2.PNG" alt>  </p><p>在这个界面可以如下图所示的，定义重命名规则，定义图片保存路径，还可以预览重命名之后的图片名。最后点击存图按钮，感受“刷刷刷”下载的快感吧！<br><img src="https://cdn.jsdelivr.net/gh/oye93/oyeImg/blog/post/doodles_3.PNG" alt></p><h2 id="链接分享"><a href="#链接分享" class="headerlink" title="链接分享"></a>链接分享</h2><p>然而，以上操作都是在qiang外面完成的，qiang内还是没有办法实现，所以我把下载的合集分享出来。<br>下面链接里是2010-2017.9.4的所有Google Doodles，我会持续更新。<br>我不知道是不是侵权，最好<strong>不要商用</strong>，侵权立删！<br>度盘：<a href="https://pan.baidu.com/s/1qYqgnbY" target="_blank" rel="noopener">https://pan.baidu.com/s/1qYqgnbY</a>，密码：5ct6</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;最近又看到Google的搜索界面的Logo变了，有些Logo还是挺漂亮的，作为一个收集癖，想把所有的Google Logo下载过来，分享一下过程，以及最终收集到的Logo合集。&lt;/p&gt;
&lt;h2 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot;
      
    
    </summary>
    
      <category term="分享境" scheme="https://oyeblog.com/categories/%E5%88%86%E4%BA%AB%E5%A2%83/"/>
    
    
      <category term="Google Doodles" scheme="https://oyeblog.com/tags/Google-Doodles/"/>
    
  </entry>
  
  <entry>
    <title>NLP Groups</title>
    <link href="https://oyeblog.com/2017/nlp-groups/"/>
    <id>https://oyeblog.com/2017/nlp-groups/</id>
    <published>2017-08-23T08:42:04.000Z</published>
    <updated>2023-10-22T07:06:32.096Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>最近在看CCKS2017评测任务的成绩时，想查一下国内NLP方面比较厉害的课题组或者实验室，记录一下。</p></blockquote><h2 id="学术界"><a href="#学术界" class="headerlink" title="学术界"></a>学术界</h2><h3 id="Fudan-Natural-Language-Processing-Group"><a href="#Fudan-Natural-Language-Processing-Group" class="headerlink" title="Fudan Natural Language Processing Group"></a>Fudan Natural Language Processing Group</h3><ul><li>主页：<a href="http://nlp.fudan.edu.cn/" title="Fudan Natural Language Processing Group" target="_blank" rel="noopener">http://nlp.fudan.edu.cn/</a></li><li>Leader：<a href="http://nlp.fudan.edu.cn/xjhuang/" target="_blank" rel="noopener">黄萱菁</a>、<a href="http://nlp.fudan.edu.cn/xpqiu/" target="_blank" rel="noopener">邱锡鹏</a></li><li>代表作：中文自然语言处理工具包 <a href="https://github.com/FudanNLP/fnlp" target="_blank" rel="noopener">FudanNLP</a></li></ul><h3 id="哈工大-社会计算与信息检索研究中心-HIT-SCIR"><a href="#哈工大-社会计算与信息检索研究中心-HIT-SCIR" class="headerlink" title="哈工大 社会计算与信息检索研究中心(HIT-SCIR)"></a>哈工大 社会计算与信息检索研究中心(HIT-SCIR)</h3><ul><li>主页：<a href="http://ir.hit.edu.cn/" target="_blank" rel="noopener">http://ir.hit.edu.cn/</a> (讲真，这个主页看着有点老了…)</li><li>Leader：<a href="https://scholar.google.co.jp/citations?user=zyMJ1V0AAAAJ" target="_blank" rel="noopener">刘挺</a>、<a href="http://ir.hit.edu.cn/~qinb/" target="_blank" rel="noopener">秦兵</a></li><li>哈工大的NLP在国内应该是数一数二的，整个组也比较大，分为社会预测组(SP)、文本挖掘(TM)、问答系统组(QA)、语言分析(LA)、聊天机器人(CR)、阅读理解(RC)、作文生成(TG)、情感分析(SA组)，与工业界合作也很多（科大讯飞、微软、腾讯等）。</li></ul><h3 id="清华大学-自然语言处理与社会人文计算实验室"><a href="#清华大学-自然语言处理与社会人文计算实验室" class="headerlink" title="清华大学 自然语言处理与社会人文计算实验室"></a>清华大学 自然语言处理与社会人文计算实验室</h3><ul><li>主页：<a href="http://nlp.csai.tsinghua.edu.cn/new/" target="_blank" rel="noopener">http://nlp.csai.tsinghua.edu.cn/new/</a></li><li>Leader：<a href="http://nlp.csai.tsinghua.edu.cn/site2/index.php/zh/people?id=16" target="_blank" rel="noopener">孙茂松</a>、<a href="http://nlp.csai.tsinghua.edu.cn/~ly/" target="_blank" rel="noopener">刘洋</a>、<a href="http://nlp.csai.tsinghua.edu.cn/~lzy/" target="_blank" rel="noopener">刘知远</a></li></ul><h3 id="北京大学-计算机科学技术研究所-语言计算与互联网挖掘研究室"><a href="#北京大学-计算机科学技术研究所-语言计算与互联网挖掘研究室" class="headerlink" title="北京大学 计算机科学技术研究所 语言计算与互联网挖掘研究室"></a>北京大学 计算机科学技术研究所 语言计算与互联网挖掘研究室</h3><ul><li>主页：<a href="http://www.icst.pku.edu.cn/lcwm/index.php?title=%E9%A6%96%E9%A1%B5" target="_blank" rel="noopener">http://www.icst.pku.edu.cn/lcwm/index.php?title=%E9%A6%96%E9%A1%B5</a></li><li>Leader：<a href="http://www.icst.pku.edu.cn/lcwm/wanxj/" target="_blank" rel="noopener">万小军</a></li></ul><h3 id="中科院-计算技术研究所-自然语言处理研究组"><a href="#中科院-计算技术研究所-自然语言处理研究组" class="headerlink" title="中科院 计算技术研究所 自然语言处理研究组"></a>中科院 计算技术研究所 自然语言处理研究组</h3><ul><li>主页：<a href="http://nlp.ict.ac.cn/2017/index_zh.php" target="_blank" rel="noopener">http://nlp.ict.ac.cn/2017/index_zh.php</a></li><li>Leader：<a href="http://nlp.ict.ac.cn/~liuqun/index_zh.htm" target="_blank" rel="noopener">刘群</a></li></ul><h3 id="中科院-自动化研究所-模式识别国家重点实验室-自然语言处理研究小组"><a href="#中科院-自动化研究所-模式识别国家重点实验室-自然语言处理研究小组" class="headerlink" title="中科院 自动化研究所 模式识别国家重点实验室  自然语言处理研究小组"></a>中科院 自动化研究所 模式识别国家重点实验室  自然语言处理研究小组</h3><ul><li>主页：<a href="http://www.nlpr.ia.ac.cn/cip/introduction.htm" target="_blank" rel="noopener">http://www.nlpr.ia.ac.cn/cip/introduction.htm</a></li><li>Leader：<a href="http://people.ucas.ac.cn/~zongchengqing" target="_blank" rel="noopener">宗成庆</a>、<a href="http://people.ucas.ac.cn/~zhaojun" target="_blank" rel="noopener">赵军</a></li></ul><h3 id="东北大学-自然语言处理实验室"><a href="#东北大学-自然语言处理实验室" class="headerlink" title="东北大学 自然语言处理实验室"></a>东北大学 自然语言处理实验室</h3><ul><li>主页：<a href="http://www.nlplab.com/" target="_blank" rel="noopener">http://www.nlplab.com/</a></li><li>Leader：<a href="http://www.nlplab.com/members/zhujingbo.html" target="_blank" rel="noopener">朱靖波</a></li><li>代表作：<a href="http://www.niutrans.com/" target="_blank" rel="noopener">小牛翻译</a>、<a href="http://www.niuparser.com/" target="_blank" rel="noopener">中文句法语义分析系统 NiuParser</a></li></ul><h3 id="苏州大学-自然语言处理实验室"><a href="#苏州大学-自然语言处理实验室" class="headerlink" title="苏州大学 自然语言处理实验室"></a>苏州大学 自然语言处理实验室</h3><ul><li>主页：<a href="http://nlp.suda.edu.cn/member.html" target="_blank" rel="noopener">http://nlp.suda.edu.cn/member.html</a> </li><li>Leader：<a href="http://nlp.suda.edu.cn/~gdzhou/" target="_blank" rel="noopener">周国栋</a>、<a href="http://ckc.suda.edu.cn/~qmzhu/" target="_blank" rel="noopener">朱巧明</a></li></ul><h2 id="工业界"><a href="#工业界" class="headerlink" title="工业界"></a>工业界</h2><h3 id="华为-NOAH’S-ARK-LAB"><a href="#华为-NOAH’S-ARK-LAB" class="headerlink" title="华为 NOAH’S ARK LAB"></a>华为 NOAH’S ARK LAB</h3><ul><li>主页：<a href="http://www.noahlab.com.hk/" target="_blank" rel="noopener">http://www.noahlab.com.hk/</a></li><li>Leader：<del><a href="https://scholar.google.com/citations?user=nTl5mSwAAAAJ&amp;hl=zh-CN" target="_blank" rel="noopener">李航</a></del>(2017.9.15更新，<a href="https://baijiahao.baidu.com/s?id=1578581689056777237" target="_blank" rel="noopener">李航从华为离职，即将加入今日头条</a>)</li></ul><h3 id="微软亚洲研究院-自然语言计算组"><a href="#微软亚洲研究院-自然语言计算组" class="headerlink" title="微软亚洲研究院 自然语言计算组"></a>微软亚洲研究院 自然语言计算组</h3><ul><li>主页：<a href="https://www.microsoft.com/en-us/research/group/natural-language-computing/" target="_blank" rel="noopener">https://www.microsoft.com/en-us/research/group/natural-language-computing/</a></li><li>Leader：<a href="https://www.microsoft.com/en-us/research/people/mingzhou/" target="_blank" rel="noopener">周明</a></li></ul><h3 id="腾讯-人工智能实验室"><a href="#腾讯-人工智能实验室" class="headerlink" title="腾讯 人工智能实验室"></a>腾讯 人工智能实验室</h3><ul><li>主页：<a href="http://ai.tencent.com/ailab/index.html" target="_blank" rel="noopener">http://ai.tencent.com/ailab/index.html</a></li><li>Leader：<a href="https://scholar.google.com/citations?hl=zh-CN&amp;user=LurWtuYAAAAJ" target="_blank" rel="noopener">张潼</a></li></ul><h3 id="今日头条-人工智能实验室"><a href="#今日头条-人工智能实验室" class="headerlink" title="今日头条 人工智能实验室"></a>今日头条 人工智能实验室</h3><ul><li>主页：<a href="http://lab.toutiao.com/" target="_blank" rel="noopener">http://lab.toutiao.com/</a></li><li>Leader：<a href="http://www.cs.cmu.edu/~./leili/" target="_blank" rel="noopener">李磊</a></li></ul><h3 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h3><ul><li>其实现在很多公司都开始在AI, NLP方向发力，比如：<strong>百度</strong>、<strong>搜狗</strong>，还有像<strong>科大讯飞</strong>这样在语音识别等领域深耕多年的公司，我相信未来还会涌现出大量创业公司，在人工智能的大潮中分一杯羹。</li></ul><blockquote><p>初步统计，如有遗漏请补充（排名不分先后）</p></blockquote><p>参考链接：<br><a href="https://www.zhihu.com/question/24366306" target="_blank" rel="noopener">https://www.zhihu.com/question/24366306</a><br><a href="http://blog.csdn.net/wangxinginnlp/article/details/44890553" target="_blank" rel="noopener">http://blog.csdn.net/wangxinginnlp/article/details/44890553</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;最近在看CCKS2017评测任务的成绩时，想查一下国内NLP方面比较厉害的课题组或者实验室，记录一下。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;学术界&quot;&gt;&lt;a href=&quot;#学术界&quot; class=&quot;headerlink&quot; title=&quot;
      
    
    </summary>
    
      <category term="技术向" scheme="https://oyeblog.com/categories/%E6%8A%80%E6%9C%AF%E5%90%91/"/>
    
    
      <category term="NLP" scheme="https://oyeblog.com/tags/NLP/"/>
    
  </entry>
  
  <entry>
    <title>Hexo 主题推荐</title>
    <link href="https://oyeblog.com/2017/hexo_theme/"/>
    <id>https://oyeblog.com/2017/hexo_theme/</id>
    <published>2017-08-17T08:49:00.000Z</published>
    <updated>2023-10-22T07:33:12.141Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>最近已经很多次翻来覆去找比较中意，或者说想借鉴一下的Hexo主题，但是实在没有特别给力的，基本就那么几款，总结一下。</p></blockquote><h2 id="Material"><a href="#Material" class="headerlink" title="Material"></a>Material</h2><p><img src="https://cdn.jsdelivr.net/gh/oye93/oyeImg/blog/post/theme_material.PNG" alt="主页展示"><br>首先，当然是自己博客的主题，这个主题是Material风格的。<br>优点：比较简洁，也可以通过修改图片来使得风格更加小清新；功能全面，基本都涉及了。<br>不足：导航栏隐藏的比较深，每次都要点一下才看得到，我觉得主页可以直接显示导航栏。<br>链接：<a href="https://github.com/viosey/hexo-theme-material" title="Material" target="_blank" rel="noopener">Demo</a></p><h2 id="NexT"><a href="#NexT" class="headerlink" title="NexT"></a>NexT</h2><p><img src="https://cdn.jsdelivr.net/gh/oye93/oyeImg/blog/post/theme_next.PNG" alt="主页展示"><br>这个主题可能是我查的所有主题里被用的最多的了。<br>优点：非常简洁，动画过渡比较细腻，功能比较全面。<br>不足：没有我想要的相册，被用的太多，审美疲劳。<br>链接：<a href="http://notes.iissnan.com/" title="NexT" target="_blank" rel="noopener">Demo</a></p><h2 id="Yilia"><a href="#Yilia" class="headerlink" title="Yilia"></a>Yilia</h2><p><img src="https://cdn.jsdelivr.net/gh/oye93/oyeImg/blog/post/theme_yilia.PNG" alt="主页展示"><br>这个主题是我最开始想要从Jekyll转到Hexo来的原因，因为他有我想要的相册。<br>优点：简洁大方，相册很美。<br>不足：相册是和ins联动的，实现比较复杂；有些功能缺失；布局比较挤。<br>链接：<a href="https://github.com/litten/hexo-theme-yilia" title="Yilia" target="_blank" rel="noopener">Demo</a></p><h2 id="Hipaper"><a href="#Hipaper" class="headerlink" title="Hipaper"></a>Hipaper</h2><p><img src="https://raw.githubusercontent.com/iTimeTraveler/iTimeTraveler.github.io/master/gallery/hipaper-demo-screen.png" alt="主页展示"><br>这个主题看起来就比较简洁，小清新，比较符合我的审美吧。<br>不足：我不喜欢他的搜索界面。<br>链接：<a href="https://itimetraveler.github.io/hexo-theme-hipaper/" title="Hipaper" target="_blank" rel="noopener">Demo</a></p><h2 id="PPOffice"><a href="#PPOffice" class="headerlink" title="PPOffice"></a>PPOffice</h2><p><img src="https://camo.githubusercontent.com/87590b6d1e333503953847fefce757a42cceac07c2319ca9c826b3f96904b154/687474703a2f2f70706f66666963652e6769746875622e696f2f6865786f2d7468656d652d6875656d616e2f67616c6c6572792f73637265656e73686f742e6a7067" alt="主页展示"><br>这个主题是把图片展示和文字结合得比较好，给人一种紧凑的感觉。<br>优点：有一个recent的侧边栏，个人比较喜欢。<br>不足：返回顶部的按钮在最下方，有点不习惯。<br>链接：<a href="https://ppoffice.github.io/hexo-theme-hueman/" title="PPOffice" target="_blank" rel="noopener">Demo</a></p><blockquote><p>以上纯属个人观点，非喜勿喷。</p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;最近已经很多次翻来覆去找比较中意，或者说想借鉴一下的Hexo主题，但是实在没有特别给力的，基本就那么几款，总结一下。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;Material&quot;&gt;&lt;a href=&quot;#Material&quot; class=&quot;he
      
    
    </summary>
    
      <category term="分享境" scheme="https://oyeblog.com/categories/%E5%88%86%E4%BA%AB%E5%A2%83/"/>
    
    
      <category term="Hexo" scheme="https://oyeblog.com/tags/Hexo/"/>
    
      <category term="Theme" scheme="https://oyeblog.com/tags/Theme/"/>
    
  </entry>
  
  <entry>
    <title>复旦-港中大 大数据青年学者论坛</title>
    <link href="https://oyeblog.com/2017/fudan_cuhk/"/>
    <id>https://oyeblog.com/2017/fudan_cuhk/</id>
    <published>2017-08-10T08:31:00.000Z</published>
    <updated>2023-10-22T07:17:02.017Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>主题：深度学习、自然语言处理、知识图谱<br>主办：复旦大学大数据学院和香港中文大学系统工程与工程管理系</p></blockquote><p><img src="https://cdn.jsdelivr.net/gh/oye93/oyeImg/blog/post/fudan_qingnian_1.png" alt="草地大合照"></p><h2 id="特邀报告"><a href="#特邀报告" class="headerlink" title="特邀报告"></a>特邀报告</h2><p><strong>Deep Learning for Text Understanding and Machine Comprehension</strong><br>这个报告的主讲人是邱锡鹏教授，FudanNLP的作者，首先介绍了NLP相关的一些基本概念，然后聚焦他本人的研究方向—机器阅读与文本推理，讲了一些基本概念、研究进展以及现存的问题等等，主要是一个热场兼承接以下各个session的作用。</p><h2 id="Session-1"><a href="#Session-1" class="headerlink" title="Session 1"></a>Session 1</h2><p><strong>Better Context-to-Sequence Frameworks and Their Applications</strong><br>这个报告主要分以下4个部分：  </p><ul><li><em>Teacher forcing</em> 讲者主要介绍了几种常见的teacher forcing方法，以及最新的进展  </li><li><em>Adversarial Training</em>   </li><li><em>Tricks</em> 讲者介绍了摘要生成领域内，几个提高performance的小技巧：Copy Mechanism, Coverage or Diversity, Dual or Reconstruction and CNN based Seq2Seq</li><li><em>Application</em> 讲者介绍了自己将以上方法和技巧运用在研究中的一些情况。  </li></ul><p><strong>Neural Representation Learning in NLP</strong><br>这个报告主要介绍了NLP里的Representation问题。从word, phrase, sentence, sentence pair 4个层次分别介绍。在word层次讲到了针对不同task可能需要特化embedding的学习，然后有提及x-word2vec，也就是引进外部知识（如：topic等）进行word2vec的训练。接下来是phrase和sentence层次。</p><blockquote><blockquote><p>这里还有一个亮点，就是台下有人提问说如今NLP领域大家用的方法越来越复杂，但是这些方法的语义可解释性并不强，导致某些人怀疑说NLP是否已经偏离了语言学的初衷？</p></blockquote><p>讲者的回答说很多事物都会经历一个“效果提升–质疑–解释”的过程，比如上文提到的word2vec，可解释性已经慢慢显现，所以我们有理由相信现在的方法在将来也会得到解释。我觉得这个观点是很正确的，正如现阶段的临床NLP，有些任务可能Deep Learning能够完成得很好，但是并不能用医学常识来解释，或许不久的将来，DL在临床NLP上也会得到医学解释。</p></blockquote><p><strong>Jointly Learning Word Embeddings and Latent Topics</strong><br>这个报告有点以上一个报告为基础，更加深入的介绍了Word Embedding和Topic Model之间的相互应用和相互提高，而且这种提高是反复的、持续的。主要思想是不同Topic中同一个词的意思可能不一样，那么embedding当然就不一样，这样根据Topic得到Embedding会更加准确；然后在文本分类，特别是短文本分类中，由于存在稀疏性较大的问题，引入embedding可以通过embedding相似来降低稀疏性，从而提高performance。</p><h2 id="Session-2"><a href="#Session-2" class="headerlink" title="Session 2"></a>Session 2</h2><p><strong>Microblog Summarization Using Conversation Structures</strong><br>这个报告主要做的是微博的总结（摘要式，而非生成式），用到了对话结构，提出了leader和follower的概念，其实就是找出影响比较大的几条微博，作为整个对话的总结。</p><p><strong>Who Will Come: Identify Target Users in LocationBased Services Using Hybrid Ranking and Embedding Method</strong><br>这个报告讲的是根据地理签到信息来为商家进行用户推荐，主要难点是features的异质性和稀疏性问题。</p><p><strong>Composite Task-completion Dialogue Policy Learningvia Hierarchical Reinforcement Learning</strong><br>这个报告主要是讲的对话系统（如chatbot）。用Hierarchical的方式来提高对话系统的训练效率，以及最终效果。</p><p><strong>Attention-based Recurrent Generator withGaussian Tolerance for Statistical Parametric Speech Synthesis</strong><br>这个报告主要讲的是文字到语音生成。</p><h2 id="Session-3"><a href="#Session-3" class="headerlink" title="Session 3"></a>Session 3</h2><p><strong>Key-phrase extraction using knowledge graphs</strong><br>这个报告本来是我最关注的一个，因为我自己现阶段的主要工作集中在实体抽取方面，想通过结合不同的知识来提高抽取效果。但是这个其实主要是关键词抽取，以实体识别作为基础，先选出关键词候选，再通过运用知识图谱选出真正的关键词。但是演示中出了点bug，中间一段的PPT没有播放，搞的云里雾里。</p><p><strong>Improving Quality of Knowledge Bases</strong><br>这个报告主要是讲的大型知识图谱的优化，主要有三个方面：补充、修正、更新。首先，补充主要是针对某些关系的缺失，比如is_a关系，可以通过is_a关系的推理来补充知识图谱的内容，这里讲者也说了许多方法来提高补充的准确性，比如环状关系、概念性的entity不可能is_a具体的entity等等，这里其实也涉及到了修正的问题，像前面说的提高准确度的方法，也可以用来修正知识图谱内的知识。更新主要是针对知识过期的问题，我觉得这个比较针对应用，因为应用内需要知识保持最新，比如问“美国总统是谁？”，必须回答是“川普”，如果再回答“奥巴马”就不合适了，讲者提供了一套通过先通过网络热搜找到部分热词，然后再推广到更多热词，然后去更新热词的知识。</p><p><strong>CN-DBpedia: A Never-Ending Chinese Knowledge Extraction</strong><br>最后这个报告讲的是根据百度百科的知识构建了知识图谱，主要有以下4个模块：抽取、归一化、填充、更新。其实每一块的方法都比较传统，更新模块用的是上一个报告说的方法，具体基于这个知识图谱的应用等等，可以参见<a href="http://kw.fudan.edu.cn/cndbpedia/intro/" title="CN-DBpedia" target="_blank" rel="noopener">CN-DBpedia</a></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><blockquote><p>这次的青年学者论坛虽然是第一届，个人感觉办的还是挺不错的。</p></blockquote><p>首先在讲者内容安排上，内容都是循序渐进，相互关联，比如Session 1里关于embedding的内容。 内容覆盖比较全，比如Session 3关于Knowledge Graph，让我一个从来没有接触过KG的人，可以从KG的构建、优化、应用3个方面，都有一定的了解，虽然不够详尽，但也都覆盖到了。</p><p>其次是论坛的环境，高端、大气，虽然有点小。论坛是在复旦大数据学院的一个会议室开的，有点像领导开会的地方。还有论坛的茶歇不错，哈哈。</p><p>最后，说实话，有很多知识不懂，比如teacher forcing，Adversarial Training等等。发现自己在这个领域走的还是比较浅，也可能是因为我现在做的大多数的中文医学NLP的原因，我甚至还动了想继续读博的念头，哈哈。也许这可以是一条路吧，我会继续探索。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;主题：深度学习、自然语言处理、知识图谱&lt;br&gt;主办：复旦大学大数据学院和香港中文大学系统工程与工程管理系&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn.jsdelivr.net/gh/oye93/oyeImg
      
    
    </summary>
    
      <category term="诸家堂" scheme="https://oyeblog.com/categories/%E8%AF%B8%E5%AE%B6%E5%A0%82/"/>
    
    
      <category term="Knowledge Graph" scheme="https://oyeblog.com/tags/Knowledge-Graph/"/>
    
      <category term="NLP" scheme="https://oyeblog.com/tags/NLP/"/>
    
      <category term="Deep Learning" scheme="https://oyeblog.com/tags/Deep-Learning/"/>
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="https://oyeblog.com/2017/hello_world/"/>
    <id>https://oyeblog.com/2017/hello_world/</id>
    <published>2017-08-01T11:11:00.000Z</published>
    <updated>2017-12-18T08:19:38.866Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>终于跳进Blog的坑</p></blockquote><h2 id="基于Jekyll的Blog搭建"><a href="#基于Jekyll的Blog搭建" class="headerlink" title="基于Jekyll的Blog搭建"></a>基于Jekyll的Blog搭建</h2><p>其实，拥有一个Blog的想法在脑子里已经很久了，但是并没有学过前端等等，只会写点python，想过用Django或者其他python web框架，但是一直没有时间做。一个偶然的机会看到Github Pages，百度之后发现也许这是个合适的时机和方法了。本来在github上搜到了<a href="https://github.com/Huxpro/huxpro.github.io" target="_blank" rel="noopener">Hux</a>的主题，这个是基于<a href="http://jekyllrb.com/" target="_blank" rel="noopener">Jekyll</a>的，查了一些资料，感觉自己修改起来会比较方便，于是就拿过来用了。配置还是比较简单，直接按照作者的readme来就好，在电脑上架好模板之后，就是自己定制的一些东西了，主要有以下几点：</p><ul><li><strong>修改图片</strong> 模板是比较文艺、简洁的，在<a href="https://unsplash.com/" target="_blank" rel="noopener">Unsplash</a>找了几张喜欢的图替换上，修改了ico，修改了模板作者的头像，换上自己的挫照。</li><li><strong>修改页面图标</strong> 因为不玩知乎等等，所以直接把footer里的图标改成了RSS和e-mail，也改了一下copyright等的写法。</li><li><strong>增加Categories页面</strong> 在看其他blog的时候，发现了大部分的Blog都有Categories页面，于是参考<a href="http://brucezhaor.github.io/" target="_blank" rel="noopener">Bruce Zhao’s Blog</a>加入Categories页面。</li><li><strong>增加Search</strong> 也是在看别人的Blog时(哈哈，自己做东西也要参考一下别人的嘛)发现有很多Blog都有Search的功能，我也觉得这是必要的，本想参照<a href="http://brucezhaor.github.io/" target="_blank" rel="noopener">Bruce Zhao’s Blog</a>直接加一个Search页面，但是觉得不方便，后来看到<a href="http://mazhuang.org/" target="_blank" rel="noopener">码志</a>，觉得在侧边栏加Search就好，又觉得码志的不太简洁，于是结合以上两个Blog，在侧边栏加入<a href="http://brucezhaor.github.io/" target="_blank" rel="noopener">Bruce Zhao’s Blog</a>风格的Search。</li><li><strong>增加back-to-top按钮</strong> 个人觉得回到top的功能还是比较重要的，所以查了一些方法，加入成功。</li><li><strong>Home页面增加缩略图</strong> 觉得原作者只展示缩略文字比较单调，想加入缩略图来丰富一下主页，自己查了查加上了，感觉还行。</li><li><strong>针对移动端设备优化显示效果</strong> 主要是上一条加入缩略图之后，在手机页面上比较难看，后来发现原作者也是对网页在移动端展示做了优化，比如移动端是不展示侧边栏的，于是找了源代码，参照着把首页缩略图以及侧边栏Search进行了同样的优化，比较满意。</li><li><strong>注册域名</strong> 自己在万网上注册了一个域名<a href="http://oyeblog.com">oyeblog.com</a>，然后找了重定向教程，把域名绑定，到这一步总算是把Blog搭好。<blockquote><p>到上一步，其实已经把Blog搭得差不多了。但是谁叫我爱折腾呢，在网上看到一个<a href="http://litten.me/photos/" target="_blank" rel="noopener">Blog的相册</a>特别好看，然后心痒痒想自己也搞一个，毕竟咱也是半个文艺青年嘛。然后开始查基于Jekyll的相册模块，实在没有我喜欢的，想移植又没有技能，最后转向<a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>，因为之前找到的Blog是基于Hexo的，又开始一顿折腾。</p></blockquote></li></ul><h2 id="转移到Hexo"><a href="#转移到Hexo" class="headerlink" title="转移到Hexo"></a>转移到Hexo</h2><p>本来想想直接用上文提到的<a href="https://github.com/litten/hexo-theme-yilia" target="_blank" rel="noopener">Blog Theme</a>，然后发现他是从ins上直接拿图，而且其他方面又不喜欢。接着开始一轮Hexo的主题搜索，找到一个比较心仪的<a href="https://github.com/viosey/hexo-theme-material" target="_blank" rel="noopener">Theme</a>，也有比较好的相册模块，对移动端阅读支持也比较好，接下来就是根据作者的<a href="https://material.viosey.com/start/" target="_blank" rel="noopener">文档</a>一步一步配置，不得不说作者的文档真的超级详细，超级具体。以下是自己的几点变化：</p><ul><li><strong>修改图片</strong> 作者的风格是Material，所以一些默认的header图片也是同样风格，但是我还是喜欢之前Unsplash的风格，所以把很多图片都替换了，换了自己的挫照和Logo。</li><li><strong>增加图床</strong> 在网上搜索的时候发现大部分博主都会把自己的图片上传到图床，以便CDN加速。于是为了长远考虑，我自己也注册了<a href="https://www.qiniu.com/" target="_blank" rel="noopener">七牛</a>，把相册的图片传上去了。然后在想加入CDN加速的时候，发现域名必须备案才能加速，然而我部署在github上又不能备案，最终只能作罢，不绑定我的域名到CDN加速了。</li><li><strong>部署在Coding.net</strong> 个人感觉访问比较慢，网上搜了一些加速的方法，发现部署在<a href="https://coding.net" title="码市" target="_blank" rel="noopener">Coding.net</a>上可以加快访问速度，于是按照<a href="https://blog.yuanbin.me/posts/2014/05/multi-deployment-with-hexo.html" title="使用Github和GitCafe同时托管博客" target="_blank" rel="noopener">网上教程</a>部署了一下，并且绑定了域名。</li></ul><blockquote><p>希望以后可以多写写画画，不浪费自己搭的Bolg</p></blockquote><h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><p>经过两种不同框架搭建Blog，发现Hexo的逻辑比Jekyll复杂一点，毕竟有theme模块，但是这样也就移植性也会比较好。其实感觉有了Blog之后，就会有一种小小的使命感，想把东西都放进来，虽然估计也不会有人看，但是毕竟自己做的，有事没事自己刷刷，耗耗流量，哈哈！希望养成记录生活，记录学习，记录工作的好习惯。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;终于跳进Blog的坑&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;基于Jekyll的Blog搭建&quot;&gt;&lt;a href=&quot;#基于Jekyll的Blog搭建&quot; class=&quot;headerlink&quot; title=&quot;基于Jekyll的Blog搭建&quot;&gt;
      
    
    </summary>
    
      <category term="自言语" scheme="https://oyeblog.com/categories/%E8%87%AA%E8%A8%80%E8%AF%AD/"/>
    
    
      <category term="Life" scheme="https://oyeblog.com/tags/Life/"/>
    
      <category term="Jekyll" scheme="https://oyeblog.com/tags/Jekyll/"/>
    
      <category term="Hexo" scheme="https://oyeblog.com/tags/Hexo/"/>
    
  </entry>
  
</feed>
