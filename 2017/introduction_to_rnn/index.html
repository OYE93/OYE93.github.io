<!DOCTYPE html>
<html style="display: none;" lang="zh">
    <head>
    <meta charset="utf-8">
    <!--
        © Material Theme
        https://github.com/viosey/hexo-theme-material
        Version: 1.5.0 -->
    <script>
        window.materialVersion = "1.5.0"
        // Delete localstorage with these tags
        window.oldVersion = [
            'codestartv1',
            '1.3.4',
            '1.4.0',
            '1.4.0b1'
        ]
    </script>

    <!-- dns prefetch -->
    <meta http-equiv="x-dns-prefetch-control" content="on">

    <link rel="dns-prefetch" href="https://cdn.jsdelivr.net/npm/hexo-material@1.5.0/source"/>






        <link rel="dns-prefetch" href="https://hm.baidu.com"/>









    <!-- Title -->
    
    <title>
        
            Introduction to RNNs | 
        
        Travon&#39;s Blog
    </title>

    <!-- Meta & Info -->
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="format-detection" content="telephone=no"/>
    <meta name="theme-color" content="#616161">
    <meta name="author" content="Travon">
    <meta name="description" itemprop="description" content="">
    <meta name="keywords" content="Travon, 欧阳恩,Deep Learning,RNN,Introduction,Translation">

    <!-- Import lsloader -->
    <script>(function(){window.lsloader={jsRunSequence:[],jsnamemap:{},cssnamemap:{}};lsloader.removeLS=function(key){try{localStorage.removeItem(key)}catch(e){}};lsloader.setLS=function(key,val){try{localStorage.setItem(key,val)}catch(e){}};lsloader.getLS=function(key){var val="";try{val=localStorage.getItem(key)}catch(e){val=""}return val};versionString="/*"+(window.materialVersion||"unknownVersion")+"*/";lsloader.clean=function(){try{var keys=[];for(var i=0;i<localStorage.length;i++){keys.push(localStorage.key(i))}keys.forEach(function(key){var data=lsloader.getLS(key);if(window.oldVersion){var remove=window.oldVersion.reduce(function(p,c){return p||data.indexOf("/*"+c+"*/")!==-1},false);if(remove){lsloader.removeLS(key)}}})}catch(e){}};lsloader.clean();lsloader.load=function(jsname,jspath,cssonload,isJs){if(typeof cssonload==="boolean"){isJs=cssonload;cssonload=undefined}isJs=isJs||false;cssonload=cssonload||function(){};var code;code=this.getLS(jsname);if(code&&code.indexOf(versionString)===-1){this.removeLS(jsname);this.requestResource(jsname,jspath,cssonload,isJs);return}if(code){var versionNumber=code.split(versionString)[0];if(versionNumber!=jspath){console.log("reload:"+jspath);this.removeLS(jsname);this.requestResource(jsname,jspath,cssonload,isJs);return}code=code.split(versionString)[1];if(isJs){this.jsRunSequence.push({name:jsname,code:code});this.runjs(jspath,jsname,code)}else{document.getElementById(jsname).appendChild(document.createTextNode(code));cssonload()}}else{this.requestResource(jsname,jspath,cssonload,isJs)}};lsloader.requestResource=function(name,path,cssonload,isJs){var that=this;if(isJs){this.iojs(path,name,function(path,name,code){that.setLS(name,path+versionString+code);that.runjs(path,name,code)})}else{this.iocss(path,name,function(code){document.getElementById(name).appendChild(document.createTextNode(code));that.setLS(name,path+versionString+code)},cssonload)}};lsloader.iojs=function(path,jsname,callback){var that=this;that.jsRunSequence.push({name:jsname,code:""});try{var xhr=new XMLHttpRequest;xhr.open("get",path,true);xhr.onreadystatechange=function(){if(xhr.readyState==4){if(xhr.status>=200&&xhr.status<300||xhr.status==304){if(xhr.response!=""){callback(path,jsname,xhr.response);return}}that.jsfallback(path,jsname)}};xhr.send(null)}catch(e){that.jsfallback(path,jsname)}};lsloader.iocss=function(path,jsname,callback,cssonload){var that=this;try{var xhr=new XMLHttpRequest;xhr.open("get",path,true);xhr.onreadystatechange=function(){if(xhr.readyState==4){if(xhr.status>=200&&xhr.status<300||xhr.status==304){if(xhr.response!=""){callback(xhr.response);cssonload();return}}that.cssfallback(path,jsname,cssonload)}};xhr.send(null)}catch(e){that.cssfallback(path,jsname,cssonload)}};lsloader.iofonts=function(path,jsname,callback,cssonload){var that=this;try{var xhr=new XMLHttpRequest;xhr.open("get",path,true);xhr.onreadystatechange=function(){if(xhr.readyState==4){if(xhr.status>=200&&xhr.status<300||xhr.status==304){if(xhr.response!=""){callback(xhr.response);cssonload();return}}that.cssfallback(path,jsname,cssonload)}};xhr.send(null)}catch(e){that.cssfallback(path,jsname,cssonload)}};lsloader.runjs=function(path,name,code){if(!!name&&!!code){for(var k in this.jsRunSequence){if(this.jsRunSequence[k].name==name){this.jsRunSequence[k].code=code}}}if(!!this.jsRunSequence[0]&&!!this.jsRunSequence[0].code&&this.jsRunSequence[0].status!="failed"){var script=document.createElement("script");script.appendChild(document.createTextNode(this.jsRunSequence[0].code));script.type="text/javascript";document.getElementsByTagName("head")[0].appendChild(script);this.jsRunSequence.shift();if(this.jsRunSequence.length>0){this.runjs()}}else if(!!this.jsRunSequence[0]&&this.jsRunSequence[0].status=="failed"){var that=this;var script=document.createElement("script");script.src=this.jsRunSequence[0].path;script.type="text/javascript";this.jsRunSequence[0].status="loading";script.onload=function(){that.jsRunSequence.shift();if(that.jsRunSequence.length>0){that.runjs()}};document.body.appendChild(script)}};lsloader.tagLoad=function(path,name){this.jsRunSequence.push({name:name,code:"",path:path,status:"failed"});this.runjs()};lsloader.jsfallback=function(path,name){if(!!this.jsnamemap[name]){return}else{this.jsnamemap[name]=name}for(var k in this.jsRunSequence){if(this.jsRunSequence[k].name==name){this.jsRunSequence[k].code="";this.jsRunSequence[k].status="failed";this.jsRunSequence[k].path=path}}this.runjs()};lsloader.cssfallback=function(path,name,cssonload){if(!!this.cssnamemap[name]){return}else{this.cssnamemap[name]=1}var link=document.createElement("link");link.type="text/css";link.href=path;link.rel="stylesheet";link.onload=link.onerror=cssonload;var root=document.getElementsByTagName("script")[0];root.parentNode.insertBefore(link,root)};lsloader.runInlineScript=function(scriptId,codeId){var code=document.getElementById(codeId).innerText;this.jsRunSequence.push({name:scriptId,code:code});this.runjs()};lsloader.loadCombo=function(jslist){var updateList="";var requestingModules={};for(var k in jslist){var LS=this.getLS(jslist[k].name);if(!!LS){var version=LS.split(versionString)[0];var code=LS.split(versionString)[1]}else{var version=""}if(version==jslist[k].path){this.jsRunSequence.push({name:jslist[k].name,code:code,path:jslist[k].path})}else{this.jsRunSequence.push({name:jslist[k].name,code:null,path:jslist[k].path,status:"comboloading"});requestingModules[jslist[k].name]=true;updateList+=(updateList==""?"":";")+jslist[k].path}}var that=this;if(!!updateList){var xhr=new XMLHttpRequest;xhr.open("get",combo+updateList,true);xhr.onreadystatechange=function(){if(xhr.readyState==4){if(xhr.status>=200&&xhr.status<300||xhr.status==304){if(xhr.response!=""){that.runCombo(xhr.response,requestingModules);return}}else{for(var i in that.jsRunSequence){if(requestingModules[that.jsRunSequence[i].name]){that.jsRunSequence[i].status="failed"}}that.runjs()}}};xhr.send(null)}this.runjs()};lsloader.runCombo=function(comboCode,requestingModules){comboCode=comboCode.split("/*combojs*/");comboCode.shift();for(var k in this.jsRunSequence){if(!!requestingModules[this.jsRunSequence[k].name]&&!!comboCode[0]){this.jsRunSequence[k].status="comboJS";this.jsRunSequence[k].code=comboCode[0];this.setLS(this.jsRunSequence[k].name,this.jsRunSequence[k].path+versionString+comboCode[0]);comboCode.shift()}}this.runjs()}})();</script>

    <!-- Import queue -->
    <script>function Queue(){this.dataStore=[];this.offer=b;this.poll=d;this.execNext=a;this.debug=false;this.startDebug=c;function b(e){if(this.debug){console.log("Offered a Queued Function.")}if(typeof e==="function"){this.dataStore.push(e)}else{console.log("You must offer a function.")}}function d(){if(this.debug){console.log("Polled a Queued Function.")}return this.dataStore.shift()}function a(){var e=this.poll();if(e!==undefined){if(this.debug){console.log("Run a Queued Function.")}e()}}function c(){this.debug=true}}var queue=new Queue();</script>

    <!-- Favicons -->
    <link rel="icon shortcut" type="image/ico" href="/img/favicon.png">
    <link rel="icon" sizes="192x192" href="/img/favicon.png">
    <link rel="apple-touch-icon" href="/img/favicon.png">

    <!--iOS -->
    <meta name="apple-mobile-web-app-title" content="Title">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <meta name="HandheldFriendly" content="True">
    <meta name="MobileOptimized" content="480">

    <!-- Add to homescreen for Chrome on Android -->
    <meta name="mobile-web-app-capable" content="yes">

    <!-- Add to homescreen for Safari on iOS -->
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <meta name="apple-mobile-web-app-title" content="Travon&#39;s Blog">

    <!-- Site Verification -->
    <meta name="google-site-verification" content="t2L8DsCgKwMGZ5LZVwtyy5kVafU7EA7NgDTE_RjuRUI" />
    <meta name="baidu-site-verification" content="b065ac8e324446cb89f79f7458774207" />

    <!-- RSS -->
    

    <!--[if lte IE 9]>
        <link rel="stylesheet" href="/css/ie-blocker.css">

        
            <script src="/js/ie-blocker.zhCN.js"></script>
        
    <![endif]-->

    <!-- Import CSS -->
    
        <style id="material_css"></style><script>if(typeof window.lsLoadCSSMaxNums === "undefined")window.lsLoadCSSMaxNums = 0;window.lsLoadCSSMaxNums++;lsloader.load("material_css","https://cdn.jsdelivr.net/npm/hexo-material@1.5.0/source/css/material.min.css",function(){if(typeof window.lsLoadCSSNums === "undefined")window.lsLoadCSSNums = 0;window.lsLoadCSSNums++;if(window.lsLoadCSSNums == window.lsLoadCSSMaxNums)document.documentElement.style.display="";}, false)</script>
        <style id="style_css"></style><script>if(typeof window.lsLoadCSSMaxNums === "undefined")window.lsLoadCSSMaxNums = 0;window.lsLoadCSSMaxNums++;lsloader.load("style_css","https://cdn.jsdelivr.net/npm/hexo-material@1.5.0/source/css/style.min.css",function(){if(typeof window.lsLoadCSSNums === "undefined")window.lsLoadCSSNums = 0;window.lsLoadCSSNums++;if(window.lsLoadCSSNums == window.lsLoadCSSMaxNums)document.documentElement.style.display="";}, false)</script>

        

    

    

    <!-- Config CSS -->

<!-- Other Styles -->
<style>
  body, html {
    font-family: Roboto, "Helvetica Neue", Helvetica, "PingFang SC", "Hiragino Sans GB", "Microsoft YaHei", "微软雅黑", Arial, sans-serif;
    overflow-x: hidden !important;
  }
  
  code {
    font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
  }

  a {
    color: #00838F;
  }

  .mdl-card__media,
  #search-label,
  #search-form-label:after,
  #scheme-Paradox .hot_tags-count,
  #scheme-Paradox .sidebar_archives-count,
  #scheme-Paradox .sidebar-colored .sidebar-header,
  #scheme-Paradox .sidebar-colored .sidebar-badge{
    background-color: #616161 !important;
  }

  /* Sidebar User Drop Down Menu Text Color */
  #scheme-Paradox .sidebar-colored .sidebar-nav>.dropdown>.dropdown-menu>li>a:hover,
  #scheme-Paradox .sidebar-colored .sidebar-nav>.dropdown>.dropdown-menu>li>a:focus {
    color: #616161 !important;
  }

  #post_entry-right-info,
  .sidebar-colored .sidebar-nav li:hover > a,
  .sidebar-colored .sidebar-nav li:hover > a i,
  .sidebar-colored .sidebar-nav li > a:hover,
  .sidebar-colored .sidebar-nav li > a:hover i,
  .sidebar-colored .sidebar-nav li > a:focus i,
  .sidebar-colored .sidebar-nav > .open > a,
  .sidebar-colored .sidebar-nav > .open > a:hover,
  .sidebar-colored .sidebar-nav > .open > a:focus,
  #ds-reset #ds-ctx .ds-ctx-entry .ds-ctx-head a {
    color: #616161 !important;
  }

  .toTop {
    background: #757575 !important;
  }

  .material-layout .material-post>.material-nav,
  .material-layout .material-index>.material-nav,
  .material-nav a {
    color: #757575;
  }

  #scheme-Paradox .MD-burger-layer {
    background-color: #757575;
  }

  #scheme-Paradox #post-toc-trigger-btn {
    color: #757575;
  }

  .post-toc a:hover {
    color: #00838F;
    text-decoration: underline;
  }

</style>


<!-- Theme Background Related-->

    <style>
      body{
        background-image: url(http://otp4h8pnz.bkt.clouddn.com/bg.png-bg_80);
      }
    </style>




<!-- Fade Effect -->

    <style>
      .fade {
        transition: all 800ms linear;
        -webkit-transform: translate3d(0,0,0);
        -moz-transform: translate3d(0,0,0);
        -ms-transform: translate3d(0,0,0);
        -o-transform: translate3d(0,0,0);
        transform: translate3d(0,0,0);
        opacity: 1;
      }

      .fade.out{
        opacity: 0;
      }
    </style>


<!-- Import Font -->
<!-- Import Roboto -->

    <link href="https://fonts.googleapis.com/css?family=Roboto:300,400,500" rel="stylesheet">


<!-- Import Material Icon -->

    <style>
        @font-face {
            font-family: 'Material Icons';
            font-style: normal;
            font-weight: 400;
            src: local('Material Icons'),
            local('MaterialIcons-Regular'),
            url(https://cdn.jsdelivr.net/npm/hexo-material@1.5.0/source/fonts/MaterialIcons-Regular.woff2) format('woff2'),
            url(https://cdn.jsdelivr.net/npm/hexo-material@1.5.0/source/fonts/MaterialIcons-Regular.woff) format('woff'),
            url(https://cdn.jsdelivr.net/npm/hexo-material@1.5.0/source/fonts/MaterialIcons-Regular.ttf) format('truetype');
        }
    </style>




    <!-- Import jQuery -->
    
        <script>lsloader.load("jq_js","https://cdn.jsdelivr.net/npm/hexo-material@1.5.0/source/js/jquery.min.js", true)</script>
    

    <!-- The Open Graph protocol -->
    <meta property="og:url" content="http://oyeblog.com">
    <meta property="og:type" content="blog">
    <meta property="og:title" content="Introduction to RNNs | Travon&#39;s Blog">
    <meta property="og:image" content="http://oyeblog.com/img/favicon.png" />
    <meta property="og:description" content="">
    <meta property="og:article:tag" content="Deep Learning"> <meta property="og:article:tag" content="RNN"> <meta property="og:article:tag" content="Introduction"> <meta property="og:article:tag" content="Translation"> 

    
        <meta property="article:published_time" content="Wed Oct 11 2017 19:11:00 GMT+0800" />
        <meta property="article:modified_time" content="Mon Dec 18 2017 16:22:23 GMT+0800" />
    

    <!-- The Twitter Card protocol -->
    <meta name="twitter:title" content="Introduction to RNNs | Travon&#39;s Blog">
    <meta name="twitter:description" content="">
    <meta name="twitter:image" content="http://oyeblog.com/img/favicon.png">
    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:url" content="http://oyeblog.com" />

    <!-- Add canonical link for SEO -->
    
        <link rel="canonical" href="http://oyeblog.com/2017/introduction_to_rnn/index.html" />
    

    <!-- Structured-data for SEO -->
    
        


<script type="application/ld+json">
{
    "@context": "https://schema.org",
    "@type": "BlogPosting",
    "mainEntityOfPage": "http://oyeblog.com/2017/introduction_to_rnn/index.html",
    "headline": "Introduction to RNNs",
    "datePublished": "Wed Oct 11 2017 19:11:00 GMT+0800",
    "dateModified": "Mon Dec 18 2017 16:22:23 GMT+0800",
    "author": {
        "@type": "Person",
        "name": "Travon",
        "image": {
            "@type": "ImageObject",
            "url": "/img/avatar.png"
        },
        "description": "Hello World!"
    },
    "publisher": {
        "@type": "Organization",
        "name": "Travon&#39;s Blog",
        "logo": {
            "@type":"ImageObject",
            "url": "/img/favicon.png"
        }
    },
    "keywords": ",Deep Learning,RNN,Introduction,TranslationTravon, 欧阳恩",
    "description": "",
}
</script>


    

    <!-- Analytics -->
    
    
    

    <!-- Custom Head -->
    
        
            <script>(function(){var bp = document.createElement('script');var curProtocol = window.location.protocol.split(':')[0];if (curProtocol === 'https'){bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';}else{bp.src = 'http://push.zhanzhang.baidu.com/push.js';}var s = document.getElementsByTagName("script")[0];s.parentNode.insertBefore(bp, s);})();</script>
        
    

<link rel="stylesheet" href="/css/prism-solarizedlight.css" type="text/css">
<link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"></head>


    
        <body id="scheme-Paradox" class="lazy">
            <div class="material-layout  mdl-js-layout has-drawer is-upgraded">
                

                <!-- Main Container -->
                <main class="material-layout__content" id="main">

                    <!-- Top Anchor -->
                    <div id="top"></div>

                    
                        <!-- Hamburger Button -->
                        <button class="MD-burger-icon sidebar-toggle">
                            <span class="MD-burger-layer"></span>
                        </button>
                    

                    <!-- Post TOC -->

    
    <!-- Back Button -->
    <!--
    <div class="material-back" id="backhome-div" tabindex="0">
        <a class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon"
           href="#" onclick="window.history.back();return false;"
           target="_self"
           role="button"
           data-upgraded=",MaterialButton,MaterialRipple">
            <i class="material-icons" role="presentation">arrow_back</i>
            <span class="mdl-button__ripple-container">
                <span class="mdl-ripple"></span>
            </span>
        </a>
    </div>
    -->


    <!-- Left aligned menu below button -->
    
    
    <button id="post-toc-trigger-btn"
        class="mdl-button mdl-js-button mdl-button--icon">
        <i class="material-icons">format_list_numbered</i>
    </button>

    <ul class="post-toc-wrap mdl-menu mdl-menu--bottom-left mdl-js-menu mdl-js-ripple-effect" for="post-toc-trigger-btn" style="max-height:80vh; overflow-y:scroll;">
        <ol class="post-toc"><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#What-are-RNNs"><span class="post-toc-number">1.</span> <span class="post-toc-text"><a href="#What-are-RNNs" class="headerlink" title="What are RNNs?"></a>What are RNNs?</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#What-can-RNNs-do"><span class="post-toc-number">2.</span> <span class="post-toc-text"><a href="#What-can-RNNs-do" class="headerlink" title="What can RNNs do?"></a>What can RNNs do?</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Language-Modeling-and-Generating-Text"><span class="post-toc-number">2.1.</span> <span class="post-toc-text"><a href="#Language-Modeling-and-Generating-Text" class="headerlink" title="Language Modeling and Generating Text"></a>Language Modeling and Generating Text</span></a></li></ol></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#Machine-Translation"><span class="post-toc-number">3.</span> <span class="post-toc-text"><a href="#Machine-Translation" class="headerlink" title="Machine Translation"></a>Machine Translation</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Speech-Recognition"><span class="post-toc-number">3.1.</span> <span class="post-toc-text"><a href="#Speech-Recognition" class="headerlink" title="Speech Recognition"></a>Speech Recognition</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Generating-Image-Descriptions"><span class="post-toc-number">3.2.</span> <span class="post-toc-text"><a href="#Generating-Image-Descriptions" class="headerlink" title="Generating Image Descriptions"></a>Generating Image Descriptions</span></a></li></ol></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#Training-RNNs"><span class="post-toc-number">4.</span> <span class="post-toc-text"><a href="#Training-RNNs" class="headerlink" title="Training RNNs"></a>Training RNNs</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#RNN-Extensions"><span class="post-toc-number">5.</span> <span class="post-toc-text"><a href="#RNN-Extensions" class="headerlink" title="RNN Extensions"></a>RNN Extensions</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Bidirectional-RNN"><span class="post-toc-number">5.1.</span> <span class="post-toc-text"><a href="#Bidirectional-RNN" class="headerlink" title="Bidirectional RNN"></a>Bidirectional RNN</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Deep-Bidirectional-RNN"><span class="post-toc-number">5.2.</span> <span class="post-toc-text"><a href="#Deep-Bidirectional-RNN" class="headerlink" title="Deep Bidirectional RNN"></a>Deep Bidirectional RNN</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#LSTM-networks"><span class="post-toc-number">5.3.</span> <span class="post-toc-text"><a href="#LSTM-networks" class="headerlink" title="LSTM networks"></a>LSTM networks</span></a></li></ol></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#Conclusion"><span class="post-toc-number">6.</span> <span class="post-toc-text"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</span></a></li></ol>
    </ul>
    




<!-- Layouts -->

    <!-- Post Module -->
    <div class="material-post_container">

        <div class="material-post mdl-grid">
            <div class="mdl-card mdl-shadow--4dp mdl-cell mdl-cell--12-col">

                <!-- Post Header(Thumbnail & Title) -->
                
    <!-- Paradox Post Header -->
    
        <!-- Custom Thumbnail -->
        <div class="post_thumbnail-custom mdl-card__media mdl-color-text--grey-50" style="background-image:url(http://otp4h8pnz.bkt.clouddn.com/rnn_introduction_header.jpg)">
    
            <p class="article-headline-p">
                Introduction to RNNs
            </p>
        </div>





                
                    <!-- Paradox Post Info -->
                    <div class="mdl-color-text--grey-700 mdl-card__supporting-text meta">

    <!-- Author Avatar -->
    <div id="author-avatar">
        <img src="/img/avatar.png" width="44px" height="44px" alt="Author Avatar"/>
    </div>
    <!-- Author Name & Date -->
    <div>
        <strong>Travon</strong>
        <span>10月 11, 2017</span>
    </div>

    <div class="section-spacer"></div>

    <!-- Favorite -->
    <!--
        <button id="article-functions-like-button" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon btn-like">
            <i class="material-icons" role="presentation">favorite</i>
            <span class="visuallyhidden">favorites</span>
        </button>
    -->

    <!-- Qrcode -->
    
        <button id="article-functions-qrcode-button" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon">
    <i class="material-icons" role="presentation">devices other</i>
    <span class="visuallyhidden">devices other</span>
</button>
<ul class="mdl-menu mdl-menu--bottom-right mdl-js-menu mdl-js-ripple-effect" for="article-functions-qrcode-button">
    <li class="mdl-menu__item">在其它设备中阅读本文章</li>
    
        <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAN4AAADeCAAAAAB3DOFrAAACY0lEQVR42u3a0W7CMAwFUP7/p7fXSRNwr5NmHTp5QlBKTpFiy/bj66PXAw8PDw8PDw8P72a8R7ye3u7Hp7+v/H2HZ3d7/d18b3h4eHhneG+O2uUNtXde2RseHh7eSd6zbb1+/eaYDgDJd5O94eHh4f0XXpJkz5B4eHh4n8RLAkCbcN8oMODh4eFtLUbk168UcP+s1oKHh4cX8/Im0/nXR/t7eHh4eAGvXbOEOLlPEgaiHeLh4eFdzMsP4nX8bDyrHkfAw8PDO86bFVXzsm87wpU8Ajw8PLw78GaN/7YIu7cJh4eHh3cHXs7Ij/6VK7el1Hh4eHgX8DYUBYKkPE/Qi0eDh4eHdzGvTaCTpLndaHv0vwlUeHh4eBfzVppSLXhWjGgTazw8PLyreXnzqQ0AM1hb+MDDw8M7z5uluXnASAoZ+afRH4OHh4d3MW/WmpoNFuQhZPYg8PDw8M7w8uN+ZchgFnIuGbrCw8PDW+bl5YM2sc7XrIBbxz08PDy8Tbw8dW7Lvq/LE22aXowU4OHh4R3knT/0Zw2wukqNh4eHdzFv7zv5gT573NtqLXh4eHhbee0P5EWNvExcXImHh4d3nFc06YP3Z1vPf31DMQIPDw+v5LWrDQZtaGnLylF/Dw8PD28rb3YotyMFeeBJGPVMGR4eHt4FvLa02pYwZiWJdrwADw8P7zxv1tQvxqGWA8a2BhgeHh7ecd5KCXhW9i0Sdzw8PLxb8tqWWJtetyEHDw8P7694s6ZX26DKH0c+xICHh4d3nrehBBAPSCUpdVuYwMPDwzvJ+7yFh4eHh4eHh4d3g/UNZFEWEaK50REAAAAASUVORK5CYII=">
    
</ul>

    

    <!-- Tags (bookmark) -->
    
    <button id="article-functions-viewtags-button" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon">
        <i class="material-icons" role="presentation">bookmark</i>
        <span class="visuallyhidden">bookmark</span>
    </button>
    <ul class="mdl-menu mdl-menu--bottom-right mdl-js-menu mdl-js-ripple-effect" for="article-functions-viewtags-button">
        <li class="mdl-menu__item">
        <a class="post_tag-link" href="/tags/Deep-Learning/">Deep Learning</a></li><li class="mdl-menu__item"><a class="post_tag-link" href="/tags/Introduction/">Introduction</a></li><li class="mdl-menu__item"><a class="post_tag-link" href="/tags/RNN/">RNN</a></li><li class="mdl-menu__item"><a class="post_tag-link" href="/tags/Translation/">Translation</a>
    </ul>
    

    <!-- Share -->
    <button id="article-fuctions-share-button" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon">
    <i class="material-icons" role="presentation">share</i>
    <span class="visuallyhidden">share</span>
</button>
<ul class="mdl-menu mdl-menu--bottom-right mdl-js-menu mdl-js-ripple-effect" for="article-fuctions-share-button">
    

    

    <!-- Share Weibo -->
    
        <a class="post_share-link" href="http://service.weibo.com/share/share.php?appkey=&title=Introduction to RNNs&url=http://oyeblog.com/2017/introduction_to_rnn/index.html&pic=http://oyeblog.com/img/favicon.png&searchPic=false&style=simple" target="_blank">
            <li class="mdl-menu__item">
                分享到微博
            </li>
        </a>
    

    <!-- Share Twitter -->
    
        <a class="post_share-link" href="https://twitter.com/intent/tweet?text=Introduction to RNNs&url=http://oyeblog.com/2017/introduction_to_rnn/index.html&via=Travon" target="_blank">
            <li class="mdl-menu__item">
                分享到 Twitter
            </li>
        </a>
    

    <!-- Share Facebook -->
    
        <a class="post_share-link" href="https://www.facebook.com/sharer/sharer.php?u=http://oyeblog.com/2017/introduction_to_rnn/index.html" target="_blank">
            <li class="mdl-menu__item">
                分享到 Facebook
            </li>
        </a>
    

    <!-- Share Google+ -->
    
        <a class="post_share-link" href="https://plus.google.com/share?url=http://oyeblog.com/2017/introduction_to_rnn/index.html" target="_blank">
            <li class="mdl-menu__item">
                分享到 Google+
            </li>
        </a>
    

    <!-- Share LinkedIn -->
    

    <!-- Share QQ -->
    

    <!-- Share Telegram -->
    
</ul>

</div>

                

                <!-- Post Content -->
                <div id="post-content" class="mdl-color-text--grey-700 mdl-card__supporting-text fade out">
    
        <blockquote>
<p>最近在找关于deep learning的基础知识看，找到一个比较推荐的<a href="http://www.wildml.com" title="WILDML" target="_blank" rel="noopener">英文博客</a>介绍，为了加深一下映象，决定翻译一遍。采取中英文对照的形式。</p>
</blockquote>
<h2 id="What-are-RNNs"><a href="#What-are-RNNs" class="headerlink" title="What are RNNs?"></a>What are RNNs?</h2><p><em>The idea behind RNNs is to make use of sequential information. In a traditional neural network we assume that all inputs (and outputs) are independent of each other. But for many tasks that’s a very bad idea. If you want to predict the next word in a sentence you better know which words came before it. RNNs are called recurrent because they perform the same task for every element of a sequence, with the output being depended on the previous computations. Another way to think about RNNs is that they have a “memory” which captures information about what has been calculated so far. In theory RNNs can make use of information in arbitrarily long sequences, but in practice they are limited to looking back only a few steps (more on this later). Here is what a typical RNN looks like:</em></p>
<p>Recurrent Neural Networks (RNNs)背后的思想是充分利用序列信息。在传统的神经网络中，我们是假设所有的输入（或者输出）之间是相互独立的。但是在一些任务中，这个假设是非常不合理的。比如，如果你想预测某个句子中的下一个词，那么最好能知道这个词的前一个词是什么。RNN之所以叫循环的（recurrent），是因为它对于序列中的每一个元素执行相同的操作，而且输出是依赖于前一步的计算。也可以从另一种角度来理解RNN，就是它拥有记忆前面所有计算得到的信息的能力。理论上，RNN可以利用任意长度序列中的信息，但是在实践中只能回溯到有限的几步。下面是一个典型的RNN图示：<br><img src="http://d3kbpzbmcynnmx.cloudfront.net/wp-content/uploads/2015/09/rnn.jpg" alt="" title="RNN"><br>Source: Nature</p>
<p><em>The above diagram shows a RNN being unrolled (or unfolded) into a full network. By unrolling we simply mean that we write out the network for the complete sequence. For example, if the sequence we care about is a sentence of 5 words, the network would be unrolled into a 5-layer neural network, one layer for each word. The formulas that govern the computation happening in a RNN are as follows:</em></p>
<p>上面的图展示了一个RNN展开成全网络的情况。通过展开，我们简单的把整个序列表示成网络形式。举个例子，如果序列的长度是5，那么整个网络会被展开成5层，每一层对应一个词。图中的参数以及一些计算公式如下：</p>
<p><em>$x_t$ is the input at time step $t$. For example, $x_1$ could be a one-hot vector corresponding to the second word of a sentence.<br>$s_t$ is the hidden state at time step $t$. It’s the “memory” of the network. $s_t$ is calculated based on the previous hidden state and the input at the current step: $s_t=f(Ux_t + Ws_{t-1})$. The function $f$ usually is a nonlinearity such as <a href="https://reference.wolfram.com/language/ref/Tanh.html" target="_blank" rel="noopener">tanh</a> or <a href="https://en.wikipedia.org/wiki/Rectifier_(neural_networks)" target="_blank" rel="noopener">ReLU</a>.  $s_{-1}$, which is required to calculate the first hidden state, is typically initialized to all zeroes.<br>$o_t$ is the output at step $t$. For example, if we wanted to predict the next word in a sentence it would be a vector of probabilities across our vocabulary. $o_t = \mathrm{softmax}(Vs_t)$.<br>There are a few things to note here:</em></p>
<p>$x_t$ 是在时间步骤 $t$ 的输入。比如： $x_1$ 可能就是一个句子中的第二个词的one-hot向量。<br>$s_t$ 是时间步骤 $t$ 的隐含状态，也就是这个网络的“记忆”。$s_t$ 是基于前一个隐含状态和当前步骤的输入计算得到，计算公式：$s_t=f(Ux_t + Ws_{t-1})$。公式 $f$ 一般是非线性函数，比如：<a href="https://reference.wolfram.com/language/ref/Tanh.html" target="_blank" rel="noopener">tanh</a> 或者 <a href="https://en.wikipedia.org/wiki/Rectifier_(neural_networks)" target="_blank" rel="noopener">ReLU</a>。$s_{-1}$ 是在计算第一个隐含状态是需要的值，会被初始化为0。<br>$o_t$ 是步骤$t$的输出。比如，如果我们想预测一个句子中的下一个词，那么 $o_t$ 可能就是一个基于整个词汇集的概率向量。公式：$o_t = \mathrm{softmax}(Vs_t)$<br>下面是需要注意的几点：</p>
<p><em>You can think of the hidden state $s_t$ as the memory of the network. $s_t$ captures information about what happened in all the previous time steps. The output at step $o_t$ is calculated solely based on the memory at time $t$. As briefly mentioned above, it’s a bit more complicated in practice because $s_t$ typically can’t capture information from too many time steps ago.</em></p>
<p>我们可以把隐含状态 $s_t$ 看成是网络的记忆。$s_t$ 能获取前面所有时间步骤中的所有信息。时间步骤 $t$ 的输出 $o_t$ 只基于时间 $t$ 的记忆计算得到。就像上面提到的，实际操作中会更加复杂，因为 $s_t$ 并不能获得太多时间步骤前的信息。</p>
<p><em>Unlike a traditional deep neural network, which uses different parameters at each layer, a RNN shares the same parameters ($U$, $V$, $W$ above) across all steps. This reflects the fact that we are performing the same task at each step, just with different inputs. This greatly reduces the total number of parameters we need to learn.</em></p>
<p>不像传统的深度神经网络那样在每层都采用不同的参数，RNN在所有步骤中都是用的相同的参数集（上图中的$U$, $V$, $W$）。这反映的事实就是我们在每步都进行了相同的操作，只是每步的输入不一样。这使得要学习的参数数量大大降低。</p>
<p><em>The above diagram has outputs at each time step, but depending on the task this may not be necessary. For example, when predicting the sentiment of a sentence we may only care about the final output, not the sentiment after each word. Similarly, we may not need inputs at each time step. The main feature of an RNN is its hidden state, which captures some information about a sequence.</em></p>
<p>上图中每个步骤都有输出，但是基于不同的任务并不是每个步骤都需要输出的。比如在做句子情感分析的时候，我们只关心最终的输出，而不是每个词的情感分析结果。类似的，我们也不需要每个步骤都有输入。RNN的一个主要特征就是隐含状态，这样能够获得整个序列的某些信息。</p>
<h2 id="What-can-RNNs-do"><a href="#What-can-RNNs-do" class="headerlink" title="What can RNNs do?"></a>What can RNNs do?</h2><p><em>RNNs have shown great success in many NLP tasks. At this point I should mention that the most commonly used type of RNNs are LSTMs, which are much better at capturing long-term dependencies than vanilla RNNs are. But don’t worry, LSTMs are essentially the same thing as the RNN we will develop in this tutorial, they just have a different way of computing the hidden state. We’ll cover LSTMs in more detail in a later post. Here are some example applications of RNNs in NLP (by non means an exhaustive list).</em></p>
<p>RNN已经在很多的NLP任务中取得了成功。最常用的RNN是LSTM，它比获取长依赖信息上比vanilla RNNs表现更好。但是，LSTM和我们想建立的RNN模型实际上是一样的，只是用了不同的方法来计算隐含状态。我们会在后面讨论LSTM的更多细节。下面是RNN在NLP领域上应用的例子。</p>
<h3 id="Language-Modeling-and-Generating-Text"><a href="#Language-Modeling-and-Generating-Text" class="headerlink" title="Language Modeling and Generating Text"></a>Language Modeling and Generating Text</h3><p><em>Given a sequence of words we want to predict the probability of each word given the previous words. Language Models allow us to measure how likely a sentence is, which is an important input for Machine Translation (since high-probability sentences are typically correct). A side-effect of being able to predict the next word is that we get a generative model, which allows us to generate new text by sampling from the output probabilities. And depending on what our training data is we can generate all kinds of stuff. In Language Modeling our input is typically a sequence of words (encoded as one-hot vectors for example), and our output is the sequence of predicted words. When training the network we set $o_t = x_{t+1}$ since we want the output at step $t$ to be the actual next word.</em></p>
<p><strong>语言建模和文本生成</strong> 给定一个词序列，我们想预测每个词出现在它前一个词后面的概率。语言模型可以让我们能够估算一个句子有多像一个正常的句子（<em>或者说符合语法、符合自然语言的句子</em>），这在机器翻译中是十分重要的（因为更高的可能性指正着更高的准确率）。预测下一个词的功能带来的另一个功能就是我们也可以得到一个生成模型，使得我们可以根据输出概率来生成新的文本。而且，根据我们的训练数据的不同，可以生成各种各样的文本素材。在语言模型中，我们的输入通常是词序列（比如：编码成one-hot的向量），输出就是预测词的序列。在训练整个网络的时候，我们设置 $o_t = x_{t+1}$ ，因为我们想得到步骤 $t$ 的输出就是下一个词。</p>
<p><em>Research papers about Language Modeling and Generating Text:</em></p>
<p>关于语言建模和文本生成的文章：</p>
<ul>
<li><a href="http://www.fit.vutbr.cz/research/groups/speech/publi/2010/mikolov_interspeech2010_IS100722.pdf" target="_blank" rel="noopener">Recurrent neural network based language model</a>  </li>
<li><a href="http://www.fit.vutbr.cz/research/groups/speech/publi/2011/mikolov_icassp2011_5528.pdf" target="_blank" rel="noopener">Extensions of Recurrent neural network based language model</a>  </li>
<li><a href="http://machinelearning.wustl.edu/mlpapers/paper_files/ICML2011Sutskever_524.pdf" target="_blank" rel="noopener">Generating Text with Recurrent Neural Networks</a></li>
</ul>
<h2 id="Machine-Translation"><a href="#Machine-Translation" class="headerlink" title="Machine Translation"></a>Machine Translation</h2><p><em>Machine Translation is similar to language modeling in that our input is a sequence of words in our source language (e.g. German). We want to output a sequence of words in our target language (e.g. English). A key difference is that our output only starts after we have seen the complete input, because the first word of our translated sentences may require information captured from the complete input sequence.</em></p>
<p><strong>机器翻译</strong> 和语言建模比较类似。只是在机器翻译中，我们的输入是源语言（比如：德语）的词序列，而我们想得到的输出是目标语言（比如：英语）的词序列。关键的不同在于我们的输出是在看了所有的输入之后进行，因为翻译的句子的第一个词有可能需要整个输入序列的信息。</p>
<p><img src="http://d3kbpzbmcynnmx.cloudfront.net/wp-content/uploads/2015/09/Screen-Shot-2015-09-17-at-10.39.06-AM.png" alt="" title="RNN for Machine Translation"><br>Source: <a href="http://cs224d.stanford.edu/lectures/CS224d-Lecture8.pdf" target="_blank" rel="noopener">http://cs224d.stanford.edu/lectures/CS224d-Lecture8.pdf</a></p>
<p><em>Research papers about Machine Translation:</em></p>
<p>关于机器翻译的文章：</p>
<ul>
<li><a href="http://www.aclweb.org/anthology/P14-1140.pdf" target="_blank" rel="noopener">A Recursive Recurrent Neural Network for Statistical Machine Translation</a></li>
<li><a href="http://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf" target="_blank" rel="noopener">Sequence to Sequence Learning with Neural Networks</a></li>
<li><a href="http://research.microsoft.com/en-us/um/people/gzweig/Pubs/EMNLP2013RNNMT.pdf" target="_blank" rel="noopener">Joint Language and Translation Modeling with Recurrent Neural Networks</a></li>
</ul>
<h3 id="Speech-Recognition"><a href="#Speech-Recognition" class="headerlink" title="Speech Recognition"></a>Speech Recognition</h3><p><em>Given an input sequence of acoustic signals from a sound wave, we can predict a sequence of phonetic segments together with their probabilities.</em></p>
<p><strong>语音识别</strong> 给定从声波中得到的声形信号序列，预测语音片段序列，以及概率。</p>
<p><em>Research papers about Speech Recognition:</em></p>
<p>关于语音识别的文章：</p>
<ul>
<li><a href="http://www.jmlr.org/proceedings/papers/v32/graves14.pdf" target="_blank" rel="noopener">Towards End-to-End Speech Recognition with Recurrent Neural Networks</a></li>
</ul>
<h3 id="Generating-Image-Descriptions"><a href="#Generating-Image-Descriptions" class="headerlink" title="Generating Image Descriptions"></a>Generating Image Descriptions</h3><p><em>Together with convolutional Neural Networks, RNNs have been used as part of a model to generate descriptions for unlabeled images. It’s quite amazing how well this seems to work. The combined model even aligns the generated words with features found in the images.</em></p>
<p><strong>生成图片描述</strong> 结合卷积神经网络，RNN开始被作为未标注图片的描述生成模型的一部分，而且取得令人惊喜的结果。这个联合模型甚至可以把生成的文字和找到的图片特征整合起来。</p>
<p><img src="http://d3kbpzbmcynnmx.cloudfront.net/wp-content/uploads/2015/09/Screen-Shot-2015-09-17-at-11.44.24-AM.png" alt="" title="Deep Visual-Semantic Alignments for Generating Image Descriptions"><br>Source: <a href="http://cs.stanford.edu/people/karpathy/deepimagesent/" target="_blank" rel="noopener">http://cs.stanford.edu/people/karpathy/deepimagesent/</a></p>
<h2 id="Training-RNNs"><a href="#Training-RNNs" class="headerlink" title="Training RNNs"></a>Training RNNs</h2><p><em>Training a RNN is similar to training a traditional Neural Network. We also use the backpropagation algorithm, but with a little twist. Because the parameters are shared by all time steps in the network, the gradient at each output depends not only on the calculations of the current time step, but also the previous time steps. For example, in order to calculate the gradient at <code>t=4</code> we would need to backpropagate 3 steps and sum up the gradients. This is called Backpropagation Through Time (BPTT). If this doesn’t make a whole lot of sense yet, don’t worry, we’ll have a whole post on the gory details. For now, just be aware of the fact that vanilla RNNs trained with BPTT have difficulties learning long-term dependencies (e.g. dependencies between steps that are far apart) due to what is called the vanishing/exploding gradient problem. There exists some machinery to deal with these problems, and certain types of RNNs (like LSTMs) were specifically designed to get around them.</em></p>
<p>训练RNN模型与训练传统神经网络模型差不多，都是使用反向传播算法，但是会有点曲折。因为参数是共享的，所以每个输出的梯度不仅取决于当前步骤的计算，也取决于前面步骤的。比如，为了计算<code>t=4</code>这个时刻的梯度，需要反向传播3步，求梯度之和，这也叫做“Backpropagation Through Time (BPTT)”。如果上面的描述还令你有点困惑也不用担心，之后会有一篇详细的说明。现在只需要清楚，因为存在梯度消失和梯度爆炸的问题，用BPTT训练的vanilla RNNs模型在学习长距离依赖（比如：相距很远的步骤间的依赖）时是有困难的。当然，现在也有一些机制来解决这些问题，也有像LSTM这样类型的RNN模型专门来避开这个问题的。</p>
<h2 id="RNN-Extensions"><a href="#RNN-Extensions" class="headerlink" title="RNN Extensions"></a>RNN Extensions</h2><p><em>Over the years researchers have developed more sophisticated types of RNNs to deal with some of the shortcomings of the vanilla RNN model. We will cover them in more detail in a later post, but I want this section to serve as a brief overview so that you are familiar with the taxonomy of models.</em></p>
<p>这么多年来，研究人员已经开发了更多复杂的RNN来解决vanilla RNN中存在的不足。我们会在后续的文章中详细介绍，下面只是简单的介绍一下，让大家有个印象。</p>
<h3 id="Bidirectional-RNN"><a href="#Bidirectional-RNN" class="headerlink" title="Bidirectional RNN"></a>Bidirectional RNN</h3><p><em>Bidirectional RNNs are based on the idea that the output at time <code>t</code> may not only depend on the previous elements in the sequence, but also future elements. For example, to predict a missing word in a sequence you want to look at both the left and the right context. Bidirectional RNNs are quite simple. They are just two RNNs stacked on top of each other. The output is then computed based on the hidden state of both RNNs.</em></p>
<p><strong>双向RNNs</strong>基于的主要思想是<code>t</code>时刻的输出不仅取决于序列中前面的要素，也要考虑后面的要素。举个例子，在预测句子中的缺失词时，就要同时考虑上下文。双向RNN也比较简单，只是两层RNN相互堆叠，然后输出基于两个RNN的隐含层计算得到。</p>
<h3 id="Deep-Bidirectional-RNN"><a href="#Deep-Bidirectional-RNN" class="headerlink" title="Deep Bidirectional RNN"></a>Deep Bidirectional RNN</h3><p><em>Deep (Bidirectional) RNNs are similar to Bidirectional RNNs, only that we now have multiple layers per time step. In practice this gives us a higher learning capacity (but we also need a lot of training data).</em></p>
<p><strong>深度（双向）RNNs</strong>和双向RNNs类似，只是每个时间步骤有多层。实践中会有更高的学习能力，同时也需要更多的训练数据。</p>
<h3 id="LSTM-networks"><a href="#LSTM-networks" class="headerlink" title="LSTM networks"></a>LSTM networks</h3><p><em>LSTM networks are quite popular these days and we briefly talked about them above. LSTMs don’t have a fundamentally different architecture from RNNs, but they use a different function to compute the hidden state. The memory in LSTMs are called cells and you can think of them as black boxes that take as input the previous state $h_{t-1}$ and current input $x_t$. Internally these cells  decide what to keep in (and what to erase from) memory. They then combine the previous state, the current memory, and the input. It turns out that these types of units are very efficient at capturing long-term dependencies. LSTMs can be quite confusing in the beginning but if you’re interested in learning more this post has an excellent explanation.</em></p>
<p><strong>LSTM网络</strong>现在应用十分广泛，上面也简单提到过。LSTM从根本上来说和RNN并没有不同，只是用了不同的函数来获得隐含状态。LSTM中的记忆单元叫做cell，可以把它想象成一个黑盒，这个黑盒的输入是前面的状态$h_{t-1}$和当前的输入$x_t$。在cell的内部决定哪些信息要被保留，哪些信息要被丢弃。然后把前面的状态、当前的记忆以及输入结合起来。实践证明，这种单元在获取长距离的依赖时十分有效。刚开始，你可能会觉得LSTM十分令人困惑，但是如果你有兴趣了解更多，后续的文章会有很好的解释说明。</p>
<h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p><em>So far so good. I hope you’ve gotten a basic understanding of what RNNs are and what they can do. In the next post we’ll implement a first version of our language model RNN using Python and Theano. Please leave questions in the comments!</em></p>
<p>到此为止，我相信你们对RNN是什么，以及RNN能做什么有个大致的了解了。下一篇文章我们将利用Python和Theano完成第一个版本的RNN语言模型。欢迎提问！</p>

        
          <div class="article-statement">
            <hr>  
            <strong>本文标题: </strong><a href="/2017/introduction_to_rnn/">Introduction to RNNs</a><br>
            <strong>原始链接: </strong><a href="/2017/introduction_to_rnn/" title="Introduction to RNNs">http://oyeblog.com/2017/introduction_to_rnn/</a><br>
            <strong>发布时间: </strong>2017年10月11日 - 19时11分<br>
            
            <strong>最后更新: </strong>2017年12月18日 - 16时22分<br>
            
            <strong>版权声明: </strong>本站文章均采用<a rel="license" href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_black">CC BY-NC-SA 4.0协议</a>进行许可。转载请注明出处！<br>
          </div>
        
        
    

    
</div>


                

                <!-- Post Comments -->
                
                    
    <!-- 使用 gitcoment -->
<div id="gitment-comment">
    <!-- Gitment 评论框 -->
<div id="container"></div>
</div>
<style>
    #gitment-comment{
        background-color: #eee;
        padding: 2pc;
    }
</style>
<link rel="stylesheet" href="https://imsun.github.io/gitment/style/default.css">
<script src="https://imsun.github.io/gitment/dist/gitment.browser.js"></script>
<script>
    var gitment = new Gitment({
        //id: '页面 ID', // 可选。默认为 location.href
        owner: 'OYE93',
        repo: 'oyeblog_comments',
        oauth: {
            client_id: '900dede2d51c6ea1c0c2',
            client_secret: 'd8d7c4458ff56be873b3c9b5f45649523e3e3adc',
        },
    })
    gitment.render('container')
</script>

                
            </div>

            <!-- Post Prev & Next Nav -->
            <nav class="material-nav mdl-color-text--grey-50 mdl-cell mdl-cell--12-col">
    <!-- Prev Nav -->
    
        <a href="/2017/hexo_blog_personalize/" id="post_nav-newer" class="prev-content">
            <button class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon mdl-color--white mdl-color-text--grey-900" role="presentation">
                <i class="material-icons">arrow_back</i>
            </button>
            &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
            新篇
        </a>
    

    <!-- Section Spacer -->
    <div class="section-spacer"></div>

    <!-- Next Nav -->
    
        <a href="/2017/use_nodeppt/" id="post_nav-older" class="next-content">
            旧篇
            &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
            <button class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon mdl-color--white mdl-color-text--grey-900" role="presentation">
                <i class="material-icons">arrow_forward</i>
            </button>
        </a>
    
</nav>

        </div>
    </div>



                    
                        <!-- Overlay For Active Sidebar -->
<div class="sidebar-overlay"></div>

<!-- Material sidebar -->
<aside id="sidebar" class="sidebar sidebar-colored sidebar-fixed-left" role="navigation">
    <div id="sidebar-main">
        <!-- Sidebar Header -->
        <div class="sidebar-header header-cover" style="background-image: url(http://otp4h8pnz.bkt.clouddn.com/sidebar_header.png-bg_50);">
    <!-- Top bar -->
    <div class="top-bar"></div>

    <!-- Sidebar toggle button -->
    <button type="button" class="sidebar-toggle mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon" style="display: initial;" data-upgraded=",MaterialButton,MaterialRipple">
        <i class="material-icons">clear_all</i>
        <span class="mdl-button__ripple-container">
            <span class="mdl-ripple">
            </span>
        </span>
    </button>

    <!-- Sidebar Avatar -->
    <div class="sidebar-image">
        <img src="/img/avatar.png" alt="Travon's avatar">
    </div>

    <!-- Sidebar Email -->
    <a data-toggle="dropdown" class="sidebar-brand" href="#settings-dropdown">
        en.ouyang.travon@gmail.com
        <b class="caret"></b>
    </a>
</div>


        <!-- Sidebar Navigation  -->
        <ul class="nav sidebar-nav">
    <!-- User dropdown  -->
    <li class="dropdown">
        <ul id="settings-dropdown" class="dropdown-menu">
            
                <li>
                    <a href="mailto: en.ouyang.travon@gmail.com" target="_blank" title="Email Me">
                        
                            <i class="material-icons sidebar-material-icons sidebar-indent-left1pc-element">contact_mail</i>
                        
                        Email Me
                    </a>
                </li>
            
        </ul>
    </li>

    <!-- Homepage -->
    
        <li id="sidebar-first-li">
            <a href="/">
                
                    <i class="material-icons sidebar-material-icons">home</i>
                
                主页
            </a>
        </li>
        
    

    <!-- Archives  -->
    
        <li class="dropdown">
            <a href="#" class="ripple-effect dropdown-toggle" data-toggle="dropdown">
                
                    <i class="material-icons sidebar-material-icons">inbox</i>
                
                    归档
                <b class="caret"></b>
            </a>
            <ul class="dropdown-menu">
            <li>
                <a class="sidebar_archives-link" href="/archives/2018/07/">七月 2018<span class="sidebar_archives-count">1</span></a></li><li><a class="sidebar_archives-link" href="/archives/2018/01/">一月 2018<span class="sidebar_archives-count">2</span></a></li><li><a class="sidebar_archives-link" href="/archives/2017/12/">十二月 2017<span class="sidebar_archives-count">2</span></a></li><li><a class="sidebar_archives-link" href="/archives/2017/11/">十一月 2017<span class="sidebar_archives-count">4</span></a></li><li><a class="sidebar_archives-link" href="/archives/2017/10/">十月 2017<span class="sidebar_archives-count">2</span></a></li><li><a class="sidebar_archives-link" href="/archives/2017/09/">九月 2017<span class="sidebar_archives-count">4</span></a></li><li><a class="sidebar_archives-link" href="/archives/2017/08/">八月 2017<span class="sidebar_archives-count">4</span></a>
            </ul>
        </li>
        
    

    <!-- Categories  -->
    
        <li class="dropdown">
            <a href="#" class="ripple-effect dropdown-toggle" data-toggle="dropdown">
                
                    <i class="material-icons sidebar-material-icons">chrome_reader_mode</i>
                
                分类
                <b class="caret"></b>
            </a>
            <ul class="dropdown-menu">
                <li>
                <a class="sidebar_archives-link" href="/categories/分享境/">分享境<span class="sidebar_archives-count">7</span></a></li><li><a class="sidebar_archives-link" href="/categories/技术向/">技术向<span class="sidebar_archives-count">7</span></a></li><li><a class="sidebar_archives-link" href="/categories/文献库/">文献库<span class="sidebar_archives-count">2</span></a></li><li><a class="sidebar_archives-link" href="/categories/自言语/">自言语<span class="sidebar_archives-count">2</span></a></li><li><a class="sidebar_archives-link" href="/categories/诸家堂/">诸家堂<span class="sidebar_archives-count">1</span></a>
            </ul>
        </li>
        
            <li class="divider"></li>
        
    

    <!-- Pages  -->
    
        <li>
            <a href="/gallery" title="映像">
                
                    <i class="material-icons sidebar-material-icons">collections</i>
                
                映像
            </a>
        </li>
        
    
        <li>
            <a href="/about" title="关于我">
                
                    <i class="material-icons sidebar-material-icons">face</i>
                
                关于我
            </a>
        </li>
        
    
        <li>
            <a href="/tags" title="标签云">
                
                标签云
            </a>
        </li>
        
    
        <li>
            <a href="/links" title="友情链接">
                
                友情链接
            </a>
        </li>
        
            <li class="divider"></li>
        
    

    <!-- Article Number  -->
    
        <li>
            <a href="/archives">
                文章总数
                <span class="sidebar-badge">19</span>
            </a>
        </li>
        
    
</ul>


        <!-- Sidebar Footer -->
        <!--
I'm glad you use this theme, the development is no so easy, I hope you can keep the copyright, I will thank you so much.
If you still want to delete the copyrights, could you still retain the first one? Which namely "Theme Material"
It will not impact the appearance and can give developers a lot of support :)

很高兴您使用并喜欢该主题，开发不易 十分谢谢与希望您可以保留一下版权声明。
如果您仍然想删除的话 能否只保留第一项呢？即 "Theme Material"
它不会影响美观并可以给开发者很大的支持和动力。 :)
-->

<!-- Sidebar Divider -->


<!-- Theme Material -->


<!-- Help & Support -->
<!--

-->

<!-- Feedback -->
<!--

-->

<!-- About Theme -->
<!--

-->

    </div>

    <!-- Sidebar Image -->
    
    <span id="footer-image">
        <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" title="cc_logo">
            <img src="/img/by-nc-nd.png" alt="cc_logo"><!--
     --></a>
    </span>


</aside>

                    

                    
                        <!-- Footer Top Button -->
                        <div id="back-to-top" class="toTop-wrap">
    <a href="#top" class="toTop">
        <i class="material-icons footer_top-i">expand_less</i>
    </a>
</div>

                    

                    <!--Footer-->
<script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<footer class="mdl-mini-footer" id="bottom">
    
        <!-- Paradox Footer Left Section -->
        <div class="mdl-mini-footer--left-section sns-list">
    <!-- Twitter -->
    

    <!-- Facebook -->
    

    <!-- Google + -->
    

    <!-- Weibo -->
    
        <a href="https://weibo.com/oye93" target="_blank">
            <button class="mdl-mini-footer--social-btn social-btn footer-sns-weibo">
                <span class="visuallyhidden">Weibo</span>
            </button><!--
     --></a>
    

    <!-- Instagram -->
    

    <!-- Tumblr -->
    

    <!-- Github -->
    
        <a href="https://github.com/OYE93" target="_blank">
            <button class="mdl-mini-footer--social-btn social-btn footer-sns-github">
                <span class="visuallyhidden">Github</span>
            </button><!--
     --></a>
    

    <!-- LinkedIn -->
    

    <!-- Zhihu -->
    

    <!-- Bilibili -->
    

    <!-- Telegram -->
    
    
    <!-- V2EX -->
    
</div>


        <!--Copyright-->
        <div id="copyright">
            Copyright&nbsp;©&nbsp;2017&nbsp;-<script type="text/javascript">var fd = new Date();document.write("&nbsp;" + fd.getFullYear() + "&nbsp;");</script>Travon's Blog
            <br/>
            <span id="busuanzi_container_site_pv">本站总访问量<span id="busuanzi_value_site_pv"></span>次</span>
            
        </div>

        <!-- Paradox Footer Right Section -->

        <!--
        I am glad you use this theme, the development is no so easy, I hope you can keep the copyright.
        It will not impact the appearance and can give developers a lot of support :)

        很高兴您使用该主题，开发不易，希望您可以保留一下版权声明。
        它不会影响美观并可以给开发者很大的支持。 :)
        -->

        <div class="mdl-mini-footer--right-section">
            <div>
                <div class="footer-develop-div">Powered by <a href="https://hexo.io" target="_blank" class="footer-develop-a">Hexo</a></div>
                <div class="footer-develop-div">Theme - <a href="https://github.com/viosey/hexo-theme-material" target="_blank" class="footer-develop-a">Material</a></div>
            </div>
        </div>
    
</footer>


                    <!-- Import JS File -->

    <script>lsloader.load("lazyload_js","https://cdn.jsdelivr.net/npm/hexo-material@1.5.0/source/js/lazyload.min.js", true)</script>



    <script>lsloader.load("js_js","https://cdn.jsdelivr.net/npm/hexo-material@1.5.0/source/js/js.min.js", true)</script>



    <script>lsloader.load("np_js","https://cdn.jsdelivr.net/npm/hexo-material@1.5.0/source/js/nprogress.js", true)</script>


<script type="text/ls-javascript" id="NProgress-script">
    NProgress.configure({
        showSpinner: true
    });
    NProgress.start();
    $('#nprogress .bar').css({
        'background': '#29d'
    });
    $('#nprogress .peg').css({
        'box-shadow': '0 0 10px #29d, 0 0 15px #29d'
    });
    $('#nprogress .spinner-icon').css({
        'border-top-color': '#29d',
        'border-left-color': '#29d'
    });
    setTimeout(function() {
        NProgress.done();
        $('.fade').removeClass('out');
    }, 800);
</script>









   <!-- Gitment -->





<!-- UC Browser Compatible -->
<script>
	var agent = navigator.userAgent.toLowerCase();
	if(agent.indexOf('ucbrowser')>0) {
		document.write('<link rel="stylesheet" href="/css/uc.css">');
	   alert('由于 UC 浏览器使用极旧的内核，而本网站使用了一些新的特性。\n为了您能更好的浏览，推荐使用 Chrome 或 Firefox 浏览器。');
	}
</script>

<!-- Import prettify js  -->



<!-- Window Load -->
<!-- add class for prettify -->
<script type="text/ls-javascript" id="window-load">
    $(window).on('load', function() {
        // Post_Toc parent position fixed
        $('.post-toc-wrap').parent('.mdl-menu__container').css('position', 'fixed');
    });

    
    
</script>

<!-- MathJax Load-->

    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({"HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"], linebreaks: { automatic:true }, EqnChunk: (MathJax.Hub.Browser.isMobile ? 10 : 50) },
        tex2jax: { inlineMath: [ ["$", "$"], ["\\(","\\)"] ], processEscapes: true, ignoreClass: "tex2jax_ignore|dno",skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']},
        TeX: {  noUndefined: { attributes: { mathcolor: "red", mathbackground: "#AAAAAA", mathsize: "90%" } }, Macros: { href: "{}" } },
        messageStyle: "none"
    });
</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>




<!-- Bing Background -->


<script type="text/ls-javascript" id="lazy-load">
    // Offer LazyLoad
    queue.offer(function(){
        $('.lazy').lazyload({
            effect : 'show'
        });
    });

    // Start Queue
    $(document).ready(function(){
        setInterval(function(){
            queue.execNext();
        },200);
    });
</script>

<!-- Custom Footer -->



<script>
    (function(){
        var scriptList = document.querySelectorAll('script[type="text/ls-javascript"]')

        for (var i = 0; i < scriptList.length; ++i) {
            var item = scriptList[i];
            lsloader.runInlineScript(item.id,item.id);
        }
    })()
console.log('\n %c © Material Theme | Version: 1.5.0 | https://github.com/viosey/hexo-theme-material %c \n', 'color:#455a64;background:#e0e0e0;padding:5px 0;border-top-left-radius:5px;border-bottom-left-radius:5px;', 'color:#455a64;background:#e0e0e0;padding:5px 0;border-top-right-radius:5px;border-bottom-right-radius:5px;');
</script>

                </main>
            </div>
        </body>
    
</html>
